{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_Fr_jmSoc52"
      },
      "source": [
        "# NNDL trainings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg84IUBEsptt"
      },
      "source": [
        "## Approach 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEa5nVtus5QK"
      },
      "source": [
        "### Common Utility Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pXRiu5Uons_"
      },
      "source": [
        "#### Download the kaggle datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUgTm-UbocWs",
        "outputId": "953d9624-38a6-4368-84d6-da7b7e5b6341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-18 23:49:08--  https://www.dropbox.com/s/c2dvapqb613ukhw/Released_Data-20221201T215316Z-001.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/c2dvapqb613ukhw/Released_Data-20221201T215316Z-001.zip [following]\n",
            "--2022-12-18 23:49:08--  https://www.dropbox.com/s/raw/c2dvapqb613ukhw/Released_Data-20221201T215316Z-001.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc5cecf31da349937ba31efc0b56.dl.dropboxusercontent.com/cd/0/inline/By5Rs_22qLCoKz5Kh2hMZY11b5vjuNXQL7Y9-UFPJrp6CZdMYP73Zioova06YdvLmLPdqdlB38tzS42w0yoJ_qJcd36rpRrYOCs3LTeTWKeMz3SfZI5cDlEt4KDkvgAoQ5SHX6SHwMdcB41E7nnYGnUtDlW-pBIWamwzUSE5tOPJFA/file# [following]\n",
            "--2022-12-18 23:49:08--  https://uc5cecf31da349937ba31efc0b56.dl.dropboxusercontent.com/cd/0/inline/By5Rs_22qLCoKz5Kh2hMZY11b5vjuNXQL7Y9-UFPJrp6CZdMYP73Zioova06YdvLmLPdqdlB38tzS42w0yoJ_qJcd36rpRrYOCs3LTeTWKeMz3SfZI5cDlEt4KDkvgAoQ5SHX6SHwMdcB41E7nnYGnUtDlW-pBIWamwzUSE5tOPJFA/file\n",
            "Resolving uc5cecf31da349937ba31efc0b56.dl.dropboxusercontent.com (uc5cecf31da349937ba31efc0b56.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to uc5cecf31da349937ba31efc0b56.dl.dropboxusercontent.com (uc5cecf31da349937ba31efc0b56.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/By5f4XzUg0kMZ5qbrzVgj3TMOF2_z5MYydrkQ7xqe82c90z3J499hmE6OyF3Zs2VVQBtCzgfr0ECIU68RfQYgnbfTjx-9BxzWkB3HydVcK590OG7V1VbV5e6E9KGGdEQf5bUfRbvtCXervu9r2HBx7VnQ9D4ENLMfOwBJzMzQizj3_C-SUEfvL-Mi1NZhCyvUdQZmNs5X4S1HvQjWPNEMTufCxGh5BLzBKQT9xgbyhxa-X8yHsS_cjXCagIIleN0uaXZHJHnKWF3DsdWJ3zLlNNSUqa1TEMaAnBPnUhr7boe72VT3Wk916MUMVfWBkkHKwLIwWitiWJzm0048aHhyHxQTNeHL1dktYEs-FekIcutW1pHa2vHm1vN9YRLtQrSNjD8eFjVX-rzHKx6zKNoNNidoFzUdKckd-B6jBqIlQTWfA/file [following]\n",
            "--2022-12-18 23:49:08--  https://uc5cecf31da349937ba31efc0b56.dl.dropboxusercontent.com/cd/0/inline2/By5f4XzUg0kMZ5qbrzVgj3TMOF2_z5MYydrkQ7xqe82c90z3J499hmE6OyF3Zs2VVQBtCzgfr0ECIU68RfQYgnbfTjx-9BxzWkB3HydVcK590OG7V1VbV5e6E9KGGdEQf5bUfRbvtCXervu9r2HBx7VnQ9D4ENLMfOwBJzMzQizj3_C-SUEfvL-Mi1NZhCyvUdQZmNs5X4S1HvQjWPNEMTufCxGh5BLzBKQT9xgbyhxa-X8yHsS_cjXCagIIleN0uaXZHJHnKWF3DsdWJ3zLlNNSUqa1TEMaAnBPnUhr7boe72VT3Wk916MUMVfWBkkHKwLIwWitiWJzm0048aHhyHxQTNeHL1dktYEs-FekIcutW1pHa2vHm1vN9YRLtQrSNjD8eFjVX-rzHKx6zKNoNNidoFzUdKckd-B6jBqIlQTWfA/file\n",
            "Reusing existing connection to uc5cecf31da349937ba31efc0b56.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21340222 (20M) [application/zip]\n",
            "Saving to: ‘released_data.zip’\n",
            "\n",
            "released_data.zip   100%[===================>]  20.35M  76.4MB/s    in 0.3s    \n",
            "\n",
            "2022-12-18 23:49:09 (76.4 MB/s) - ‘released_data.zip’ saved [21340222/21340222]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Download the dataset from Dropbox\n",
        "!wget -O released_data.zip \"https://www.dropbox.com/s/c2dvapqb613ukhw/Released_Data-20221201T215316Z-001.zip?dl=0\"\n",
        "\n",
        "#Unzip the train, test and other datasets\n",
        "!unzip -q released_data.zip\n",
        "!unzip -q ./Released_Data/test_shuffle.zip\n",
        "!unzip -q ./Released_Data/train_shuffle.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZvH3sFqQLdt"
      },
      "source": [
        "#### Display sample images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KodonqI8QNWn",
        "outputId": "65a81e30-51e4-4d3a-94af-1321cefed9cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512.jpg (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F66AF7BD2E0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "755.jpg (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F66A0E2BBE0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1585.jpg (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F66B2005070>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4496.jpg (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F66A0E2B940>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3643.jpg (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F66A0DC1550>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512.jpg (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F66A0DC1E50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAARRklEQVR4nG1a2brTOrPsSXIW8LL/9XloIJMHSd3noiTZWWx9EELi2D13dUn8v//9H11WRLiHu3s4BYlqsvR1+/r68ePnz5+/fv76+evXr1+/fv389ePHzx8/fuS0qCqLUFAQURCziKipqpmqqiozM5N7tLFqrbWWfT/WdX08Hn///v39+/fv37///Pnz58+fv3//3u/31+v1fr9rrcykaimlnHPOKaUkIkTEzERkU3RmIuKAFKdC+I6YxhsmJiaGVMzjDTFRjAuY6Pwad56Xjl/MWzLTf62IGG8+RTqlJSjQZRzXzT9E4ykR/aKICA94yN2bt+aNmIXnk4hZiELY3YXZmYhFhm/PFeFxWf/Id1W1qwkTT63wjbnHh6lp3DCo/5qH5O7wfimlHMdhJqIRZNpYZDiJmUXE3d3cm6qKQAH8HK8jimqtFR9OHfB7EUH4QRRVYZZTHfiaIoKstTq0YWaOQDBPkzAkc/dWWyllPw4RZWKPqNVzzqYmgkAXYhYWVYUAEAWPvZofOsAOpZShQ5deVc3MzFJKzBRB+HDeCgJDZau1DtvTxWXzE5rer7UchzBxuPfHL0dK2dRUlUVl2k5ULtIjO0YIBYKnNW+tHsdRCpwQzDSlR8q6OzNHBDNPJ3zLECulDkG5P+8af13j8NZKrUHUmpdS9/1IKee8ppTNTNVUDXJrt/1psPnIa7hDBwRkay0iIMCUvtbq7iLs7kgtEaYzxEcS11oRUjP4mEVUFKVjZEDzFoVabYcUEVGBl3NKySyZmamZJVVTUxMTERaeCYQX2HJWIfhkKsDMIqf58aGIuDckKsraNx2slDKzB3GmasxMEtMH3ePVY/yWCcFqZilZSikn/GsJDhGRS0k4nyh9wT8UQa21WhvMjHumlJEV+KS12tqsWnQtX8wXBVA7zAyuGDVxmqq5e62t1dqaj7trVyDnnJeccs4ZDpmmQlscz2Mkt5lCSYT4VVwzTcncMzQW4VIUOkAGdx5VKyK4K8BMzKKqCET8uLcbpghyb6XU4ziOo5TjgM2YRdVyynlZluW2LMuSl5Ry92GEh88Ho8iMCpNG5nQdUJ2GUWzWVRERKbVKrbU1rrXCEJD+DKFh9WDm1tTMz4ZCHIQqVI/j2NZt27bjKLU2Ija1nPOy3G63o9y+6q2mVMyMiCO8NW8VLmsXBRICfaghzHKJbFbVlHrQy2XNYCEid4aKVmuZBfgzaeJs+UHu0WorR9n2/b2u+7aXUiPI1PKSS63NHWnampsaMUH6UmutpdY2qqEC2ECBlKADai6PjiuqRsQyCrMIj297uZ+9b5ZRBkJS1dHnz+bsQREOa5bj2Pd93dZylAhSteaNiDuAU2UW6N+az1YFNzDTyIF0XTYWFEGZMlMRCHZiChQiVFgUz97IoAAztzZbe1xg1AeUqKWUoxzH4U5mLizJKpIb+c3cIqLWVkoppez7PmolTSfMcjlfpy6z6cIPV7DHo9rPumatNURLhIoIJIgYZYuIuwYEIOfurUGTHhVtNNigGFhrXO/e6oBPpY7acIKF4zhyzqWUZVlaa7P4TINOMDsVEJHWFDFCRIZnI9g/RJ8Y7xPtBhG6AfUJgPjSBbX/FSJnYiLGxdAZThj1HslQJp5DVDDTNfSZdVpkpvUMciKy+e7acQak++a7vqQHprBSR20GLGFqZr3AS1OfMf2tJxCxSFWtrdkVjUJ0VVVtEYpPoMPsS9/Qq/UqM6ScMcd0Jk2X9wS5ZqpuRkS9EX8uhCI61ERKIo3Zh6XcnYbdZ8wwgBTaOxrtJ77sHviAEiIMhAJT9ZcT1CEeQobgHTzkjNhKKS/5slLKOTGrqiMmW/NaHVjgkh6An63WbnhV9ODUWkPjmwgNE1EEmREzXc1PRKZqRLPF9ClWxsuIxOiGsZRzKnlpHipCxCnl5Xa7oQ0vGdowK/r0zObRVQCJS61M1GL4ol3WrAhDSuggY6pDvbkokHOa1W1UMrWBh7EiSNVPoHtrQVTVmDmnfPv6un3dbrfbstyW5bbkzKwRYVZPeCuKQDLb911LOUqp7kDRFybhv6ZNZNAlyD+W5bzAPCJTgaR6dkfpA6GaWcop18VbMHNLziw559vt68fXjy+osSw5LyI6EiCN2apnyrYls23fVfVA/UFRGpPTR66PeYC/gdAPBZZlGTkkZpZzvnaT2eFHbuVlcRoNW0RTGgr86I6AAkQE9JoBVPOS85bzkvO6rkBB23Ecc2oRUWYA7Jih5d5a6yzBBHxTgT7U3263GaAIkpSzJcyJXQciNqOIFB5EpCI1ZY9QKLDcvr6+vr5+fH3dluWWc0YHjYAO9XYr+37cbrdt29Y19+HBzGw7jtJahUWuQ+PIDQfwmZ/8hwdutwX6XOfRNDVQFVVmEffer1SSWWvwgyVDFt9ut9tt+VoWwGmFE6YOpdR937dtW5ZlAAdbVwPKwOx7xUKzkU9Lz2H63xC6oWCdRR72GXOiin7ksaWW/cS9llLOS17ysix5yXnBL+dMPHRopRzbtsNFVwiHQIITzBKImDkkTAblU4FTC8s5j4Y1u9QQvxckw6ATEwwB9TCjsIz8nPNxH1agxgQppZTbbV+WJedZJ0zV9n07jiMiRHhgUrv270tS/IcTLKWEdxOfTE5mgNykqsJCzJ0ziuCTwundE7+d4+KA+10azL7HcSzLMmcAVbn2L2aabdhMRfSiwkzgM4/xCutexZnSjzHd0lWHgTMYiItZZeCjyanhL6oWxGUWOGG4Rcbs0qsfokiEJymMKBqinnXpWyqDPpiE3umCUbkRr9nMVHQMF8IdgCoR3BInGzkgyNQh54ScLqWM2IgJe5lZVQC2B7clo/m4e4OtZ6ebgL8rgDz7BMXTFSiqS845wQmqwhjvutWRo968uYcDyY52w8yXKR7vZ3ZO3BAUzGyGWtRRHQbBWmEYnwoDlqOFo5BYx9LUIeF0hZkms9wJkxm4HSpzH5a5j2nUImqlFuERPEZWH75Vs9lSaE52UxQmNtMxmdAoOxiyfWTzdycAX9jAGxwdI6HWy8UDfY0aBx4XpZrGoOhBFA7USRGkqp3tOQNDmQUQo14Wir2ZDoKxRz1GRXcXaYP6/pYJRGMiA86OiOBhMx0FErRPTjmlBCGm9O6O3gzv1trA23gzZjFLtdZ2EoOiShExqU8M+7AlFJ5V0t1F6ogZZWnD5xMs9TzuPZWZ3aWHFSrDKPCAMshmxA/6oruHd8qoYdA/jlJKRIjUIAKyGqHSnfuRW30O7k29tTpKvXtrpfCcv6+THU1fQAH8ZgyaZwxhPOwBlHLK2dTmXgsG0dZbbD2OY9/3bQMuCFVFFKWUlmVZlr4DgCS+jBa51amAjlkRUV4xeQ1I11TbHJPpgqsNkReX1CNi4c4/n/OimagyM9w3E7EUEEX7tu3bth3HMRQIVc0p78uxLCXnYtoJU2wEjjSzZMmzC0tzzGLYfhAi9kEFpHQOPQDCZyND1EIzb4jpsdU4Zkj0We6Mb5f+m+jrtm7rdpQS7ioGziunvCzLviw5ZVWLSaq59w3B0XsoiJ0j1N3d+xQ1Ishba+jW3UseTIR61/cH3EUuAz/DCwPeAVcT970ZkKRAl+u6ruv7va7rum7r9k8I5bwsOS/JkoiGBwJj5LYTmHqW6C3CXSR8Mr7YTmutNW/e0mABIlhObrQShbBUEVwIJ2AHYEQdOOoAu3gcx75t67qt6/p+vd+v9/v1er/XbdvQUFU1nEQlWc4p55QNCkTXDVbwNqRhFuYQCWIJcnHgrtZaSlMBKOHuTkHC3D2ATT6RkFpHHfDoDh4LWwTNp/TvdX2/3+/X+/V6v16v1+u9ruu+n4wvjD05UNUOh8yMiT281r6vMSqHEIcAPUcHG8lTa81Ss9asVWuppdH7pgfQiSKiqZxUfnzwWhERLTq9vm3v9f16vZ7PV1/P9/v9XtftOPZaGwWpWRu7B6ljQWDSSCkJS1B489q3XmJs6V6SnDmI3JtZSqm2atWSWQMRZp2bcCI23CIiWlPv+eVX8RE5EXGUsu/7uq6v1+vxeDwez+fz+Xy+3q/3+/3etv0oR2vORGYJ0yAqzaQIEDxjupgcBE3x4e4gAj2sCpxqar2UVNVehaKDeovLunIyMap9cydqrfm+7+u6vV6vx+N5v9/v9/vj8YQf1rFj4O7MklKCK6Rr0McUQAmga6aBYU8s3PUYZHPMGUMAYfSSlCIED3zwiZeN/ABA6MgpSqnbtr/f79fr/Xg+7/f7n7/3xx0avNdtPfajVqST5LS4R9+w63B2ASZnxnSqPA5YnHvzIkCJgwA+iSk5k5EvYjIx9dDEZgj3bekBOfr+diWifT/WbXuv6/P1fDwe9/vj79+/9/vj+XwifspxNHfClsfixIw+vu+3bd9vx47tNbXEIgQOE51gsq+gcFAxSFg60Un9zwjobt9OQBu6pmBrGHMjn+avrTFX98CuDDzwfD7vj8fj/rjf78/na13fvf44kL0FhajmI+/HWKUcFUx6dVd3mUPZWe5mvR4b7zQYuRjbzH5OmBHhxGyAiNwnQbl6oDWvtVFwbW1DArzfz9fr+Xw9n8/H8/l4PHsCHEfrHV1zSoCiRymlFLyWUrBbVluz5iLOzKLRd0T4wobTKTbM3PFdACeFj91WD2dmU9GgQNuFDWD+Npquu5dS0XTfbzjh9Rxl9Pl6bet6lOKtgWiJCFFNJU/BS614rR0MNHFh6SPIrHeB8ZS6/3sNQSScxGnfx2qDVzUWYYqZI/NURocMpQjLcZRt29epw9Dk/X6vSIBBTqkpMakZxD9qOVcdXmhNVNkdASPBHtiaxnBBqORdXogLoDc6crdDBF9ObEF0+kCatTALMR172bZt27Z121bAn3Vd+3/3fQeCcGY2R/yUA8FzlJkEmBYGMSE9LZka8J0IeQhTUD8W0P9A4iF27cCi1dZ6I/NO3zkz4zowgaXU4yjYDd/3Y9v3fdv3fd/3Yz9zswvXaiEKIkEZ7SYfX+/Hvh87oGtKWU25nzvpwS4iGCCjz3rTyvUqeB2fjGLQsVCb8wEug+2PUtQMIdlTsc4QGLsog2lC3I6BHTin36cn8umE4zgM2LaXcqauDwW6AGo3Ur7fqY23Vw94EJPVVgE+0A2QbnisqcJEZcjdmRMCBj43JpvLpQ+izqEMOIxS+k5rOUoxK3227r2om0/jPDdxnfr7ARN4oP+ntdoioECpfc6IYOZqNgKgmBpMVDH5eRCRAKOZ9nMCyVJLRITZupMu5/TtfaoaPqml1FRK1UHN9JegCLjlXwXg0B7/I6h8eGAe9gh3JjZDqPRsA4XYWgsfJI8q2MycU85LrZgfWKSfTzqn77k33nxmFw5OaKnSt2WGAhGu0BwZUM+QPUOpXVfvm6UWhBDqYKlWR7xbNYSJd8aGhMUulHpZahuHrWqpHsHEk4HsOjgotXlYsbVaq1ZRVKKOQyNCvO/QDA+MlBuBdF3etz3ZaqlEAZwoIiBruvJWhTt8DccJUAZflEG3dLoBZwykORCoCguTzI4efoYS3GBWW5Xam89QQL4pcMnhq+jjbuHBTPOwRydXesqM4FNVonAnv1BGJ7eTMG2M80wNJwzPA54DuMRVAygxwSaPgzLoJBHhs4DWdpUd/ezigSCmjzJ61tw6K26jsVM0wTtwY99N7vvJ2rR5OHnHYZ3lvXAw/7WggIjgKacH2inoOPI1WJe5ugKYgOHMPhD7tyUx0GDHXeP8QQfBPI3OcRbTAXo7ppmhNJ/uYzu1Eykghq9XwXsx58TzIEpfFNSpno/xd2xCjTeDcKVz8Th+NMs4wD19rLjspMT5z7fbnkdNxkMuFC9dDi19nCgeffzagGi8/74bTv9c9HmWJb5f+vGTjyHqcv8xVv37NP6Q4eP7j3MfRET/D/uQzPrZTzVdAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "755.jpg (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F66AF7BD1F0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8913.jpg (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F66A0DC1FA0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1585.jpg (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F66AF7BD1F0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4496.jpg (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F66A0DC1FD0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "full_train_imgs = os.listdir(\"./train_shuffle\")\n",
        "full_test_imgs = os.listdir(\"./test_shuffle\")\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    train_img = cv2.imread(os.path.join('train_shuffle', full_train_imgs[i]), cv2.IMREAD_UNCHANGED)\n",
        "    train_img = cv2.resize(train_img, (64, 64), interpolation = cv2.INTER_CUBIC)\n",
        "    print(full_train_imgs[i], train_img.shape)\n",
        "    #cv2.imwrite(\"sample_test.png\", test_img)\n",
        "    cv2_imshow(train_img)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    test_img = cv2.imread(os.path.join('test_shuffle', full_test_imgs[i]), cv2.IMREAD_UNCHANGED)\n",
        "    test_img = cv2.resize(test_img, (64, 64), interpolation = cv2.INTER_CUBIC)\n",
        "    print(full_test_imgs[i], test_img.shape)\n",
        "    #cv2.imwrite(\"sample_test.png\", test_img)\n",
        "    cv2_imshow(test_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBK0TTcBbk5Q"
      },
      "source": [
        "#### Create new folder with 64x64 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zDpBtfCbx2x",
        "outputId": "cfae7349-7e4c-4914-cdd0-c1d7031edfd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6472\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "img_names = os.listdir(\"train_shuffle\")\n",
        "os.makedirs(\"train_shuffle_64\", exist_ok = True)\n",
        "\n",
        "for img_name in img_names:\n",
        "    img = cv2.imread(os.path.join(\"train_shuffle\", img_name), cv2.IMREAD_UNCHANGED)\n",
        "    img = cv2.resize(img, (64, 64), interpolation = cv2.INTER_CUBIC)\n",
        "    cv2.imwrite(os.path.join(\"train_shuffle_64\", img_name), img)\n",
        "\n",
        "print(len(os.listdir(\"train_shuffle_64\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfqYefGKdjCL"
      },
      "source": [
        "#### Create new folder with 32x32 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKtuRyB9dnZg",
        "outputId": "3e8b14b1-88eb-413e-875b-3bc65dc40ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6472\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "img_names = os.listdir(\"train_shuffle\")\n",
        "os.makedirs(\"train_shuffle_32\", exist_ok = True)\n",
        "\n",
        "for img_name in img_names:\n",
        "    img = cv2.imread(os.path.join(\"train_shuffle\", img_name), cv2.IMREAD_UNCHANGED)\n",
        "    img = cv2.resize(img, (32, 32), interpolation = cv2.INTER_CUBIC)\n",
        "    cv2.imwrite(os.path.join(\"train_shuffle_32\", img_name), img)\n",
        "\n",
        "print(len(os.listdir(\"train_shuffle_32\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X-VJRUwWI81"
      },
      "source": [
        "#### Get the device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2ab5gJSWNMn",
        "outputId": "16008f67-398d-4e3c-c15e-edfef121c123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "#Always upgrade to the latest versions\n",
        "#!pip3 install --upgrade torch torchvision\n",
        "\n",
        "import torch\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVH4Elj1e3GL"
      },
      "source": [
        "### Load the tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xxHpOrne5SD",
        "outputId": "fddaf495-81c7-4fe8-8bad-bc8aadc9fe11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (2.9.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.51.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.38.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PJ4XpuL9nFNF",
        "outputId": "9056ed4b-96ef-4bd9-b22c-82c5c0593f95"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#!rm -rf runs\n",
        "#!rm -rf models\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmvpcuP6s0oF"
      },
      "source": [
        "### Baseline Dataset and Dataloader preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6_XaVfgSbYm"
      },
      "source": [
        "#### Train and Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsYRPJv8SbwD",
        "outputId": "d1c16b69-f4f0-495e-fb27-29cef3292413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{74: 51, 11: 51, 14: 51, 5: 51, 41: 51, 16: 51, 85: 51, 52: 51, 40: 51, 57: 51, 79: 51, 82: 51, 42: 51, 88: 51, 8: 51, 26: 51, 20: 51, 60: 51, 61: 51, 81: 51, 84: 51, 19: 51, 24: 100, 30: 100, 27: 100, 6: 100, 28: 100, 76: 100, 86: 100, 4: 100}\n",
            "{12: 50, 38: 50, 10: 50, 45: 50, 80: 50, 87: 50, 23: 50, 32: 50, 9: 50, 17: 50, 2: 50, 55: 50, 78: 50, 54: 50, 0: 50, 25: 50, 63: 100, 49: 100, 22: 100, 18: 100, 7: 100, 66: 100, 71: 100, 37: 100, 65: 100, 31: 100, 21: 100, 46: 100, 36: 100}\n",
            "{48: 50, 68: 50, 69: 50, 75: 50, 3: 50, 56: 50, 33: 50, 34: 50, 39: 50, 13: 50, 15: 50, 72: 100, 43: 100, 1: 100, 53: 100, 67: 100, 58: 100, 59: 100, 35: 100, 70: 100, 73: 100, 77: 100, 51: 100, 64: 100, 44: 100, 29: 100, 50: 100, 83: 100, 62: 100, 47: 100}\n",
            "Common names:  []\n",
            "Error names:  []\n",
            "Total number of images:  6472\n",
            "Number of training images:  (5738, 3)\n",
            "Number of validation images:  (734, 3)\n",
            "Super Class distribution:\n",
            "Class:  1  Validation:  239  Train:  1861  Ratio:  7.7866108786610875\n",
            "Class:  0  Validation:  220  Train:  1702  Ratio:  7.736363636363636\n",
            "Class:  2  Validation:  275  Train:  2175  Ratio:  7.909090909090909\n",
            "------------------------------\n",
            "Sub Class distribution:\n",
            "Class:  63  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  24  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  74  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  72  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  43  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  1  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  11  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  12  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  49  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  22  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  53  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  18  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  48  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  7  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  30  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  68  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  27  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  67  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  66  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  58  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  59  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  35  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  14  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  71  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  5  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  69  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  70  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  38  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  75  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  6  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  73  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  10  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  45  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  41  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  77  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  16  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  85  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  37  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  51  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  28  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  52  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  40  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  65  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  57  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  76  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  64  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  79  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  44  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  29  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  86  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  82  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  80  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  3  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  87  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  56  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  31  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  4  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  42  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  88  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  23  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  50  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  8  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  21  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  26  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  20  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  46  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  32  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  60  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  61  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  33  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  9  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  17  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  34  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  36  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  2  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  55  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  78  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  54  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  39  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  13  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  81  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  84  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  83  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  0  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  15  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Class:  62  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  19  Validation:  6  Train:  45  Ratio:  7.5\n",
            "Class:  47  Validation:  11  Train:  89  Ratio:  8.090909090909092\n",
            "Class:  25  Validation:  6  Train:  44  Ratio:  7.333333333333333\n",
            "Minimum Sub Class ratio:  7.333333333333333\n",
            "Maximum Sub Class ratio:  8.090909090909092\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "full_labels = pd.read_csv('./Released_Data/train_data.csv').to_numpy()\n",
        "\n",
        "labels_list = [set(),set(),set()]\n",
        "\n",
        "#prepare lists based on the super classes\n",
        "labels_list = [{}, {}, {}]\n",
        "val_labels_list = [{}, {}, {}]\n",
        "\n",
        "# Create mapping between the sub classes and the super classes\n",
        "sub_class_list = [{}, {}, {}]\n",
        "\n",
        "for i in range(len(full_labels)):\n",
        "    if full_labels[i][2] in labels_list[full_labels[i][1]]:\n",
        "        labels_list[full_labels[i][1]][full_labels[i][2]] += 1\n",
        "    else:\n",
        "        labels_list[full_labels[i][1]][full_labels[i][2]] = 1\n",
        "        val_labels_list[full_labels[i][1]][full_labels[i][2]] = 0\n",
        "        sub_class_list[full_labels[i][1]][len(sub_class_list[full_labels[i][1]])] = full_labels[i][2]\n",
        "\n",
        "# Check the number of times each sub class appears\n",
        "print(dict(sorted(labels_list[0].items(), key=lambda item: item[1])))\n",
        "print(dict(sorted(labels_list[1].items(), key=lambda item: item[1])))\n",
        "print(dict(sorted(labels_list[2].items(), key=lambda item: item[1])))\n",
        "\n",
        "# print(sub_class_list[0])\n",
        "# print(sub_class_list[1])\n",
        "# print(sub_class_list[2])\n",
        "\n",
        "\n",
        "#Splitting the train and validation datasets\n",
        "train_imgs = []\n",
        "val_imgs = []\n",
        "\n",
        "for i in range(len(full_labels)):\n",
        "    if val_labels_list[full_labels[i][1]][full_labels[i][2]] <= (0.1)*(labels_list[full_labels[i][1]][full_labels[i][2]]):\n",
        "        val_labels_list[full_labels[i][1]][full_labels[i][2]] += 1\n",
        "        val_imgs.append(full_labels[i][0])\n",
        "    else:\n",
        "        train_imgs.append(full_labels[i][0])\n",
        "\n",
        "#Check if there is any common image between training and validation datasets\n",
        "common_names = [name for name in train_imgs if name in val_imgs]\n",
        "print(\"Common names: \", common_names)\n",
        "\n",
        "train_data = full_labels[np.isin(full_labels[:, 0], train_imgs)]\n",
        "val_data = full_labels[np.isin(full_labels[:, 0], val_imgs)]\n",
        "\n",
        "#Check if there is any name missing from the training dataset\n",
        "ver_train_names = train_data[:, 0]\n",
        "error_names = [name for name in ver_train_names if name not in train_imgs]\n",
        "print(\"Error names: \", error_names)\n",
        "\n",
        "print(\"Total number of images: \", len(full_labels))\n",
        "print(\"Number of training images: \", train_data.shape)\n",
        "print(\"Number of validation images: \", val_data.shape)\n",
        "# print(type(train_data[0][0]))\n",
        "# print(type(train_data[0][1]))\n",
        "# print(type(val_data[0][0]))\n",
        "# print(type(val_data[0][1]))\n",
        "\n",
        "\n",
        "# --------Code to check the distribution of super and sub classes in the training and validation datasets---------\n",
        "train_sub_dict = {}\n",
        "train_super_dict = {}\n",
        "val_sub_dict = {}\n",
        "val_super_dict = {}\n",
        "\n",
        "for i in range(full_labels.shape[0]):\n",
        "    name = full_labels[i][0]\n",
        "    super_class = full_labels[i][1]\n",
        "    sub_class = full_labels[i][2]\n",
        "\n",
        "    if name in val_data[:, 0]:\n",
        "        if super_class in val_super_dict:\n",
        "            val_super_dict[super_class] += 1\n",
        "        else:\n",
        "            val_super_dict[super_class] = 1\n",
        "        \n",
        "        if sub_class in val_sub_dict:\n",
        "            val_sub_dict[sub_class] += 1\n",
        "        else:\n",
        "            val_sub_dict[sub_class] = 1\n",
        "    else:\n",
        "        if super_class in train_super_dict:\n",
        "            train_super_dict[super_class] += 1\n",
        "        else:\n",
        "            train_super_dict[super_class] = 1\n",
        "        \n",
        "        if sub_class in train_sub_dict:\n",
        "            train_sub_dict[sub_class] += 1\n",
        "        else:\n",
        "            train_sub_dict[sub_class] = 1\n",
        "\n",
        "print(\"Super Class distribution:\")\n",
        "for k in val_super_dict:\n",
        "    print(\"Class: \", k, \" Validation: \", val_super_dict[k], \" Train: \", train_super_dict[k], \" Ratio: \", train_super_dict[k]/val_super_dict[k])\n",
        "\n",
        "print(\"------------------------------\")\n",
        "print(\"Sub Class distribution:\")\n",
        "min_val = 10000\n",
        "max_val = -1\n",
        "for k in val_sub_dict:\n",
        "    min_val = min(min_val, train_sub_dict[k]/val_sub_dict[k])\n",
        "    max_val = max(max_val, train_sub_dict[k]/val_sub_dict[k])\n",
        "    print(\"Class: \", k, \" Validation: \", val_sub_dict[k], \" Train: \", train_sub_dict[k], \" Ratio: \", train_sub_dict[k]/val_sub_dict[k])\n",
        "\n",
        "print(\"Minimum Sub Class ratio: \", min_val)\n",
        "print(\"Maximum Sub Class ratio: \", max_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrEdW8Li5-DY"
      },
      "source": [
        "#### KaggleDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P9rfTIHYs0-B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class KaggleDataset(nn.Module):\n",
        "    def __init__(self, mode = 'train'):\n",
        "        super(KaggleDataset, self).__init__()\n",
        "        self.mode = mode\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.dataset = train_data\n",
        "        else:\n",
        "            self.dataset = val_data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.dataset[idx][0]\n",
        "        img = cv2.imread(os.path.join('train_shuffle_32', img_name))   \n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    #convert image from BGR to RGB format\n",
        "\n",
        "        super_class = torch.tensor(self.dataset[idx][1], dtype = torch.float32)\n",
        "        sub_class = torch.tensor(self.dataset[idx][2], dtype = torch.float32)\n",
        "\n",
        "        apply_transform = self.transform_data()\n",
        "        image = apply_transform(image = img)['image']\n",
        "\n",
        "        return image, super_class, sub_class\n",
        "\n",
        "    def transform_data(self):\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            transform_func = A.Compose(\n",
        "              [\n",
        "                  #flip the image 40% of the time\n",
        "                  A.HorizontalFlip(p=0.4),  \n",
        "                  #shift, scale and rotate the image 50% of the time\n",
        "                  A.ShiftScaleRotate(shift_limit=0.025, scale_limit=0, rotate_limit=15, p=0.5),\n",
        "                  #randomly change brightness, contrast, and saturation of the image 50% of the time\n",
        "                  A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue = 0, p=0.5), \n",
        "                  A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1), \n",
        "                  ToTensorV2(p=1),\n",
        "              ])\n",
        "        else:     #augmentations during validation and testing\n",
        "          transform_func = A.Compose(\n",
        "          [   \n",
        "              A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1),\n",
        "              ToTensorV2(p=1),\n",
        "          ])\n",
        "    \n",
        "        return transform_func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI1Srqj-GkHs"
      },
      "source": [
        "#### KaggleDataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekKlmYMuGmnu",
        "outputId": "3ab739ec-2903-4e0f-954d-86afb2fa100c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = KaggleDataset(mode='train')\n",
        "val_dataset = KaggleDataset(mode='val')\n",
        "    \n",
        "train_loader = DataLoader(dataset = train_dataset, batch_size = 32, shuffle = True, num_workers = 8, pin_memory = True)\n",
        "val_loader = DataLoader(dataset = val_dataset, batch_size = 32, shuffle = False)\n",
        "\n",
        "# print(len(train_loader))\n",
        "# print(len(val_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJQD547UyV4w"
      },
      "source": [
        "### Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3OOSvfMdZxb"
      },
      "source": [
        "#### Baseline Super Class model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZvrRhmddgyt"
      },
      "source": [
        "##### Super Class training utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGIlY3_ZdlOf"
      },
      "outputs": [],
      "source": [
        "# Will contain utility functions used for training the model\n",
        "import torch\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "#Training Function\n",
        "def fit_classifier(model, train_loader, val_loader, optimizer, loss_func, epochs=10, initial_epoch=0, device='cpu', name='effnetb6'):\n",
        "    '''\n",
        "    function to train a classifier model.\n",
        "    args:\n",
        "        model - the model to be trained\n",
        "        train_loader - Dataloader() for train set\n",
        "        val_loader - Dataloader() for val set\n",
        "        optimizer - optimization algorithm for updating weights\n",
        "        loss_func - loss function to be used\n",
        "    \n",
        "    keyword args:\n",
        "        epochs - Number of training epochs (default=10)\n",
        "        initial_epoch - The starting epoch\n",
        "        device - the device for training (default='cpu')\n",
        "        name - Name for saving the model\n",
        "    \n",
        "    returns: Nothing\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    model = model.to(device, non_blocking=True)\n",
        "    \n",
        "    # Save the models based on the super class validation accuracies\n",
        "    best_super_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    \n",
        "    #create the logger object\n",
        "    writer = SummaryWriter()\n",
        "    start_time = time.time()\n",
        "    \n",
        "    #Iterate epochs\n",
        "    for epoch in range(initial_epoch, initial_epoch + epochs):\n",
        "        #Each epoch has a training phase and validation phase\n",
        "        for phase in ['train','val']:\n",
        "            data_loader = None\n",
        "            if phase == 'train':\n",
        "                #Set train mode\n",
        "                model.train()\n",
        "                data_loader = train_loader\n",
        "            else:\n",
        "                #Set Eval mode\n",
        "                model.eval()\n",
        "                data_loader = val_loader\n",
        "          \n",
        "            running_super_loss = 0.\n",
        "            running_super_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            \n",
        "            #tqdm for observing the progress\n",
        "            with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
        "                #Iterate batches\n",
        "                for itr, (images, super_labels, sub_labels) in enumerate(tepoch):\n",
        "                    tepoch.set_description(f\"Epoch {(epoch)} {phase}\")\n",
        "                    images = images.to(device, non_blocking=True)\n",
        "\n",
        "                    super_labels = super_labels.long().to(device, non_blocking=True)\n",
        "                    sub_labels = sub_labels.long().to(device, non_blocking=True)\n",
        "                    \n",
        "                    optimizer.zero_grad()\n",
        "                    \n",
        "                    #Set gradient calculation only for training phase\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        super_outputs = model(images)\n",
        "                        super_loss = loss_func(super_outputs, super_labels)\n",
        "\n",
        "                        super_preds = torch.argmax(super_outputs, dim=1)\n",
        "\n",
        "                        loss = 5 * super_loss\n",
        "                        \n",
        "                        #Do backprop only during training\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                    \n",
        "                    running_super_loss += 5 * super_loss.item() * images.size(0)\n",
        "                    running_super_corrects += torch.sum(super_preds == super_labels)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        writer.add_scalar(\"Batch_Loss/\" + phase, loss.item(), epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Super_Class/\" + phase,\n",
        "                                          (torch.sum(super_preds == super_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                    \n",
        "                    tepoch.set_postfix(loss=loss.item(),\n",
        "                              super_class_accuracy=(torch.sum(super_preds == super_labels)/(images.shape[0])).item())\n",
        "                \n",
        "                epoch_super_loss = running_super_loss / len(data_loader.dataset)\n",
        "                epoch_super_acc = running_super_corrects.float() / (len(data_loader.dataset))\n",
        "\n",
        "                print(f\"Epoch {(epoch)} {phase} Super Class loss: {epoch_super_loss} Super Class acc: {epoch_super_acc.item()}\")\n",
        "                \n",
        "                writer.add_scalar(\"Epoch_Loss_Super_Class/\" + phase, epoch_super_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Super_Class/\" + phase, epoch_super_acc, epoch)\n",
        "                \n",
        "                # #Saving best model based on super class accuracy\n",
        "                if phase == 'val' and epoch_super_acc > best_super_acc:\n",
        "                    best_super_acc = epoch_super_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SuperClass.pth\")   \n",
        "                \n",
        "        print('-'*20)\n",
        "    \n",
        "    #End of Training \n",
        "    end_time = time.time()  \n",
        "    writer.close()\n",
        "    print('Best Super Class val acc: {}'.format(best_super_acc.item()))\n",
        "    print(f\"Average Time taken for an epoch: {(end_time - start_time)/epochs} sec\")\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRVv9fvjeZz6"
      },
      "source": [
        "##### Create the Super Class model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "1eac266755e14dfdbfb7e331da9a8894",
            "267b5da6d4104a4fb540eeb24202ade4",
            "bcb42bd15db94d569c3c7d5dcd68417a",
            "2f54049fba174b8f9ecf1bb37cba8e5c",
            "05df3846f31140c6a78e3de18766b889",
            "48447bacc83b4994a3245725f0c2c751",
            "f150e713a47a4af9a7a0762101c18874",
            "cb6b5a6576294c55adbe568ec772cb41",
            "54e278fb178441e18a7470b44d6fbc5f",
            "6461925d48ed4295907384fdb9acbf24",
            "88afd5b763ce48dcac39908b8837bbbc"
          ]
        },
        "id": "l06NtfDDeczL",
        "outputId": "f2f82100-d5b8-427c-d76d-9cdc35a6153b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/swin_t-704ceda3.pth\" to /root/.cache/torch/hub/checkpoints/swin_t-704ceda3.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/108M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1eac266755e14dfdbfb7e331da9a8894"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# Load the Swin Transformer model trained on ImageNet\n",
        "backbone_model = torchvision.models.swin_t(weights='IMAGENET1K_V1')\n",
        "backbone_model.head = nn.Identity()\n",
        "\n",
        "class BaselineSuperModel(nn.Module):\n",
        "    def __init__(self, backbone) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        # 3 super classes\n",
        "        self.superclass = nn.Linear(in_features = 768, out_features = 3)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.backbone(x)\n",
        "        super_class_out = self.superclass(out)\n",
        "        return super_class_out\n",
        "\n",
        "# Create the baseline model\n",
        "baseline_super_model = BaselineSuperModel(backbone_model)\n",
        "baseline_super_model = baseline_super_model.to(device, non_blocking = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C19BLYHTe-Ou"
      },
      "source": [
        "##### Train the Super Class model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJEE0vzie-Ov"
      },
      "source": [
        "###### Freeze all the layers except Classifier layers (phase 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvMXStc4e-Ov",
        "outputId": "c28c8ac5-84e9-4f98-8128-6d90c077f5de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "================================================================\n",
            "Total params: 18,854,499\n",
            "Trainable params: 2,307\n",
            "Non-trainable params: 18,852,192\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 71.92\n",
            "Estimated Total Size (MB): 91.07\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with all backbone frozen)\n",
        "for param in baseline_super_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in baseline_super_model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(baseline_super_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in baseline_super_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH0mm_oBe-Ov",
        "outputId": "04cc8959-c863-4d5b-b6c3-9bc09d97faec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 train: 100%|██████████| 180/180 [00:07<00:00, 23.15batch/s, loss=4.69, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train Super Class loss: 4.82147335289413 Super Class acc: 0.5449634194374084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 val: 100%|██████████| 23/23 [00:00<00:00, 32.53batch/s, loss=4.27, super_class_accuracy=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 val Super Class loss: 4.2532674192732625 Super Class acc: 0.6158037781715393\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 train: 100%|██████████| 180/180 [00:08<00:00, 22.39batch/s, loss=5.8, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train Super Class loss: 4.075293569624653 Super Class acc: 0.6418612599372864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 val: 100%|██████████| 23/23 [00:00<00:00, 23.16batch/s, loss=3.89, super_class_accuracy=0.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 val Super Class loss: 3.843906446276309 Super Class acc: 0.6689373254776001\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 train: 100%|██████████| 180/180 [00:07<00:00, 24.12batch/s, loss=2.43, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train Super Class loss: 3.755002365882241 Super Class acc: 0.684384822845459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 val: 100%|██████████| 23/23 [00:00<00:00, 34.05batch/s, loss=3.62, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 val Super Class loss: 3.625774547579503 Super Class acc: 0.6866484880447388\n",
            "--------------------\n",
            "Best Super Class val acc: 0.6866484880447388\n",
            "Average Time taken for an epoch: 9.483170509338379 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 3\n",
        "initial_epoch = 0\n",
        "learning_rate = 1e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    baseline_super_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Baseline_SwinT_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU-vX-oye-Ov"
      },
      "source": [
        "###### Unfreeze some layers of the backbone network (phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNlp9swle-Ov",
        "outputId": "ce955f81-10bd-46ec-f7de-8977d75b95e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "================================================================\n",
            "Total params: 18,854,499\n",
            "Trainable params: 4,727,811\n",
            "Non-trainable params: 14,126,688\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 71.92\n",
            "Estimated Total Size (MB): 91.07\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with some backbone frozen)\n",
        "for param in baseline_super_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "#print(baseline_model.backbone.features[7])\n",
        "\n",
        "for param in baseline_super_model.backbone.features[:8].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for idx, (name, param) in enumerate(baseline_super_model.backbone.features[7].named_parameters()):\n",
        "    #print(name, idx)\n",
        "    if idx > 15:\n",
        "        param.requires_grad = True\n",
        "\n",
        "summary(baseline_super_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in baseline_super_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9d2SBjae-Ov",
        "outputId": "2b84ac68-8858-4fcd-958e-94e48003fde5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 train: 100%|██████████| 180/180 [00:08<00:00, 21.32batch/s, loss=2.76, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train Super Class loss: 3.4882886364469132 Super Class acc: 0.7091320753097534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 val: 100%|██████████| 23/23 [00:00<00:00, 34.40batch/s, loss=3.23, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 val Super Class loss: 3.076882973841166 Super Class acc: 0.7670299410820007\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 train: 100%|██████████| 180/180 [00:08<00:00, 21.50batch/s, loss=2.73, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train Super Class loss: 2.9844414220740463 Super Class acc: 0.7588009834289551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 val: 100%|██████████| 23/23 [00:00<00:00, 33.48batch/s, loss=3.01, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 val Super Class loss: 2.8612357621621696 Super Class acc: 0.7752043604850769\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 train: 100%|██████████| 180/180 [00:08<00:00, 21.42batch/s, loss=5.48, super_class_accuracy=0.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train Super Class loss: 2.7144633736831465 Super Class acc: 0.784593939781189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 val: 100%|██████████| 23/23 [00:00<00:00, 32.99batch/s, loss=3.11, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 val Super Class loss: 2.6942027281025775 Super Class acc: 0.7929155230522156\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 train: 100%|██████████| 180/180 [00:08<00:00, 21.50batch/s, loss=3.76, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train Super Class loss: 2.5245388345088475 Super Class acc: 0.7985360622406006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 val: 100%|██████████| 23/23 [00:00<00:00, 33.03batch/s, loss=2.98, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 val Super Class loss: 2.657127040121146 Super Class acc: 0.7847411632537842\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 train: 100%|██████████| 180/180 [00:08<00:00, 21.46batch/s, loss=2.76, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train Super Class loss: 2.4286810574360365 Super Class acc: 0.8070756196975708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 val: 100%|██████████| 23/23 [00:00<00:00, 34.52batch/s, loss=3.46, super_class_accuracy=0.767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 val Super Class loss: 2.822546451390602 Super Class acc: 0.7833787202835083\n",
            "--------------------\n",
            "Best Super Class val acc: 0.7929155230522156\n",
            "Average Time taken for an epoch: 9.241707229614258 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "initial_epoch = 3\n",
        "learning_rate = 3e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    baseline_super_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Baseline_SwinT_semi_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d5iaNWIe-Ov"
      },
      "source": [
        "###### Unfreeze all the layers in the network (phase 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6qmHtA5e-Ov",
        "outputId": "56de3f73-acb5-4ed4-f966-7b9600ee44eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "================================================================\n",
            "Total params: 18,854,499\n",
            "Trainable params: 18,854,499\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 71.92\n",
            "Estimated Total Size (MB): 91.07\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with everything unfrozen)\n",
        "for param in baseline_super_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "summary(baseline_super_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in baseline_super_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9lJAWMke-Ow",
        "outputId": "0da09d28-db9c-423d-b493-2d390dc4a9b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 train: 100%|██████████| 180/180 [00:16<00:00, 10.77batch/s, loss=2.29, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 train Super Class loss: 3.0272700613427554 Super Class acc: 0.7636806964874268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 val: 100%|██████████| 23/23 [00:00<00:00, 31.54batch/s, loss=2.35, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 val Super Class loss: 2.365348228641687 Super Class acc: 0.829700231552124\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 train: 100%|██████████| 180/180 [00:15<00:00, 11.63batch/s, loss=2.82, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 train Super Class loss: 2.2728976892984547 Super Class acc: 0.8271174430847168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 val: 100%|██████████| 23/23 [00:00<00:00, 33.10batch/s, loss=1.29, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 val Super Class loss: 2.2612869816677446 Super Class acc: 0.8201634883880615\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 train: 100%|██████████| 180/180 [00:15<00:00, 11.92batch/s, loss=1.67, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 train Super Class loss: 1.9374616775478624 Super Class acc: 0.8539560437202454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 val: 100%|██████████| 23/23 [00:00<00:00, 32.88batch/s, loss=1.71, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 val Super Class loss: 2.440904890483991 Super Class acc: 0.8106266856193542\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 train: 100%|██████████| 180/180 [00:15<00:00, 11.33batch/s, loss=2.35, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 train Super Class loss: 1.723081583073431 Super Class acc: 0.8713837265968323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 val: 100%|██████████| 23/23 [00:00<00:00, 31.98batch/s, loss=1.78, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 val Super Class loss: 1.9964888488889065 Super Class acc: 0.8446866273880005\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 train: 100%|██████████| 180/180 [00:16<00:00, 10.73batch/s, loss=0.594, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 train Super Class loss: 1.4912948884140036 Super Class acc: 0.8915998339653015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 val: 100%|██████████| 23/23 [00:00<00:00, 31.85batch/s, loss=1.13, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 val Super Class loss: 1.9191545258182272 Super Class acc: 0.8514986038208008\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 train: 100%|██████████| 180/180 [00:15<00:00, 11.67batch/s, loss=0.686, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 train Super Class loss: 1.3280023047528478 Super Class acc: 0.9004879593849182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 val: 100%|██████████| 23/23 [00:00<00:00, 31.13batch/s, loss=1.41, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 val Super Class loss: 2.139566760784274 Super Class acc: 0.8365122675895691\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 train: 100%|██████████| 180/180 [00:15<00:00, 11.85batch/s, loss=1.15, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 train Super Class loss: 1.2349051365654158 Super Class acc: 0.9097246527671814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 val: 100%|██████████| 23/23 [00:00<00:00, 32.54batch/s, loss=0.455, super_class_accuracy=0.967]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 val Super Class loss: 2.2193308215212757 Super Class acc: 0.8460490107536316\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 train: 100%|██████████| 180/180 [00:15<00:00, 11.59batch/s, loss=2.38, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 train Super Class loss: 1.1453671865074342 Super Class acc: 0.911990225315094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 val: 100%|██████████| 23/23 [00:00<00:00, 30.28batch/s, loss=0.845, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 val Super Class loss: 2.1664185087102634 Super Class acc: 0.85694819688797\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 train: 100%|██████████| 180/180 [00:15<00:00, 11.73batch/s, loss=0.869, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 train Super Class loss: 0.9638863001583594 Super Class acc: 0.9278494119644165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 val: 100%|██████████| 23/23 [00:00<00:00, 31.52batch/s, loss=0.737, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 val Super Class loss: 2.0981600492867853 Super Class acc: 0.863760232925415\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 train: 100%|██████████| 180/180 [00:15<00:00, 11.76batch/s, loss=0.312, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 train Super Class loss: 0.8243874848893957 Super Class acc: 0.9414430260658264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 val: 100%|██████████| 23/23 [00:00<00:00, 31.10batch/s, loss=1.78, super_class_accuracy=0.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 val Super Class loss: 2.317374534194411 Super Class acc: 0.8528610467910767\n",
            "--------------------\n",
            "Best Super Class val acc: 0.863760232925415\n",
            "Average Time taken for an epoch: 16.542545127868653 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "initial_epoch = 8\n",
        "learning_rate = 3e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    baseline_super_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Baseline_SwinT_unfrozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj1QkMhJgM5W"
      },
      "source": [
        "#### Baseline Sub Class model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3mo7w5VgW7J"
      },
      "source": [
        "##### Sub Class training utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3wRTmdagW7J"
      },
      "outputs": [],
      "source": [
        "# Will contain utility functions used for training the model\n",
        "import torch\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "#Training Function\n",
        "def fit_classifier(model, train_loader, val_loader, optimizer, loss_func, epochs=10, initial_epoch=0, device='cpu', name='effnetb6'):\n",
        "    '''\n",
        "    function to train a classifier model.\n",
        "    args:\n",
        "        model - the model to be trained\n",
        "        train_loader - Dataloader() for train set\n",
        "        val_loader - Dataloader() for val set\n",
        "        optimizer - optimization algorithm for updating weights\n",
        "        loss_func - loss function to be used\n",
        "    \n",
        "    keyword args:\n",
        "        epochs - Number of training epochs (default=10)\n",
        "        initial_epoch - The starting epoch\n",
        "        device - the device for training (default='cpu')\n",
        "        name - Name for saving the model\n",
        "    \n",
        "    returns: Nothing\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    model = model.to(device, non_blocking=True)\n",
        "    \n",
        "    # Save the models based on the sub class validation accuracies\n",
        "    best_sub_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    \n",
        "    #create the logger object\n",
        "    writer = SummaryWriter()\n",
        "    start_time = time.time()\n",
        "    \n",
        "    #Iterate epochs\n",
        "    for epoch in range(initial_epoch, initial_epoch + epochs):\n",
        "        #Each epoch has a training phase and validation phase\n",
        "        for phase in ['train','val']:\n",
        "            data_loader = None\n",
        "            if phase == 'train':\n",
        "                #Set train mode\n",
        "                model.train()\n",
        "                data_loader = train_loader\n",
        "            else:\n",
        "                #Set Eval mode\n",
        "                model.eval()\n",
        "                data_loader = val_loader\n",
        "          \n",
        "            running_sub_loss = 0.\n",
        "            running_sub_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            \n",
        "            #tqdm for observing the progress\n",
        "            with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
        "                #Iterate batches\n",
        "                for itr, (images, super_labels, sub_labels) in enumerate(tepoch):\n",
        "                    tepoch.set_description(f\"Epoch {(epoch)} {phase}\")\n",
        "                    images = images.to(device, non_blocking=True)\n",
        "\n",
        "                    super_labels = super_labels.long().to(device, non_blocking=True)\n",
        "                    sub_labels = sub_labels.long().to(device, non_blocking=True)\n",
        "                    \n",
        "                    optimizer.zero_grad()\n",
        "                    \n",
        "                    #Set gradient calculation only for training phase\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        sub_outputs = model(images)\n",
        "                        sub_loss = loss_func(sub_outputs, sub_labels)\n",
        "\n",
        "                        sub_preds = torch.argmax(sub_outputs, dim=1)\n",
        "\n",
        "                        loss = 2 * sub_loss\n",
        "                        \n",
        "                        #Do backprop only during training\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                    \n",
        "                    running_sub_loss += 2 * sub_loss.item() * images.size(0)\n",
        "                    running_sub_corrects += torch.sum(sub_preds == sub_labels)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        writer.add_scalar(\"Batch_Loss/\" + phase, loss.item(), epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Sub_Class/\" + phase,\n",
        "                                          (torch.sum(sub_preds == sub_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                    \n",
        "                    tepoch.set_postfix(loss=loss.item(),\n",
        "                              sub_class_accuracy=(torch.sum(sub_preds == sub_labels)/(images.shape[0])).item())\n",
        "                \n",
        "                epoch_sub_loss = running_sub_loss / len(data_loader.dataset)\n",
        "                epoch_sub_acc = running_sub_corrects.float() / (len(data_loader.dataset))\n",
        "\n",
        "                print(f\"Epoch {(epoch)} {phase} Sub Class loss: {epoch_sub_loss} Sub Class acc: {epoch_sub_acc.item()}\")\n",
        "                \n",
        "                writer.add_scalar(\"Epoch_Loss_Sub_Class/\" + phase, epoch_sub_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Sub_Class/\" + phase, epoch_sub_acc, epoch)\n",
        "                \n",
        "                # #Saving best model based on sub class accuracy\n",
        "                if phase == 'val' and epoch_sub_acc > best_sub_acc:\n",
        "                    best_sub_acc = epoch_sub_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SubClass.pth\")   \n",
        "                \n",
        "        print('-'*20)\n",
        "    \n",
        "    #End of Training \n",
        "    end_time = time.time()  \n",
        "    writer.close()\n",
        "    print('Best Sub Class val acc: {}'.format(best_sub_acc.item()))\n",
        "    print(f\"Average Time taken for an epoch: {(end_time - start_time)/epochs} sec\")\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKUvkzSVgW7J"
      },
      "source": [
        "##### Create the Sub Class model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uFnB8pegW7J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# Load the Swin Transformer model trained on ImageNet\n",
        "backbone_model = torchvision.models.swin_t(weights='IMAGENET1K_V1')\n",
        "backbone_model.head = nn.Identity()\n",
        "\n",
        "# input = torch.rand((1, 3, 32, 32))\n",
        "# output = backbone_model(input)\n",
        "# print(output.shape)\n",
        "\n",
        "class BaselineSubModel(nn.Module):\n",
        "    def __init__(self, backbone) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        # 89 sub classes\n",
        "        self.subclass = nn.Linear(in_features = 768, out_features = 89)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.backbone(x)\n",
        "        sub_class_out = self.subclass(out)\n",
        "        return sub_class_out\n",
        "\n",
        "# Create the baseline model\n",
        "baseline_sub_model = BaselineSubModel(backbone_model)\n",
        "baseline_sub_model = baseline_sub_model.to(device, non_blocking = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2aFWCJKgW7K"
      },
      "source": [
        "##### Train the Sub Class model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2y4blwZgW7K"
      },
      "source": [
        "###### Freeze all the layers except Classifier layers (phase 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfveITargW7K",
        "outputId": "b5acfa9a-c2d6-473a-9112-68da668aeb9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,920,633\n",
            "Trainable params: 68,441\n",
            "Non-trainable params: 18,852,192\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.18\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with all backbone frozen)\n",
        "for param in baseline_sub_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in baseline_sub_model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(baseline_sub_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in baseline_sub_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NpzQik5gW7K",
        "outputId": "84901ef9-8590-4cea-ce28-2ec5a37c73c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 train: 100%|██████████| 180/180 [00:07<00:00, 24.35batch/s, loss=9.47, sub_class_accuracy=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train Sub Class loss: 9.045067670163315 Sub Class acc: 0.029801324009895325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 val: 100%|██████████| 23/23 [00:00<00:00, 34.65batch/s, loss=8.83, sub_class_accuracy=0.0333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 val Sub Class loss: 8.577811056651601 Sub Class acc: 0.06403269618749619\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 train: 100%|██████████| 180/180 [00:07<00:00, 24.08batch/s, loss=8.79, sub_class_accuracy=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train Sub Class loss: 8.3459862708713 Sub Class acc: 0.07145346701145172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 val: 100%|██████████| 23/23 [00:00<00:00, 32.03batch/s, loss=8.59, sub_class_accuracy=0.0667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 val Sub Class loss: 8.125049461136072 Sub Class acc: 0.10490462929010391\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 train: 100%|██████████| 180/180 [00:07<00:00, 24.17batch/s, loss=7.69, sub_class_accuracy=0.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train Sub Class loss: 7.931267695129437 Sub Class acc: 0.11293133348226547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 val: 100%|██████████| 23/23 [00:00<00:00, 34.53batch/s, loss=8.44, sub_class_accuracy=0.0333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 val Sub Class loss: 7.815843569160482 Sub Class acc: 0.12261579930782318\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 train: 100%|██████████| 180/180 [00:08<00:00, 20.74batch/s, loss=7.78, sub_class_accuracy=0.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train Sub Class loss: 7.555991061268139 Sub Class acc: 0.14360404014587402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 val: 100%|██████████| 23/23 [00:00<00:00, 33.47batch/s, loss=8.43, sub_class_accuracy=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 val Sub Class loss: 7.585698720219999 Sub Class acc: 0.13760218024253845\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 train: 100%|██████████| 180/180 [00:07<00:00, 24.12batch/s, loss=7.7, sub_class_accuracy=0.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train Sub Class loss: 7.304360453531525 Sub Class acc: 0.1624259352684021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 val: 100%|██████████| 23/23 [00:00<00:00, 31.17batch/s, loss=8.31, sub_class_accuracy=0.0333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 val Sub Class loss: 7.410756386593187 Sub Class acc: 0.14032697677612305\n",
            "--------------------\n",
            "Best Sub Class val acc: 0.14032697677612305\n",
            "Average Time taken for an epoch: 8.645339488983154 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "initial_epoch = 0\n",
        "learning_rate = 1e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    baseline_sub_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Baseline_SwinT_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQuPdGAfgW7K"
      },
      "source": [
        "###### Unfreeze some layers of the backbone network (phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkvG6UcAgW7K",
        "outputId": "b1b82086-a6f3-437c-8d27-8850f8b247ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,920,633\n",
            "Trainable params: 4,793,945\n",
            "Non-trainable params: 14,126,688\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.18\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with some backbone frozen)\n",
        "for param in baseline_sub_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in baseline_sub_model.backbone.features[:8].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for idx, (name, param) in enumerate(baseline_sub_model.backbone.features[7].named_parameters()):\n",
        "    #print(name, idx)\n",
        "    if idx > 15:\n",
        "        param.requires_grad = True\n",
        "\n",
        "summary(baseline_sub_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in baseline_sub_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM-tIv_LgW7K",
        "outputId": "8d21acaf-4937-4423-c5d6-0d72c6d7fc3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 train: 100%|██████████| 180/180 [00:08<00:00, 21.03batch/s, loss=5.53, sub_class_accuracy=0.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train Sub Class loss: 6.950139871413136 Sub Class acc: 0.17148831486701965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 val: 100%|██████████| 23/23 [00:00<00:00, 34.53batch/s, loss=8.4, sub_class_accuracy=0.0333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 val Sub Class loss: 6.824393636199369 Sub Class acc: 0.17711171507835388\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 train: 100%|██████████| 180/180 [00:08<00:00, 21.19batch/s, loss=7.59, sub_class_accuracy=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train Sub Class loss: 6.034075055566138 Sub Class acc: 0.2476472556591034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 val: 100%|██████████| 23/23 [00:00<00:00, 30.91batch/s, loss=8.16, sub_class_accuracy=0.0667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 val Sub Class loss: 6.667068218989983 Sub Class acc: 0.18528610467910767\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 train: 100%|██████████| 180/180 [00:08<00:00, 20.56batch/s, loss=5.79, sub_class_accuracy=0.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train Sub Class loss: 5.346681682936362 Sub Class acc: 0.32154059410095215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 val: 100%|██████████| 23/23 [00:00<00:00, 30.99batch/s, loss=8.57, sub_class_accuracy=0.0333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 val Sub Class loss: 6.762468301632748 Sub Class acc: 0.19073569774627686\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 train: 100%|██████████| 180/180 [00:08<00:00, 20.51batch/s, loss=5.74, sub_class_accuracy=0.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 train Sub Class loss: 4.707395521345434 Sub Class acc: 0.38062041997909546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 val: 100%|██████████| 23/23 [00:00<00:00, 33.65batch/s, loss=9.15, sub_class_accuracy=0.0333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 val Sub Class loss: 7.032096171573982 Sub Class acc: 0.18119890987873077\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 train: 100%|██████████| 180/180 [00:08<00:00, 21.40batch/s, loss=3.61, sub_class_accuracy=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 train Sub Class loss: 4.228890012306966 Sub Class acc: 0.4390031397342682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 val: 100%|██████████| 23/23 [00:00<00:00, 31.82batch/s, loss=9.34, sub_class_accuracy=0.0333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 val Sub Class loss: 7.232087569275734 Sub Class acc: 0.19754767417907715\n",
            "--------------------\n",
            "Best Sub Class val acc: 0.19754767417907715\n",
            "Average Time taken for an epoch: 9.522721242904662 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "initial_epoch = 5\n",
        "learning_rate = 3e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    baseline_sub_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Baseline_SwinT_semi_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfEPjLV4gW7K"
      },
      "source": [
        "###### Unfreeze all the layers in the network (phase 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cELRYbHlgW7K",
        "outputId": "ad43b4e7-3a61-42d9-870b-ba0aebc7748a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,920,633\n",
            "Trainable params: 18,920,633\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.18\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with everything unfrozen)\n",
        "for param in baseline_sub_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "summary(baseline_sub_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in baseline_sub_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBjRJcvFgW7L",
        "outputId": "e9d16c4d-bd12-4478-b669-1c0ac08d3111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 train: 100%|██████████| 180/180 [00:15<00:00, 11.94batch/s, loss=6.81, sub_class_accuracy=0.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 train Sub Class loss: 5.662336003119707 Sub Class acc: 0.26368072628974915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 val: 100%|██████████| 23/23 [00:00<00:00, 33.00batch/s, loss=6.62, sub_class_accuracy=0.167]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 val Sub Class loss: 6.1117013338801 Sub Class acc: 0.20572206377983093\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 train: 100%|██████████| 180/180 [00:15<00:00, 11.72batch/s, loss=4.99, sub_class_accuracy=0.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 train Sub Class loss: 4.613216345798017 Sub Class acc: 0.3708609342575073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 val: 100%|██████████| 23/23 [00:00<00:00, 32.02batch/s, loss=6.75, sub_class_accuracy=0.167]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 val Sub Class loss: 5.982834123460734 Sub Class acc: 0.24386920034885406\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 train: 100%|██████████| 180/180 [00:15<00:00, 11.53batch/s, loss=3.78, sub_class_accuracy=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 train Sub Class loss: 3.9517699715649885 Sub Class acc: 0.4428372085094452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 val: 100%|██████████| 23/23 [00:00<00:00, 31.55batch/s, loss=6.67, sub_class_accuracy=0.167]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 val Sub Class loss: 6.0940348926616945 Sub Class acc: 0.24386920034885406\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 train: 100%|██████████| 180/180 [00:16<00:00, 10.94batch/s, loss=4.59, sub_class_accuracy=0.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 train Sub Class loss: 3.2953145438347513 Sub Class acc: 0.5231788158416748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 val: 100%|██████████| 23/23 [00:00<00:00, 32.06batch/s, loss=7.76, sub_class_accuracy=0.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 val Sub Class loss: 6.214816128525487 Sub Class acc: 0.25476840138435364\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 train: 100%|██████████| 180/180 [00:15<00:00, 11.74batch/s, loss=4.75, sub_class_accuracy=0.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 train Sub Class loss: 2.7633775735657653 Sub Class acc: 0.5930637717247009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 val: 100%|██████████| 23/23 [00:00<00:00, 32.21batch/s, loss=7.35, sub_class_accuracy=0.267]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 val Sub Class loss: 6.246788479651677 Sub Class acc: 0.2643051743507385\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 train: 100%|██████████| 180/180 [00:15<00:00, 11.72batch/s, loss=2.07, sub_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 train Sub Class loss: 2.244989477246013 Sub Class acc: 0.6707912087440491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 val: 100%|██████████| 23/23 [00:00<00:00, 31.62batch/s, loss=7.69, sub_class_accuracy=0.267]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 val Sub Class loss: 6.846289690573793 Sub Class acc: 0.2806539535522461\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 train: 100%|██████████| 180/180 [00:15<00:00, 11.50batch/s, loss=1.32, sub_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 train Sub Class loss: 1.9519951399629978 Sub Class acc: 0.707563579082489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 val: 100%|██████████| 23/23 [00:00<00:00, 32.68batch/s, loss=8.96, sub_class_accuracy=0.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 val Sub Class loss: 7.678999864437924 Sub Class acc: 0.23433242738246918\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 train: 100%|██████████| 180/180 [00:15<00:00, 11.71batch/s, loss=1.27, sub_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 train Sub Class loss: 1.7411795473963012 Sub Class acc: 0.7295224666595459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 val: 100%|██████████| 23/23 [00:00<00:00, 31.28batch/s, loss=8.15, sub_class_accuracy=0.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 val Sub Class loss: 7.421948944840184 Sub Class acc: 0.24795639514923096\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 train: 100%|██████████| 180/180 [00:15<00:00, 11.54batch/s, loss=0.132, sub_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 train Sub Class loss: 1.3825934658475603 Sub Class acc: 0.7908678650856018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 val: 100%|██████████| 23/23 [00:00<00:00, 31.82batch/s, loss=8.69, sub_class_accuracy=0.233]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 val Sub Class loss: 8.049755163998306 Sub Class acc: 0.25068119168281555\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 train: 100%|██████████| 180/180 [00:15<00:00, 11.51batch/s, loss=2.4, sub_class_accuracy=0.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 train Sub Class loss: 1.2546675747053346 Sub Class acc: 0.8098640441894531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 val: 100%|██████████| 23/23 [00:00<00:00, 31.00batch/s, loss=9.26, sub_class_accuracy=0.333]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 val Sub Class loss: 8.47159391398001 Sub Class acc: 0.25476840138435364\n",
            "--------------------\n",
            "Best Sub Class val acc: 0.2806539535522461\n",
            "Average Time taken for an epoch: 16.404507565498353 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "initial_epoch = 10\n",
        "learning_rate = 3e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    baseline_sub_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Baseline_SwinT_unfrozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI8EiIEelBk0"
      },
      "source": [
        "### Baseline Joint Super Sub Class Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAucHCRNlR_F"
      },
      "source": [
        "##### Joint training utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Cjq-dHw4lR_F"
      },
      "outputs": [],
      "source": [
        "# Will contain utility functions used for training the model\n",
        "import torch\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "#Training Function\n",
        "def fit_classifier(model, train_loader, val_loader, optimizer, loss_func, epochs=10, initial_epoch=0, device='cpu', name='effnetb6'):\n",
        "    '''\n",
        "    function to train a classifier model.\n",
        "    args:\n",
        "        model - the model to be trained\n",
        "        train_loader - Dataloader() for train set\n",
        "        val_loader - Dataloader() for val set\n",
        "        optimizer - optimization algorithm for updating weights\n",
        "        loss_func - loss function to be used\n",
        "    \n",
        "    keyword args:\n",
        "        epochs - Number of training epochs (default=10)\n",
        "        initial_epoch - The starting epoch\n",
        "        device - the device for training (default='cpu')\n",
        "        name - Name for saving the model\n",
        "    \n",
        "    returns: Nothing\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    model = model.to(device, non_blocking=True)\n",
        "    \n",
        "    # Save the models based on the super and sub class validation accuracies\n",
        "    best_super_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    best_sub_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    \n",
        "    #create the logger object\n",
        "    writer = SummaryWriter()\n",
        "    start_time = time.time()\n",
        "    \n",
        "    #Iterate epochs\n",
        "    for epoch in range(initial_epoch, initial_epoch + epochs):\n",
        "        #Each epoch has a training phase and validation phase\n",
        "        for phase in ['train','val']:\n",
        "            data_loader = None\n",
        "            if phase == 'train':\n",
        "                #Set train mode\n",
        "                model.train()\n",
        "                data_loader = train_loader\n",
        "            else:\n",
        "                #Set Eval mode\n",
        "                model.eval()\n",
        "                data_loader = val_loader\n",
        "          \n",
        "            running_super_loss = 0.\n",
        "            running_sub_loss = 0.\n",
        "            running_super_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            running_sub_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            \n",
        "            #tqdm for observing the progress\n",
        "            with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
        "                #Iterate batches\n",
        "                for itr, (images, super_labels, sub_labels) in enumerate(tepoch):\n",
        "                    tepoch.set_description(f\"Epoch {(epoch)} {phase}\")\n",
        "                    images = images.to(device, non_blocking=True)\n",
        "\n",
        "                    super_labels = super_labels.long().to(device, non_blocking=True)\n",
        "                    sub_labels = sub_labels.long().to(device, non_blocking=True)\n",
        "                    \n",
        "                    optimizer.zero_grad()\n",
        "                    \n",
        "                    #Set gradient calculation only for training phase\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        super_outputs, sub_outputs = model(images)\n",
        "\n",
        "                        super_loss = loss_func(super_outputs, super_labels)\n",
        "                        sub_loss = loss_func(sub_outputs, sub_labels)\n",
        "\n",
        "                        super_preds = torch.argmax(super_outputs, dim=1)\n",
        "                        sub_preds = torch.argmax(sub_outputs, dim=1)\n",
        "\n",
        "                        loss = 5 * super_loss + 2 * sub_loss\n",
        "                        \n",
        "                        #Do backprop only during training\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                    \n",
        "                    running_super_loss += 5 * super_loss.item() * images.size(0)\n",
        "                    running_sub_loss += 2 * sub_loss.item() * images.size(0)\n",
        "                    running_super_corrects += torch.sum(super_preds == super_labels)\n",
        "                    running_sub_corrects += torch.sum(sub_preds == sub_labels)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        writer.add_scalar(\"Batch_Loss/\" + phase, loss.item(), epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Super_Class/\" + phase,\n",
        "                                          (torch.sum(super_preds == super_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Sub_Class/\" + phase,\n",
        "                                          (torch.sum(sub_preds == sub_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                    \n",
        "                    tepoch.set_postfix(loss=loss.item(),\n",
        "                              super_class_accuracy=(torch.sum(super_preds == super_labels)/(images.shape[0])).item(),\n",
        "                              sub_class_accuracy=(torch.sum(sub_preds == sub_labels)/(images.shape[0])).item())\n",
        "                \n",
        "                epoch_super_loss = running_super_loss / len(data_loader.dataset)\n",
        "                epoch_sub_loss = running_sub_loss / len(data_loader.dataset)\n",
        "                epoch_super_acc = running_super_corrects.float() / (len(data_loader.dataset))\n",
        "                epoch_sub_acc = running_sub_corrects.float() / (len(data_loader.dataset))\n",
        "\n",
        "                print(f\"Epoch {(epoch)} {phase} Super Class loss: {epoch_super_loss} Super Class acc: {epoch_super_acc.item()}\")\n",
        "                print(f\"Sub Class loss: {epoch_sub_loss} Sub Class acc: {epoch_sub_acc.item()}\")\n",
        "\n",
        "                writer.add_scalar(\"Epoch_Loss_Super_Class/\" + phase, epoch_super_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Loss_Sub_Class/\" + phase, epoch_sub_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Super_Class/\" + phase, epoch_super_acc, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Sub_Class/\" + phase, epoch_sub_acc, epoch)\n",
        "                \n",
        "                # #Saving best model based on super class accuracy\n",
        "                if phase == 'val' and epoch_super_acc > best_super_acc:\n",
        "                    best_super_acc = epoch_super_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SuperClass.pth\")\n",
        "\n",
        "                #Saving best model based on sub class accuracy\n",
        "                if phase == 'val' and epoch_sub_acc > best_sub_acc:\n",
        "                    best_sub_acc = epoch_sub_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SubClass.pth\")    \n",
        "                \n",
        "        print('-'*20)\n",
        "    \n",
        "    #End of Training \n",
        "    end_time = time.time()  \n",
        "    writer.close()\n",
        "    print('Best Super Class val acc: {}'.format(best_super_acc.item()))\n",
        "    print('Best Sub Class val acc: {}'.format(best_sub_acc.item()))\n",
        "    print(f\"Average Time taken for an epoch: {(end_time - start_time)/epochs} sec\")\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJr43jtTlR_F"
      },
      "source": [
        "##### Create the Joint model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JX3emNc6lR_F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# Load the Swin Transformer model trained on ImageNet\n",
        "backbone_model = torchvision.models.swin_t(weights='IMAGENET1K_V1')\n",
        "backbone_model.head = nn.Identity()\n",
        "\n",
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self, backbone) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        # 3 super classes and 89 sub classes\n",
        "        self.superclass = nn.Linear(in_features = 768, out_features = 3)\n",
        "        self.subclass = nn.Linear(in_features = 768, out_features = 89)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.backbone(x)\n",
        "        super_class_out = self.superclass(out)\n",
        "        sub_class_out = self.subclass(out)\n",
        "        return super_class_out, sub_class_out\n",
        "\n",
        "# Create the baseline model\n",
        "baseline_model = BaselineModel(backbone_model)\n",
        "baseline_model = baseline_model.to(device, non_blocking = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1sIjZN6lR_F"
      },
      "source": [
        "##### Train the Joint model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIZBvNR1lR_F"
      },
      "source": [
        "###### Freeze all the layers except Classifier layers (phase 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRdweO3plR_G",
        "outputId": "b20851ab-ad06-4aaf-d62b-a6dee41eb229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "          Linear-152                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,922,940\n",
            "Trainable params: 70,748\n",
            "Non-trainable params: 18,852,192\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.19\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n",
            "27590102\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with all backbone frozen)\n",
        "for param in baseline_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in baseline_model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(baseline_model, (3, 64, 64))\n",
        "\n",
        "# Check number of parameters\n",
        "pytorch_total_params = sum(p.numel() for p in baseline_model.parameters())\n",
        "print(pytorch_total_params)\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in baseline_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi9OlVeElR_G",
        "outputId": "e9426d67-e5d7-4c98-92a9-d55b906678d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 train: 100%|██████████| 180/180 [00:08<00:00, 20.50batch/s, loss=13, sub_class_accuracy=0, super_class_accuracy=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train Super Class loss: 5.328964847187083 Super Class acc: 0.4726385474205017\n",
            "Sub Class loss: 9.036592568616578 Sub Class acc: 0.029452770948410034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 val: 100%|██████████| 23/23 [00:00<00:00, 28.04batch/s, loss=13.5, sub_class_accuracy=0.0333, super_class_accuracy=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 val Super Class loss: 4.462522807498069 Super Class acc: 0.5762942433357239\n",
            "Sub Class loss: 8.532650825438123 Sub Class acc: 0.06811989098787308\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 train: 100%|██████████| 180/180 [00:08<00:00, 20.85batch/s, loss=11.9, sub_class_accuracy=0, super_class_accuracy=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train Super Class loss: 4.253886572759548 Super Class acc: 0.6214708685874939\n",
            "Sub Class loss: 8.33917418852547 Sub Class acc: 0.07790170609951019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 val: 100%|██████████| 23/23 [00:00<00:00, 30.00batch/s, loss=12.8, sub_class_accuracy=0.0333, super_class_accuracy=0.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 val Super Class loss: 3.9085906419182344 Super Class acc: 0.6594005227088928\n",
            "Sub Class loss: 8.069492178976699 Sub Class acc: 0.09809264540672302\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 train: 100%|██████████| 180/180 [00:09<00:00, 18.33batch/s, loss=11.1, sub_class_accuracy=0, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train Super Class loss: 3.8419159487507906 Super Class acc: 0.6760194897651672\n",
            "Sub Class loss: 7.90146464144739 Sub Class acc: 0.11258278042078018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 val: 100%|██████████| 23/23 [00:00<00:00, 28.80batch/s, loss=12.5, sub_class_accuracy=0.0333, super_class_accuracy=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 val Super Class loss: 3.64877019737332 Super Class acc: 0.6880108714103699\n",
            "Sub Class loss: 7.7642061301083265 Sub Class acc: 0.12534059584140778\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 train: 100%|██████████| 180/180 [00:08<00:00, 21.05batch/s, loss=11, sub_class_accuracy=0.1, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train Super Class loss: 3.62490751864645 Super Class acc: 0.6950156688690186\n",
            "Sub Class loss: 7.514234652540832 Sub Class acc: 0.14203554391860962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 val: 100%|██████████| 23/23 [00:00<00:00, 28.96batch/s, loss=12.3, sub_class_accuracy=0.0333, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 val Super Class loss: 3.468185738744138 Super Class acc: 0.7057220339775085\n",
            "Sub Class loss: 7.535686916486444 Sub Class acc: 0.13351498544216156\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 train: 100%|██████████| 180/180 [00:08<00:00, 21.37batch/s, loss=10.8, sub_class_accuracy=0.1, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train Super Class loss: 3.4910838097676704 Super Class acc: 0.719240128993988\n",
            "Sub Class loss: 7.26467843153785 Sub Class acc: 0.1646915227174759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 val: 100%|██████████| 23/23 [00:00<00:00, 30.01batch/s, loss=12.2, sub_class_accuracy=0.0333, super_class_accuracy=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 val Super Class loss: 3.3744200406347375 Super Class acc: 0.7193460464477539\n",
            "Sub Class loss: 7.366533035153589 Sub Class acc: 0.13487738370895386\n",
            "--------------------\n",
            "Best Super Class val acc: 0.7193460464477539\n",
            "Best Sub Class val acc: 0.13487738370895386\n",
            "Average Time taken for an epoch: 10.185715055465698 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "initial_epoch = 0\n",
        "learning_rate = 1e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    baseline_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Baseline_Joint_SwinT_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGZ4csVxlR_G"
      },
      "source": [
        "###### Unfreeze some layers of the backbone network (phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtD1BgHqlR_G",
        "outputId": "169cf6f5-6d91-4d72-e99c-628de3e4388d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "          Linear-152                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,922,940\n",
            "Trainable params: 4,796,252\n",
            "Non-trainable params: 14,126,688\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.19\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with some backbone frozen)\n",
        "for param in baseline_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in baseline_model.backbone.features[:8].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for idx, (name, param) in enumerate(baseline_model.backbone.features[7].named_parameters()):\n",
        "    #print(name, idx)\n",
        "    if idx > 15:\n",
        "        param.requires_grad = True\n",
        "\n",
        "summary(baseline_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in baseline_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12qcDVZdlR_G",
        "outputId": "f77ce852-b6fa-435a-f094-7b874b2d8093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 train: 100%|██████████| 180/180 [00:09<00:00, 18.95batch/s, loss=6.58, sub_class_accuracy=0.4, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train Super Class loss: 3.3434295273587527 Super Class acc: 0.727605402469635\n",
            "Sub Class loss: 6.895415291299218 Sub Class acc: 0.1751481294631958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 val: 100%|██████████| 23/23 [00:00<00:00, 29.31batch/s, loss=10.9, sub_class_accuracy=0.0333, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 val Super Class loss: 2.91723047598831 Super Class acc: 0.7629427909851074\n",
            "Sub Class loss: 6.869902491244698 Sub Class acc: 0.1689373254776001\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 train: 100%|██████████| 180/180 [00:09<00:00, 19.98batch/s, loss=14.6, sub_class_accuracy=0.3, super_class_accuracy=0.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train Super Class loss: 2.9602571427510482 Super Class acc: 0.763332188129425\n",
            "Sub Class loss: 6.1732687466482785 Sub Class acc: 0.23893342912197113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 val: 100%|██████████| 23/23 [00:00<00:00, 30.53batch/s, loss=11.8, sub_class_accuracy=0.0667, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 val Super Class loss: 2.808729399614828 Super Class acc: 0.7806539535522461\n",
            "Sub Class loss: 6.623563774275195 Sub Class acc: 0.18801090121269226\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 train: 100%|██████████| 180/180 [00:09<00:00, 18.16batch/s, loss=9.75, sub_class_accuracy=0.4, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train Super Class loss: 2.770463666482934 Super Class acc: 0.7791913151741028\n",
            "Sub Class loss: 5.625134327138247 Sub Class acc: 0.28494247794151306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 val: 100%|██████████| 23/23 [00:00<00:00, 28.18batch/s, loss=10.9, sub_class_accuracy=0.0333, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 val Super Class loss: 2.97183755632967 Super Class acc: 0.7806539535522461\n",
            "Sub Class loss: 6.515550616001888 Sub Class acc: 0.19891007244586945\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 train: 100%|██████████| 180/180 [00:10<00:00, 17.75batch/s, loss=7.65, sub_class_accuracy=0.2, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 train Super Class loss: 2.557134427553521 Super Class acc: 0.8006274104118347\n",
            "Sub Class loss: 5.189878377319421 Sub Class acc: 0.32624608278274536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 val: 100%|██████████| 23/23 [00:00<00:00, 28.30batch/s, loss=11.7, sub_class_accuracy=0.0333, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 val Super Class loss: 2.955287161412616 Super Class acc: 0.7956402897834778\n",
            "Sub Class loss: 6.616044145838766 Sub Class acc: 0.19754767417907715\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 train: 100%|██████████| 180/180 [00:09<00:00, 19.40batch/s, loss=7.88, sub_class_accuracy=0.1, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 train Super Class loss: 2.458311077109942 Super Class acc: 0.811781108379364\n",
            "Sub Class loss: 4.80726651191379 Sub Class acc: 0.376437783241272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 val: 100%|██████████| 23/23 [00:00<00:00, 31.37batch/s, loss=10.4, sub_class_accuracy=0.0333, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 val Super Class loss: 2.968092195750582 Super Class acc: 0.7806539535522461\n",
            "Sub Class loss: 6.6192652652958754 Sub Class acc: 0.19073569774627686\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 train: 100%|██████████| 180/180 [00:09<00:00, 19.86batch/s, loss=5.32, sub_class_accuracy=0.2, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 train Super Class loss: 2.20613604131664 Super Class acc: 0.8264203667640686\n",
            "Sub Class loss: 4.415617847575589 Sub Class acc: 0.41338443756103516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 val: 100%|██████████| 23/23 [00:00<00:00, 29.67batch/s, loss=11.3, sub_class_accuracy=0.0667, super_class_accuracy=0.7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 val Super Class loss: 3.020709701877199 Super Class acc: 0.776566743850708\n",
            "Sub Class loss: 6.720046248682838 Sub Class acc: 0.18664850294589996\n",
            "--------------------\n",
            "Best Super Class val acc: 0.7956402897834778\n",
            "Best Sub Class val acc: 0.19891007244586945\n",
            "Average Time taken for an epoch: 10.56770900885264 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 6\n",
        "initial_epoch = 5\n",
        "learning_rate = 3e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    baseline_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Baseline_Joint_SwinT_semi_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaZLlv9olR_G"
      },
      "source": [
        "###### Unfreeze all the layers in the network (phase 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ5KT7q1lR_G",
        "outputId": "f902e450-9c64-40a2-abc2-e49f6f83da49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "          Linear-152                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,922,940\n",
            "Trainable params: 18,922,940\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.19\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with everything unfrozen)\n",
        "for param in baseline_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "summary(baseline_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in baseline_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjsrCTpBlR_G",
        "outputId": "736fc273-5c46-49d3-f898-4b6e19253c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 train: 100%|██████████| 180/180 [00:17<00:00, 10.46batch/s, loss=9.01, sub_class_accuracy=0, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 train Super Class loss: 2.834274049376976 Super Class acc: 0.7786685228347778\n",
            "Sub Class loss: 6.040963886755607 Sub Class acc: 0.22586266696453094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 val: 100%|██████████| 23/23 [00:00<00:00, 29.07batch/s, loss=9.3, sub_class_accuracy=0.0333, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 val Super Class loss: 2.601215904350177 Super Class acc: 0.7901906967163086\n",
            "Sub Class loss: 6.093281213204283 Sub Class acc: 0.21253405511379242\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 train: 100%|██████████| 180/180 [00:17<00:00, 10.39batch/s, loss=4.79, sub_class_accuracy=0.5, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 train Super Class loss: 2.1260942441322697 Super Class acc: 0.8398396372795105\n",
            "Sub Class loss: 5.249378168113392 Sub Class acc: 0.29644474387168884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 val: 100%|██████████| 23/23 [00:00<00:00, 28.55batch/s, loss=7.42, sub_class_accuracy=0.133, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 val Super Class loss: 1.8738608090689137 Super Class acc: 0.859673023223877\n",
            "Sub Class loss: 5.702678091844356 Sub Class acc: 0.24114440381526947\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 train: 100%|██████████| 180/180 [00:18<00:00,  9.80batch/s, loss=5.63, sub_class_accuracy=0.5, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 train Super Class loss: 1.7497503183036782 Super Class acc: 0.8661554455757141\n",
            "Sub Class loss: 4.660722582628603 Sub Class acc: 0.3579644560813904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 val: 100%|██████████| 23/23 [00:00<00:00, 28.94batch/s, loss=9.22, sub_class_accuracy=0.167, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 val Super Class loss: 2.2679681523781707 Super Class acc: 0.8365122675895691\n",
            "Sub Class loss: 5.797773960175891 Sub Class acc: 0.23024523258209229\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 train: 100%|██████████| 180/180 [00:17<00:00, 10.35batch/s, loss=7.15, sub_class_accuracy=0.1, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 train Super Class loss: 1.4427884901575445 Super Class acc: 0.891251266002655\n",
            "Sub Class loss: 4.167213091745572 Sub Class acc: 0.39909374713897705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 val: 100%|██████████| 23/23 [00:00<00:00, 27.93batch/s, loss=8.64, sub_class_accuracy=0.167, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 val Super Class loss: 2.1227439470609464 Super Class acc: 0.8365122675895691\n",
            "Sub Class loss: 5.696847876670899 Sub Class acc: 0.25749319791793823\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 train: 100%|██████████| 180/180 [00:17<00:00, 10.48batch/s, loss=3.75, sub_class_accuracy=0.5, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 train Super Class loss: 1.2665798454313337 Super Class acc: 0.9060648083686829\n",
            "Sub Class loss: 3.81296347026087 Sub Class acc: 0.43917739391326904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 val: 100%|██████████| 23/23 [00:00<00:00, 31.28batch/s, loss=7.85, sub_class_accuracy=0.267, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 val Super Class loss: 2.1501453233025054 Super Class acc: 0.8501362204551697\n",
            "Sub Class loss: 5.95773287625014 Sub Class acc: 0.25885558128356934\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 train: 100%|██████████| 180/180 [00:16<00:00, 11.11batch/s, loss=6.86, sub_class_accuracy=0.4, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 train Super Class loss: 1.0474347083482978 Super Class acc: 0.9205297827720642\n",
            "Sub Class loss: 3.368991556795851 Sub Class acc: 0.49128615856170654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 val: 100%|██████████| 23/23 [00:00<00:00, 29.25batch/s, loss=7.88, sub_class_accuracy=0.267, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 val Super Class loss: 2.6425620166417363 Super Class acc: 0.8419618606567383\n",
            "Sub Class loss: 6.239957571679305 Sub Class acc: 0.2888283431529999\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 train: 100%|██████████| 180/180 [00:16<00:00, 10.63batch/s, loss=3.1, sub_class_accuracy=0.4, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 train Super Class loss: 0.9606047995121024 Super Class acc: 0.9292436242103577\n",
            "Sub Class loss: 3.08758310891062 Sub Class acc: 0.5390380024909973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 val: 100%|██████████| 23/23 [00:00<00:00, 27.77batch/s, loss=9.02, sub_class_accuracy=0.133, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 val Super Class loss: 2.330903110452179 Super Class acc: 0.8514986038208008\n",
            "Sub Class loss: 6.234845160138704 Sub Class acc: 0.25885558128356934\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 train: 100%|██████████| 180/180 [00:16<00:00, 10.79batch/s, loss=5.25, sub_class_accuracy=0.4, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 train Super Class loss: 0.8057861868649171 Super Class acc: 0.9384803175926208\n",
            "Sub Class loss: 2.785620877783487 Sub Class acc: 0.5698849558830261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 val: 100%|██████████| 23/23 [00:00<00:00, 30.53batch/s, loss=9.56, sub_class_accuracy=0.333, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 val Super Class loss: 2.2540313127255245 Super Class acc: 0.8610354065895081\n",
            "Sub Class loss: 6.207986328842205 Sub Class acc: 0.26294276118278503\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 train: 100%|██████████| 180/180 [00:16<00:00, 11.17batch/s, loss=2.14, sub_class_accuracy=0.8, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 train Super Class loss: 0.6989779344893948 Super Class acc: 0.9491111636161804\n",
            "Sub Class loss: 2.4844378452759748 Sub Class acc: 0.6146740913391113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 val: 100%|██████████| 23/23 [00:00<00:00, 32.00batch/s, loss=9.06, sub_class_accuracy=0.267, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 val Super Class loss: 2.3904783638036866 Super Class acc: 0.8623977899551392\n",
            "Sub Class loss: 6.5567423810101335 Sub Class acc: 0.26566755771636963\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 train: 100%|██████████| 180/180 [00:16<00:00, 10.96batch/s, loss=2.78, sub_class_accuracy=0.7, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 train Super Class loss: 0.6209772618006397 Super Class acc: 0.955907940864563\n",
            "Sub Class loss: 2.2234037394887607 Sub Class acc: 0.6610317230224609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 val: 100%|██████████| 23/23 [00:00<00:00, 30.38batch/s, loss=9.91, sub_class_accuracy=0.167, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 val Super Class loss: 2.3245637947109805 Super Class acc: 0.8692098259925842\n",
            "Sub Class loss: 6.543633211536044 Sub Class acc: 0.25749319791793823\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 train: 100%|██████████| 180/180 [00:18<00:00,  9.86batch/s, loss=2.52, sub_class_accuracy=0.7, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 train Super Class loss: 0.666134306643536 Super Class acc: 0.9508539438247681\n",
            "Sub Class loss: 2.0486428236537546 Sub Class acc: 0.6821191906929016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 val: 100%|██████████| 23/23 [00:00<00:00, 28.84batch/s, loss=9.66, sub_class_accuracy=0.233, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 val Super Class loss: 2.174131553569347 Super Class acc: 0.8719345927238464\n",
            "Sub Class loss: 6.656365100954144 Sub Class acc: 0.25340598821640015\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 train: 100%|██████████| 180/180 [00:16<00:00, 10.62batch/s, loss=2.03, sub_class_accuracy=0.7, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 train Super Class loss: 0.47778729074019466 Super Class acc: 0.9658417701721191\n",
            "Sub Class loss: 1.7466034967336725 Sub Class acc: 0.7227256894111633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 val: 100%|██████████| 23/23 [00:00<00:00, 29.69batch/s, loss=10.9, sub_class_accuracy=0.3, super_class_accuracy=0.867]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 val Super Class loss: 2.9451977301196117 Super Class acc: 0.8446866273880005\n",
            "Sub Class loss: 7.255734885421046 Sub Class acc: 0.25749319791793823\n",
            "--------------------\n",
            "Best Super Class val acc: 0.8719345927238464\n",
            "Best Sub Class val acc: 0.2888283431529999\n",
            "Average Time taken for an epoch: 18.133280515670776 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 12\n",
        "initial_epoch = 11\n",
        "learning_rate = 3e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    baseline_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Baseline_Joint_SwinT_unfrozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzdSFPqWYwLW"
      },
      "source": [
        "### Create Augmented Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OICLE4c-Y1QV",
        "outputId": "59f9ef34-3d19-40f3-c9a6-080277f4af65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15833\n",
            "[['' -1 -1]\n",
            " ['hflip_328.jpg' 1 78]\n",
            " ['coarse_328.jpg' 1 78]]\n",
            "15833\n",
            "[['coarse_3687.jpg' 0 27]\n",
            " ['hflip_5626.jpg' 2 62]\n",
            " ['hflip_3644.jpg' 1 21]]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import albumentations as A\n",
        "\n",
        "!rm -rf aug_train_shuffle_32\n",
        "!rm -rf aug_train_shuffle_64\n",
        "\n",
        "size_val = 64\n",
        "\n",
        "# Applying augmentations to the image\n",
        "os.makedirs(f\"aug_train_shuffle_{size_val}\", exist_ok = True)\n",
        "\n",
        "aug_train_data = np.array([[\"\", -1, -1]], dtype=object)\n",
        "\n",
        "for idx in range(len(train_data)):\n",
        "    file = train_data[idx][0]\n",
        "    superclass = train_data[idx][1]\n",
        "    subclass = train_data[idx][2]\n",
        "\n",
        "    img = cv2.imread(os.path.join(f\"train_shuffle_{size_val}\", file), cv2.IMREAD_UNCHANGED)\n",
        "    cv2.imwrite(os.path.join(f\"aug_train_shuffle_{size_val}\", file), img)\n",
        "\n",
        "    hflip_transform = A.Compose([A.HorizontalFlip(p = 1)])\n",
        "    hflip_img = hflip_transform(image = img)['image']\n",
        "    #cv2_imshow(hflip_img)\n",
        "    cv2.imwrite(os.path.join(f\"aug_train_shuffle_{size_val}\", f\"hflip_{file}\"), hflip_img)\n",
        "    aug_train_data = np.vstack((aug_train_data, np.asarray([f\"hflip_{file}\", superclass, subclass], object)))\n",
        "\n",
        "    coarse_transform = A.Compose([A.CoarseDropout(max_holes=8, max_height=4, max_width=4, min_holes=8, min_height=4, min_width=4, p=1)])\n",
        "    coarse_img = coarse_transform(image = img)['image']\n",
        "    #cv2_imshow(coarse_img)\n",
        "    cv2.imwrite(os.path.join(f\"aug_train_shuffle_{size_val}\", f\"coarse_{file}\"), coarse_img)\n",
        "    aug_train_data = np.vstack((aug_train_data, np.asarray([f\"coarse_{file}\", superclass, subclass], object)))\n",
        "\n",
        "    \n",
        "    # Use some more augmentations for lower numbered subclasses\n",
        "    if labels_list[superclass][subclass] < 55:\n",
        "\n",
        "        rot_transform = A.Compose([A.Rotate(limit=(90, 90), interpolation=cv2.INTER_CUBIC, border_mode=cv2.BORDER_CONSTANT, value=0, p=1)])\n",
        "        rot_img = rot_transform(image = img)['image']\n",
        "        #cv2_imshow(rot_img)\n",
        "        cv2.imwrite(os.path.join(f\"aug_train_shuffle_{size_val}\", f\"rot_{file}\"), rot_img)\n",
        "        aug_train_data = np.vstack((aug_train_data, np.asarray([f\"rot_{file}\", superclass, subclass], object)))\n",
        "\n",
        "        trans_transform = A.Compose([A.Affine(translate_percent = (0.05, 0.08), p=1)]) \n",
        "        trans_img = trans_transform(image = img)['image']\n",
        "        #cv2_imshow(trans_img)\n",
        "        cv2.imwrite(os.path.join(f\"aug_train_shuffle_{size_val}\", f\"trans_{file}\"), trans_img)\n",
        "        aug_train_data = np.vstack((aug_train_data, np.asarray([f\"trans_{file}\", superclass, subclass], object)))\n",
        "    \n",
        "\n",
        "    # Other Augmentations that we experimented with but didn't give good results\n",
        "    # vflip_transform = A.Compose([A.VerticalFlip(p = 1)])\n",
        "    # vflip_img = vflip_transform(image = img)['image']\n",
        "    # cv2_imshow(vflip_img)\n",
        "    # cv2.imwrite(os.path.join(f\"aug_train_shuffle_{size_val}\", f\"vflip_{file}\"), vflip_img)\n",
        "    # aug_train_data = np.vstack((aug_train_data, np.asarray([f\"vflip_{file}\", superclass, subclass], object)))\n",
        "\n",
        "    # opt_transform = A.Compose([A.OpticalDistortion(distort_limit=(0.39, 0.40), shift_limit=0.01, interpolation=cv2.INTER_CUBIC, border_mode=cv2.BORDER_CONSTANT, value=0, p=1)])\n",
        "    # opt_img = opt_transform(image = img)['image']\n",
        "    # #cv2_imshow(opt_img)\n",
        "    # cv2.imwrite(os.path.join(f\"aug_train_shuffle_{size_val}\", f\"opt_{file}\"), opt_img)\n",
        "    # aug_train_data = np.vstack((aug_train_data, np.asarray([f\"opt_{file}\", superclass, subclass], object)))\n",
        "\n",
        "    # persp_transform = A.Compose([A.Perspective(scale=(0.085, 0.085), keep_size=True, pad_mode=cv2.BORDER_CONSTANT, pad_val=0, p=1)])\n",
        "    # persp_img = persp_transform(image = img)['image']\n",
        "    # #cv2_imshow(persp_img)\n",
        "    # cv2.imwrite(os.path.join(f\"aug_train_shuffle_{size_val}\", f\"persp_{file}\"), persp_img)\n",
        "    # aug_train_data = np.vstack((aug_train_data, np.asarray([f\"persp_{file}\", superclass, subclass], object)))\n",
        "\n",
        "    # jitt_transform = A.Compose([A.ColorJitter(brightness=(1.16, 1.16), contrast=(1.23, 1.23), saturation=(1.41, 1.41), hue = (0.02, 0.02), p=1)]) \n",
        "    # jitt_img = jitt_transform(image = img)['image']\n",
        "    # #cv2_imshow(jitt_img)\n",
        "    # cv2.imwrite(os.path.join(f\"aug_train_shuffle_{size_val}\", f\"jitt_{file}\"), jitt_img)\n",
        "    # aug_train_data = np.vstack((aug_train_data, np.asarray([f\"jitt_{file}\", superclass, subclass], object)))\n",
        "\n",
        "print(len(aug_train_data))\n",
        "print(aug_train_data[:3])\n",
        "new_files = os.listdir(f\"aug_train_shuffle_{size_val}\")\n",
        "print(len(aug_train_data))\n",
        "\n",
        "train_data = aug_train_data[1:]\n",
        "np.random.shuffle(train_data)\n",
        "print(train_data[:3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Sample images"
      ],
      "metadata": {
        "id": "Bqix9GZ2Kto8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Dd_c46mljwfW",
        "outputId": "14ab2054-a99f-40ea-8036-e4bd19c5a9bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F71E40FE460>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F71E40FE820>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F71E40FE5B0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F71E40FE850>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F71E40FE460>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F71E40FE430>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F71E40FE6A0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAKuUlEQVR4nK1aWXLoOI7MBOl3yz7R/M9Jq2ocZRE5HyAhkJL9qjsawXDIskRiSawy//d//gUAgBb5orxD0sxaa6213ntrzcxISnD3McZ1XdeXjzHGkLtTINnaR2utNX58fPT+y8x672YW980sDv36+vr7778/Pz///PPPv/766/Ov//vjjz8+Pz8/Pz+/vi5JAFprvf3qvf/69StPD7YN/1WK8w6Kw+rP7+j46+tux5/+OwJ8w5YDTjIOO7jJm0963ZbkqyJ6IOQHWQ/KMyQBP6mzPp/gJBlSBT3hesiQrAeMAzwVQv1nZfzwpyp2Xjx1IVGiuwMwM3cH5jUAL3Rwz0L2oM0Ch15flfHNfT4V9rRVXocY0khrRAx4laEKEPEjWG+thUhTgNj0Zwu8/XXeBgCZ1iZxMN75FmCSyBEGDAtc1zXGSDFSNaF3ksberLdCcT926D/ouCrj+cBTzQmh6nwpw8LPvVtaoBrhAGSF0LsA8MKBBEnuco/rqUsCEAm4aKRe0D/PkyikDAf30gjkmBnWJuPy62uMawowhjfYEBpIWuCnmzWym/1aWSjd4N0C9ddX+/DHIJ2vhEG0EB9Hmpkk+dxz5sHrGmP4Nejv6u+L3gX4AUjv90cERAMAOYG5auROk8rBJogcAMRtzzHGuK5xXX7dbhwCtPZBMvnOUuA3AvxWryucYzpxhRA3GSQFn4moFK0KkBao3JsZ2UL3Hx8fvVDGIkkdHlsuxxIhQLgvgivNVQWu+XfCg8By1iKDSTVV3YqIn9eikCHxY9aC15AhqBZjiET2St/Fk9fcm/gGp/KKL4W/3OxOWK07kqYD7OUjVwUZHCeQEk7TAjV3VnaxvA1HUgQpUEYQvGOioQmSCUDNLTa9wOEe8S35zCu/rniALp8n3rpPCFUxCoTe8n8Vhqt4utW8SkAKICgYqPL8vaGsen5NuBH+Q8i41kp5JIG7fEjfrZ7QWovjeotzOZWttea1LH4xmsEodnaiGYwgQRcMAOHysI3T55I7XGQ1yAr2YyFKKdNKwxbctwdV9UcpQfKG0IGfNMQBIcryOUmGzVBpyNwtnd53Wtl3w9I6MJ34J5pOTNoRDSeonIC4+oWavQHANR0gHZ1NilBVIPRQfKH3IjTAXZ04M1elgBDJ/tT9PL7wUQ1Qn9TKteknx27BWOU+S7cqwHF0VX9wX+ufg43OXfsEJXLly6wMsXLtt9wvv5k+LcBFQSv4KAqdMXym3omiKjlthoPYpNFiGRiLQq5gor9Bf2vkntev2bpuU5LAC3hmztoF4OqzDpsn3OvpFXK9oSVP0xFx636jVW1wVfycFagRqweQ6BH7cYkS6aILw2PpGrrcv0Zk4FmVxJIBMIMJDazLhFh0kaKLmDJ0PjLu886h9ZR23XwJYlVPexI4iau9qvn0SdopQ3OnZiFUzyaY2Sr2tbMDnvlBAOi0nG7Y4pih+MX67QuBnFn2yCQMlxmbnZIH32OM2kDPYxbeXmqhpcu7b6qsL6Xe5Vo0K1NPz7p7sfuqfjmT0SMiHTqNtI1V4KTROvXTaIigpMjJsTh7gFqEC4RoAoBQ8r3g0BB8Lg2fFxfkSxEkQK7AVQNOvCK6BI87Jrh84ap/J/TKrBuOter7GgdCH1qvPHLtrvLdGXS2CgcK5v6+emWtOWc+0LOFO19ecWZFF0hw16VREYJsPtBuAcbwa2i4X2N8XePrqhex5HfPzSVEpJrgLhu6u3VYOa5G1dMCfCuNdiNsvUi+UgukZ8FQqrfbrVOjyEb5YVsvc4q8v2Vi30c6egugQTMIOKYtYnIBOJtcwJUWeAqQOwTPErNHq0A9zvU1/AqVZ9itj/WKBO3VQRWgIHsrgAGQUsHlAfFDmBQKD9xb+a1qLW/Gm4fPdJVifVphqwps9gdOODWgkY2VLww4jLMZg0nSGLF89YqZiekyeYN8tR3ETLFwRQ6OXD5vyjFbPPNxH7pZAD9QwaWX0tc3AUjxmrqZf33i56Ct4hJsVr/nsYkllcatyrD5AGoaR/RsN3xfSSsyzINpKUD8zHxcsUoSjmiGjO918gGkMeYApmpkE+B4+a7ddiMUZxiHACSjyKriVaNvxY2dpf+z24q31nFz+lKtij0PxHZY6zYnVuCIhZggxIU0VipIi0czrCENZSyPAB95CJIwBQh2a+NS6+digTOy/dYH7lj0CuI7or8lzgP6FaKIqI+7266tY7d2YOkwexphCoCaieeA0xBNEZcFZiXDXJW5mTVnreWQKNARwQQRWGLRnIjJRbgYS+v4UWRoNAt3kijDNOmsr3x1QshvZKm8RH+mZJVc80rr3Rqhzz4uMWZmkbXr/bTAx+p90w0O567Gnz5gs/JZsyqsOsRDMCs+MNIvKItPAXcrvMomAnJFXUkBssbuckEgBTmVU52AU/1y0dm79cYGQBBBl2N4pIVszdxn8fLtbLTSBmJtd2rmPnLk0tzWcElateIUozpAnaDkK2mQekpSt70fYK7odAFFyyZIE+c5dzDQo31TzIiA8B6K0eWYySnE+O4etgIQcU/Xerf1CSM+h6UAIWcKEM2T3Q3gskCKVTLKhry418D8xpuN2CZ/+XUWmNES4TROClCHPyFAWiCw/swSmwCRDrMtvtMAmCPS0DeFg/Vn7qyKCN3HeNeW1g81wZgWCCMYJ4oK5LZM11pL0CrmQpWJe2ttU+s0S6d9MYKJav5am/AOX0vrtwvZHVhC9yFAQr/3brxZiq2C4/CTLGOT517NMXdHI0i7t/A1/HC/k7+kBrp7nWmQhpwsRXVt2+YhRrWAlW/XvXfDTGSRYWTmZmhNvUcHEvE17XNO5hL9uQvWvwVIajRRZkYXabK7f1hqvsWOWUvUPMl98o0cGB+jW9wZIJ6Zymqtgme4G+lSN96R1I5jMGcFWe0AaLMLkxndPeJ66j7eciKV1HxO4KdGlvqrKYzWLL9gzy8XoYIJecCk/vFxe6jcBBK9isu9tLzNsg8r4bNvweRy0/26XAIshm6r2mYK7gPQZECr5X+pptrsoDs5fWDl4c12+VoDzOzCRuEYkkw34uPdVp/TbZnDCIcnpIJSAAN8/9QQDzRvUszE0gLlxBcLrM66ejzLvDIFOF6sAuS2rwJsFi77k8zPYRlGZyEcAnQ7J3MTswJBLTCQbKRikBj/8QOMKsDqqG/OA+drXsQVHTYdta1GqM9k/NDi3t2T+yAmhCqxZACVriBAVTP5XpAeDd2M+k8BWGxVfXpZ4wzrKtawMj6KBxaESolW3SiskXOJ1MQsY2Z1e5/nJdeui0dhvIMtSynt2MsdwmO9BOv6870aTUm2EP7Yev5q5dctqd25uQqgCqH9UJJwwV4kWYHnnKX2FaVPzqrvTzFmwDRbY3QSitF0iVco/EUxWe+ENCT92WcKvv4rSTs/t9mPCPEP+wE+Ytlvn78v9joX36h/Mirkx6PEfcrwhN9WSlQWf2Rr27ceUyu/+tohwCv3+e50UEVhHKbhQVjOjWqBJxOH1hej59nVVfbK9BbgB61/J0ndP+jI1lOAwwIH3690GPf1gXurhwA16L6e9bRkcm97y4/DAj+z/gohlOr8gBYePvCdLn4+tFrgEEDSmTV+2OuHx75j4pAn675/i+7Zx+N0kmca/o+pJpfnSb+lf/7wEd//HyYij7ZBmhv4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F71E40FE820>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAS+0lEQVR4nI1aa5LzOI5EAiBl184x9zZ7oT1YV1kiCeT+gCS7vu6dGEaFwuWHBIB4JBLE//7Pf5OUa5GkqIjUNUQAUByAmKqqwFRV4CFkWjBnMDMjMjNXMCIiZTGBJgBVKUJySsbiWHMfa845Z6y1xphzrbUymCEEIICqUnGLJIqSR1UBkJQEcH7Bb+k/1Xj/e34vRez3RxTIv1kAShr+P59+vji/+uv+uD/lr/eFJD6e7fUxRAAk//FxJQ0/HvFPsv4h3/Wwv/9KRfS3DkBCTrFY71BEhPUV6imhiPB67xLVTxuUZudN653LNoBcV1UVKACBCsrNkEIRUaWIKEmSWT9PEX3LzdMh71UuUS/Ia0+vT0UkLx1v29f101lOBcpUl60gIgolWc84hVZVVTUHAG0JqRggmJkiyExK1g1IkKBo3vc/ZZFbaFV1d4pkJpgQigj0LVIJlEJSYpFkZvJaIgrA8Q+O8d6HT9vDzMygpqpqLSFCDyaCEaFqay0BASCFGSSyPPa35T53wExEJDJVaPVA9VuOEGamMDNTpFJFZGap8UuB32qoiGRJcj3KzNxcm0PdzNS6mDIthVaZJ3KtNeZU1RVkIIIizAT/tkREVa8YEKWlkFrb4vUuyZkREVyTpCApERFrrVKjxPb7RveqOLljQFXVzMzcHWZuTd3Mu5hCWjD1UsDMoKo6ZUXCRVKYknndlvhw33pupcVIighMxdSsVQyTRKw5K0tn3aEUKB0qaP9UoFLYHdDlqdd2m7XWvFtz860UqB2oO5opKlVjESkSMQcAkfwdeakqIM2QYiQNAkDdVFW0rlhrcRJg5lojRWStNdcx15zHiIiS8M8YAHBaqsrZGbjm7q01a623bq2bN7iVAho0szln5drMXEkTZsLSbvsBqJx+Oa0CUJiIsBKEm5mVAvVOiWRmqhoxy/xjjHEctQOlgMnvBbzrsZhdCnR3N3e73clNaBDmh1iRdHdPhjC0khgBQEWSIgmlVl5HCQoAnwoQdtmUEWpLBKSkMBkr5pjHPsYx5yxp/UNu/Hpdipkp3K2X3KbNvZu7u4up0ISpV3b7cMI7bybAcr8866tSKv2Xq2jtwIcLef08MytCKu1ExIq5Ys41xhhrrXMH7lrDK0OXAlADoOowc29ubtZqN2tzSVZqfD/gCq872V3BmoQLYJYhrKpy7kDhnDNvGwAqMzOZyRUx1xpzHmPsx/G6r2N+KPDhoPJOO6qCKjTNzNTbuQGqIpKZlMgUJlfGMWOtNeccY4wx55xzrhXrAlNQVVeoGclbgUqXpUAKSSbLCU9bHMexX+s4jjHGcRzzXMdaq7KlR4TIuzp+pE6vSunuMC/p62skM2IxM2LG2sca95prrTVWLKZQCTEoVd1UFEJNyKWAkgxBZgYzIgrQRkbZYt/31/798/p+vb73/Wff93rCuta5A3c+KulvKd3dzNybuqu6qkJVgLVWCiM5M2JxrHgds2xTCkTEjEyImgHWu4mau6MZxKiovRWREEZwZchakUlyMW9j//z8fP981/r5+RljfuzvbwXuglLucWcud7dWfu8wZ2JFkpyxVuSINY61j+PagXUcx1zVDhBuSuvtQbI17a1r98IjoiYiWbaPwJKIKcjFNcax1tr3/efn5/V6fX9///XXX6+fn3Ecr5+fy3mG5AKDmVL9QJWtW4daVwEwM4M1AEkRypmM5zrW3F9jH8fPPsYY+z6O41iRwQSgzb03Vd22TVVba9abmcEM5iQTsmaIQjNEz2wzYx3H6zhe+76/Xt+v1+v1+t734zhea62IWeFHkgwRiOSfMXDjrUr25UinzSJJRuSaMcbYx/F6Ha9j/34dx3GMscYYKzKFqupCdbtsId60da/qUXBtMQFwci0t9Bm5Ys1j7MfYX6/vn9f3z8/36/Wz78cYR0SuNSUDmQDvVsc/cvavLPS5A4R+4tjahCvtVGU8FYhkMM1MTD3iA7rJu/wBIpopqqGgoPJ9ZCWFiLXGijnGPsaxYmQGJTJTkEAZU6HKhCBdYRRC5QY8+reVghujf2b9O/ffK/IszG/cKyGS9x+gosJM5ftNMihBBhmZK7O8ZTGXZFACoJpICppqWppkkoQI3MxEBCr/KP3VHf3Zof4dHl9+eHan+OhjTrW58nyyiEjVkojIFbyEjpyZK7kqwVaoAwRYSJcEaZkfCvTe6/FmZq6339+J/xYu8dmLuGkzW+UYERHBiBAlhNfvSGZJv9bCnCICLkJvPxzzmOuo3FLSSy5kGOgQc3goSYVSlCJMUCRDkhSqIN8KVO1qrZ3F67JiYY07U93hfveE7hkRVReDVxC7n+6XWeBC5yKJK6IuBcacx1xHrCWxMsvNcMWMZjYAEQjm1XIrnZlKEnD33kTkRA6qbk3N+bY1bhe5XaWsXt1BMFtU4loAZqxCZtXEVWGJiDlnCrFUVAm5tdpnJYCx1ozT4xMqajDXbesiVAXpdxa5X5Qw7u6lwG3XW+6VYkEiSNydKD768YhozF4xDlNVS88TjOsbOEXMOVcGTAEEmcKK8rHmnCPzBPdmcPfMFdFFUlTNsWYmFxOUqGuG1Gso3b3fAVq8W2kWBCNIEEJiZWa+G/OK+NZaCoOl0jTDjHU24SeplWSuNROUheLYEkJyZZCsJmutlbkKe2/NFQ2Au7QWa9mIJCNT7iuJzCWiIvnuB0SkLF3mB6GqonkqQ5YCZbnf9U7eQWJaLdhiFqVVkoVQlEyIMgQimQIyIgIZkISyuUKdnh6bd1vLIiJim1dG/qxFtwwe6/RwuSiICAIgiKtslALVKxfqiqzMXUwO1cQIqEqw+IzaOoCRs2QnkgSRKVomEkmBqInr2STfvn5WG+ZNpawrod06ICkifvdmIlI6nElTqj0vr30zRZXGUxgZ1dLcWyEiypPeUUow78qdEqxOFUIAF9CGQi+GTgBoAbNTvSQoEYvJFUTEvF2IDK00uu+7/LGQJHm229XymciJ48tVCEmUZ/wJQzIJFMsmWd5EhvAsYAoxVRY/ViQT4Hb1xDi7KRhAQgsfl+gRM4KZqxQ4Y+A4jisAfvFnWfQg3ruhargoFlEkRKgpvHXA7/Whw+kAAgjFxAgTIaDuJ1B1V++t/q0MAVxBn3krsFZGTPINnP17Pz7B3CdAyDgJDwA8mUWvThOmogoN3h2tZAWSIKGUzKq2JCIYDADQkxxVM3N4s9Za770/+7k2N/fWrepgGSsyV8xYGbnWjMhKYOVs8J+fnz8VuMjAzLwVKIhv5t6aaqobzKAU4GzMP3DR5w1rA5JZIwCDATChmbVuvffHs2/P5+PZt23r3ftja6211lShaoAE8+IK5pzxmQZFxH++f8XAHekASoE3cMg0ixVhZpZejgtV6hu6FVHxG3SImZECEKbu2rq3Zuba3bZHezz642t7PPrz+dy23rZe22IGVQdYHfMJs1f+qcC+7zdi++U/lbCuHTAzjXB3qytT6WfE2Vl0pRgeSrHZSq0OiUwTQEVNW7fWrG/uvW2Ptm33X++99c37trVmvTdvatrUTp4iIlbomu+CcCpwB/FnBN9Y4wQ2bibiQGY6mZnGUEZRUaDdGIR3OjKYqIipwlxSHEp1tGb90Vvz/ty2rW9b2x592/r2aH3zajzd1Rzuaqa1b2qiIRrN7F3O3grgg5P7zKa4ZzMf6kUEIRJCRYXvZeaLBiq/gahqeP3WqVAVdbTm5SS+9d57f/TeK2rVDIWeSGZirfLGShJl8gREtapEzQfoa5098R95kBDoRXJdBhapcpyZYERxhDeBfjqUqZqKKYCUJiKqIqZmsKatuffmTb331pr31nvv5iaQXAwuIIkVswJMqwKBkTXNUkFWMwkq9DexhWtuJdXfXA3aWWjK0SEiEkK76Ev54PZw9aXV/hJZwBvlEs1aN+/F9rmZqZu7utdAixEyYl3y8AQD5QUKkQTsGr2ligH0akRIUa1BoApMzbzYuOaqWtn/9CLwBJmZNa9lMd1IKJFOstCRN+v9adUgbe6u3r11s+YAa4uu3T75DjIW7zCNOwcWQ6wGhdVVQCGgv+fE+jnLqB2wd/kqJJdM8oyjk1g/oainppIiqVrp0vrmfXu2Zr5535p3c1f1k0AvXJ25UuSmB/Y5IuZaJ34HaGZqBXvVrKmKWatGC4DzZqeL+NZioa/G+GTmCtIlOJnMZDClQFMKnKo1ojRCzHDz0u7amlWwbo9eCpTJq8aNWGTGWmMex3Ecc9/HmOso/rCC2JoXxOjdW9vM4F5Mh+BzSokr4fwRD6e1MiNjrbqumUGejQy8Rh5GMVGspREz085nFNh2PVk5K+9GJFkwJ4vy3/f9dRyv17Efq1jimZmq4r1mQy2yJZe7J9clKl3VL0isgN0Dmxr0ntM1SDELdcRhzjmKW1VUenH31nyFle/CxKygh3p3M7WlZoSaUEVBxoyMmPscY+xjjON4/by+931/7fuY+z5WxCSpJi16pFM2c7qrqlRjWxnlPeS7i5FcYCYzkShfLCAy5zzmGGMc1aSjFDAztOZ987VWcBSTQxUyRRExQ+YKb9PNqkdlnfUoBeac+1E06P469jH2Y0aZ2QxEqvXWjNKgosbazxNO97ZVdv9wGxGRxVQKFkmuPCcOc879mGOMY80icaksBXpvfZYCTUSCazHWWivntm199L6dGTWFlFgRK8Yx55jHWqsI3eN47eOY8xiRlQxas0Y/x2Qnt0dVMTs3wVtrpcBHJFxIrkov11o559z34xjjOI59rjFGktW5V55tzfqwOY8Z28o54nGscYzX63j0zbevrfd25ntIZqGyNec81hERcx7HcYy5rwtziom7m3dhimSVizO5dW/dTmLLH+0DKUTVhOq0IqKg7DjWWHPfj33f55z7mGOMlVEnfLTu6zKXzdhn9pnHmK8+XvvRt+ej9+4/7m7qMD87/cyMWBGxckbOiHmsozJp2c6awbSsbhCDmEpz3VrrzZp7Va2TFyqPJyUuSrmqySzbj2OMUQq8jmOMdcwREVEUi8Mbtq4rbKVFzpVrztbmfhxb21+tmW/NDOqmF9lFMlkD90iJzDVzFSyoBG8uImmgqqiJOc7y7WjNvSnEBOl+jvZLYCWROW7q7xhrjPGzv47jKAX2seaMY4yIKLLEFjwsU4OWYpRIyYhpy47jqKmsdS8FoGcdLwUKookSYEjWOwDcnQSUqm/RvWlNvLxpa5UwcXKgECNuJlneOeeY+76/9tc5LNzna8w555hzsdodnoNtUairZR2NImnMiNAFM9XhZoCLajXG95SlGh1RQyIvNCV3pJqpmZrDvGoIa7hciU7kxELVATNWXsOLGGONMWvK+XqdCoxjHXPNETNWnEcEBAgoMjWTN3tXThjBFMkEmKqiWcKJoABsMVEsGHa/NoO7ejP3OtUg7qJ68uw1SRAIKVD6RcVdk+oZ9+hl/72OY8wRK/KCKSKQOhdn5lXOipy/hrMwA2oig5qhFAVLkfswCcxVK6/bmdO8mbtXqmlXfwMltKTPyKlBQCXo5yENcq3TbWpkdK8xxpyrZpsRlf+kjg0ANf+yC6u0bevbZtujt+5wAFSHCKk0hzpUoXaeBQRY/q3lHg5crLq7b1t7PLdtqwa/KiwzY61hZiIXLzRGnYiROWdhhXkNri/p533GKDMLmRMiJtakdaum9vHsz+fz+dUej759td69LFrH6qg0gzVTqxpEAGpipmao9ArXmwQoi2yP3nv3Vr2lXB0h1hqkVcT6OJac49Py/jHGmGONozSZNX2P4ngomaIqogKXtmnvtj3s+ezP5/Prvx5fX/3x7I+vXgqolalPBdSrtZBq8sr8nwqIZIHf0yG79d69F32HzBVxtiX1DsmzJ74VqIH4+Dj2UHUxr77xtJ9JRVh/tMdje35tX1+P+nt+9cfX1jfFGzmnmKrR3M3p7ndyNDNzqsPdxH411WamjtZNm5mdjViVqcry1w6MUTtQePP2nEuHWCujztWecClVVe10nsejPb/a19fjX1/Pr6/H81+Pr6/n42vbHiYG1aslV5iLWqUUN7v9x7yJOsxUTGoH3pDeBEqxM0HJRVRCT0aZ5MVO431epmDz7+Fp9Xi4euIEzAx1FOGD29mez+fj8fh6PPrT4Fp9LRkJuRVorZmhPLsyjDrMROw8HXWiMiWRZOb5xGveU358LV8x6tWHAvn+m7lmBpOsA0U1EBA1KTdw12bem50NpLdt27Zt69t7B0qBcqHWUQq0bu52K6BKuNWZtRubZSVNuZpZieQvVkvu80I3+LmPK8W1MpPX6abagA/gzbvlv4+iNXN3b2YwUOvYaNF0Ym7uVS6qQSt2QmFy70AdJa2EU0WQXBShkFeV/BwROa8Dip9016eKV3d24e06SCspn9sNCBWXt5b/AvcR2rhK3ntV/2RmqlB7u9BdpOX6hVyM2ce4n4WmzpmF/Mfr1uufD6W/1/so50Xr3QfbPojX02Sfr/9mvrdHxed37vV/nnCqflIA/HQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F71E40FE7C0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F71E40FE9D0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for i in range(10):\n",
        "    img = cv2.imread(f\"aug_train_shuffle_64/{train_data[i][0]}\", cv2.IMREAD_UNCHANGED)\n",
        "    cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Kaggle Augmented Dataset"
      ],
      "metadata": {
        "id": "a63Sqs0HKwNM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "B2-puV5LK0UN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class KaggleDataset(nn.Module):\n",
        "    def __init__(self, mode = 'train'):\n",
        "        super(KaggleDataset, self).__init__()\n",
        "        self.mode = mode\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.dataset = train_data\n",
        "        else:\n",
        "            self.dataset = val_data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.dataset[idx][0]\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            img = cv2.imread(os.path.join('aug_train_shuffle_64', img_name))   \n",
        "        else:\n",
        "            img = cv2.imread(os.path.join('train_shuffle_64', img_name))\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    #convert image from BGR to RGB format\n",
        "\n",
        "        super_class = torch.tensor(self.dataset[idx][1], dtype = torch.float32)\n",
        "        sub_class = torch.tensor(self.dataset[idx][2], dtype = torch.float32)\n",
        "\n",
        "        apply_transform = self.transform_data()\n",
        "        image = apply_transform(image = img)['image']\n",
        "\n",
        "        return image, super_class, sub_class\n",
        "\n",
        "    def transform_data(self):\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            transform_func = A.Compose(\n",
        "              [\n",
        "                  A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1), \n",
        "                  ToTensorV2(p=1),\n",
        "              ])\n",
        "        else:     #augmentations during validation and testing\n",
        "            transform_func = A.Compose(\n",
        "            [   \n",
        "                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1),\n",
        "                ToTensorV2(p=1),\n",
        "            ])\n",
        "    \n",
        "        return transform_func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlgw7N4eK8Hl"
      },
      "source": [
        "##### Kaggle Augmented Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a3eb63-fae3-4edc-9819-6023bf982dee",
        "id": "Lvjr78ouK8Hm"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "495\n",
            "23\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = KaggleDataset(mode='train')\n",
        "val_dataset = KaggleDataset(mode='val')\n",
        "    \n",
        "train_loader = DataLoader(dataset = train_dataset, batch_size = 32, shuffle = True, num_workers = 8, pin_memory = True)\n",
        "val_loader = DataLoader(dataset = val_dataset, batch_size = 32, shuffle = False)\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(val_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXieIgvOO-vZ"
      },
      "source": [
        "### Created Augmented Data Joint Super Sub Class Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vENS2PxDO-vZ"
      },
      "source": [
        "##### Joint training utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXTJzl5jO-va"
      },
      "outputs": [],
      "source": [
        "# Will contain utility functions used for training the model\n",
        "import torch\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "#Training Function\n",
        "def fit_classifier(model, train_loader, val_loader, optimizer, loss_func, epochs=10, initial_epoch=0, device='cpu', name='effnetb6'):\n",
        "    '''\n",
        "    function to train a classifier model.\n",
        "    args:\n",
        "        model - the model to be trained\n",
        "        train_loader - Dataloader() for train set\n",
        "        val_loader - Dataloader() for val set\n",
        "        optimizer - optimization algorithm for updating weights\n",
        "        loss_func - loss function to be used\n",
        "    \n",
        "    keyword args:\n",
        "        epochs - Number of training epochs (default=10)\n",
        "        initial_epoch - The starting epoch\n",
        "        device - the device for training (default='cpu')\n",
        "        name - Name for saving the model\n",
        "    \n",
        "    returns: Nothing\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    model = model.to(device, non_blocking=True)\n",
        "    \n",
        "    # Save the models based on the super and sub class validation accuracies\n",
        "    best_super_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    best_sub_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    \n",
        "    #create the logger object\n",
        "    writer = SummaryWriter()\n",
        "    start_time = time.time()\n",
        "    \n",
        "    #Iterate epochs\n",
        "    for epoch in range(initial_epoch, initial_epoch + epochs):\n",
        "        #Each epoch has a training phase and validation phase\n",
        "        for phase in ['train','val']:\n",
        "            data_loader = None\n",
        "            if phase == 'train':\n",
        "                #Set train mode\n",
        "                model.train()\n",
        "                data_loader = train_loader\n",
        "            else:\n",
        "                #Set Eval mode\n",
        "                model.eval()\n",
        "                data_loader = val_loader\n",
        "          \n",
        "            running_super_loss = 0.\n",
        "            running_sub_loss = 0.\n",
        "            running_super_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            running_sub_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            \n",
        "            #tqdm for observing the progress\n",
        "            with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
        "                #Iterate batches\n",
        "                for itr, (images, super_labels, sub_labels) in enumerate(tepoch):\n",
        "                    tepoch.set_description(f\"Epoch {(epoch)} {phase}\")\n",
        "                    images = images.to(device, non_blocking=True)\n",
        "\n",
        "                    super_labels = super_labels.long().to(device, non_blocking=True)\n",
        "                    sub_labels = sub_labels.long().to(device, non_blocking=True)\n",
        "                    \n",
        "                    optimizer.zero_grad()\n",
        "                    \n",
        "                    #Set gradient calculation only for training phase\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        super_outputs, sub_outputs = model(images)\n",
        "\n",
        "                        super_loss = loss_func(super_outputs, super_labels)\n",
        "                        sub_loss = loss_func(sub_outputs, sub_labels)\n",
        "\n",
        "                        super_preds = torch.argmax(super_outputs, dim=1)\n",
        "                        sub_preds = torch.argmax(sub_outputs, dim=1)\n",
        "\n",
        "                        loss = 5 * super_loss + 2 * sub_loss\n",
        "                        \n",
        "                        #Do backprop only during training\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                    \n",
        "                    running_super_loss += 5 * super_loss.item() * images.size(0)\n",
        "                    running_sub_loss += 2 * sub_loss.item() * images.size(0)\n",
        "                    running_super_corrects += torch.sum(super_preds == super_labels)\n",
        "                    running_sub_corrects += torch.sum(sub_preds == sub_labels)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        writer.add_scalar(\"Batch_Loss/\" + phase, loss.item(), epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Super_Class/\" + phase,\n",
        "                                          (torch.sum(super_preds == super_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Sub_Class/\" + phase,\n",
        "                                          (torch.sum(sub_preds == sub_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                    \n",
        "                    tepoch.set_postfix(loss=loss.item(),\n",
        "                              super_class_accuracy=(torch.sum(super_preds == super_labels)/(images.shape[0])).item(),\n",
        "                              sub_class_accuracy=(torch.sum(sub_preds == sub_labels)/(images.shape[0])).item())\n",
        "                \n",
        "                epoch_super_loss = running_super_loss / len(data_loader.dataset)\n",
        "                epoch_sub_loss = running_sub_loss / len(data_loader.dataset)\n",
        "                epoch_super_acc = running_super_corrects.float() / (len(data_loader.dataset))\n",
        "                epoch_sub_acc = running_sub_corrects.float() / (len(data_loader.dataset))\n",
        "\n",
        "                print(f\"Epoch {(epoch)} {phase} Super Class loss: {epoch_super_loss} Super Class acc: {epoch_super_acc.item()}\")\n",
        "                print(f\"Sub Class loss: {epoch_sub_loss} Sub Class acc: {epoch_sub_acc.item()}\")\n",
        "\n",
        "                writer.add_scalar(\"Epoch_Loss_Super_Class/\" + phase, epoch_super_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Loss_Sub_Class/\" + phase, epoch_sub_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Super_Class/\" + phase, epoch_super_acc, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Sub_Class/\" + phase, epoch_sub_acc, epoch)\n",
        "                \n",
        "                # #Saving best model based on super class accuracy\n",
        "                if phase == 'val' and epoch_super_acc > best_super_acc:\n",
        "                    best_super_acc = epoch_super_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SuperClass.pth\")\n",
        "\n",
        "                #Saving best model based on sub class accuracy\n",
        "                if phase == 'val' and epoch_sub_acc > best_sub_acc:\n",
        "                    best_sub_acc = epoch_sub_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SubClass.pth\")    \n",
        "                \n",
        "        print('-'*20)\n",
        "    \n",
        "    #End of Training \n",
        "    end_time = time.time()  \n",
        "    writer.close()\n",
        "    print('Best Super Class val acc: {}'.format(best_super_acc.item()))\n",
        "    print('Best Sub Class val acc: {}'.format(best_sub_acc.item()))\n",
        "    print(f\"Average Time taken for an epoch: {(end_time - start_time)/epochs} sec\")\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDCStS5tO-vb"
      },
      "source": [
        "##### Create the Joint model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dS8m6cYO-vb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# Load the Swin Transformer model trained on ImageNet\n",
        "backbone_model = torchvision.models.swin_t(weights='IMAGENET1K_V1')\n",
        "backbone_model.head = nn.Identity()\n",
        "\n",
        "# Set the DropOut value in the backbone model\n",
        "def set_dropout_p(m, p):\n",
        "    if isinstance(m, nn.Dropout):\n",
        "        m.p = p\n",
        "\n",
        "backbone_model.apply(lambda m: set_dropout_p(m, p = 0.25))\n",
        "\n",
        "class AugmentedModel(nn.Module):\n",
        "    def __init__(self, backbone) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        # 3 super classes and 89 sub classes\n",
        "        self.superclass = nn.Linear(in_features = 768, out_features = 3)\n",
        "        self.subclass = nn.Linear(in_features = 768, out_features = 89)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.backbone(x)\n",
        "        super_class_out = self.superclass(out)\n",
        "        sub_class_out = self.subclass(out)\n",
        "        return super_class_out, sub_class_out\n",
        "\n",
        "# Create the baseline model\n",
        "augmented_joint_model = AugmentedModel(backbone_model)\n",
        "augmented_joint_model = augmented_joint_model.to(device, non_blocking = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg9QjyfrO-vb"
      },
      "source": [
        "##### Train the Joint model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzl8UoNdO-vb"
      },
      "source": [
        "###### Freeze all the layers except Classifier layers (phase 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaQ-DblPO-vb",
        "outputId": "c57b724e-ffc3-45ca-f373-9c2baa8f4c1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "          Linear-152                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,922,940\n",
            "Trainable params: 70,748\n",
            "Non-trainable params: 18,852,192\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.19\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n",
            "27590102\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with all backbone frozen)\n",
        "for param in augmented_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in augmented_joint_model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(augmented_joint_model, (3, 64, 64))\n",
        "\n",
        "# Check number of parameters\n",
        "pytorch_total_params = sum(p.numel() for p in augmented_joint_model.parameters())\n",
        "print(pytorch_total_params)\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in augmented_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s-fSMXsO-vb",
        "outputId": "11f28c34-ad5e-4494-e1c5-edc6911a6837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 train: 100%|██████████| 495/495 [00:20<00:00, 23.94batch/s, loss=13.6, sub_class_accuracy=0, super_class_accuracy=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train Super Class loss: 4.983701880770901 Super Class acc: 0.5053057074546814\n",
            "Sub Class loss: 8.876493526745952 Sub Class acc: 0.024949468672275543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 val: 100%|██████████| 23/23 [00:00<00:00, 24.48batch/s, loss=13.4, sub_class_accuracy=0.0333, super_class_accuracy=0.533]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 val Super Class loss: 4.379552537803754 Super Class acc: 0.5967302322387695\n",
            "Sub Class loss: 8.46478257192253 Sub Class acc: 0.058583106845617294\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 train: 100%|██████████| 495/495 [00:21<00:00, 23.48batch/s, loss=12.3, sub_class_accuracy=0.125, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train Super Class loss: 4.447518702918318 Super Class acc: 0.605419397354126\n",
            "Sub Class loss: 8.478429579867324 Sub Class acc: 0.05482567101716995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 val: 100%|██████████| 23/23 [00:00<00:00, 25.87batch/s, loss=12.9, sub_class_accuracy=0, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 val Super Class loss: 4.227945938584591 Super Class acc: 0.611716628074646\n",
            "Sub Class loss: 8.027168364875648 Sub Class acc: 0.09945503622293472\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 train: 100%|██████████| 495/495 [00:28<00:00, 17.26batch/s, loss=12.2, sub_class_accuracy=0.167, super_class_accuracy=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train Super Class loss: 4.201622383199357 Super Class acc: 0.6344744563102722\n",
            "Sub Class loss: 8.188273412281362 Sub Class acc: 0.0792066678404808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 val: 100%|██████████| 23/23 [00:01<00:00, 14.40batch/s, loss=12.8, sub_class_accuracy=0, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 val Super Class loss: 4.033261034079404 Super Class acc: 0.6457765698432922\n",
            "Sub Class loss: 7.763533111489111 Sub Class acc: 0.1130790188908577\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 train: 100%|██████████| 495/495 [00:25<00:00, 19.76batch/s, loss=12.6, sub_class_accuracy=0.0417, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train Super Class loss: 4.1565402346828355 Super Class acc: 0.6374431252479553\n",
            "Sub Class loss: 8.004291351784836 Sub Class acc: 0.09405002743005753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 val: 100%|██████████| 23/23 [00:00<00:00, 25.17batch/s, loss=12.7, sub_class_accuracy=0.0333, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 val Super Class loss: 4.079655071857514 Super Class acc: 0.6348773837089539\n",
            "Sub Class loss: 7.606210919102141 Sub Class acc: 0.12942779064178467\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 train: 100%|██████████| 495/495 [00:22<00:00, 22.47batch/s, loss=10.5, sub_class_accuracy=0.167, super_class_accuracy=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train Super Class loss: 4.089567330734123 Super Class acc: 0.6431909799575806\n",
            "Sub Class loss: 7.863306313467001 Sub Class acc: 0.10087165236473083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 val: 100%|██████████| 23/23 [00:01<00:00, 19.45batch/s, loss=12.5, sub_class_accuracy=0.0333, super_class_accuracy=0.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 val Super Class loss: 3.926862854236478 Super Class acc: 0.6525885462760925\n",
            "Sub Class loss: 7.496757348811594 Sub Class acc: 0.12534059584140778\n",
            "--------------------\n",
            "Best Super Class val acc: 0.6525885462760925\n",
            "Best Sub Class val acc: 0.12942779064178467\n",
            "Average Time taken for an epoch: 25.090459203720094 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "initial_epoch = 0\n",
        "learning_rate = 1e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    augmented_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Augment_Joint_SwinT_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Ur1eLdO-vc"
      },
      "source": [
        "###### Unfreeze some layers of the backbone network (phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSc3rp_TO-vc",
        "outputId": "5bfb15cb-90b1-47b4-bd4a-dd151a4710ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "          Linear-152                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,922,940\n",
            "Trainable params: 9,523,292\n",
            "Non-trainable params: 9,399,648\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.19\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with some backbone frozen)\n",
        "for param in augmented_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in augmented_joint_model.backbone.features[:7].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for idx, (name, param) in enumerate(augmented_joint_model.backbone.features[7].named_parameters()):\n",
        "    #print(name, idx)\n",
        "    if idx > 15:\n",
        "        param.requires_grad = True\n",
        "\n",
        "summary(augmented_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in augmented_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Som44RvbO-vc",
        "outputId": "49f59865-5aa3-4223-8d01-a638bbd8968a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 train: 100%|██████████| 495/495 [00:29<00:00, 16.75batch/s, loss=10.1, sub_class_accuracy=0.167, super_class_accuracy=0.792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train Super Class loss: 3.9202724141927607 Super Class acc: 0.6598660945892334\n",
            "Sub Class loss: 7.407000721434621 Sub Class acc: 0.12158918380737305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 val: 100%|██████████| 23/23 [00:00<00:00, 25.25batch/s, loss=11.7, sub_class_accuracy=0, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 val Super Class loss: 3.3051128153580085 Super Class acc: 0.7125340700149536\n",
            "Sub Class loss: 7.068792158641347 Sub Class acc: 0.1607629358768463\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 train: 100%|██████████| 495/495 [00:29<00:00, 16.93batch/s, loss=10.4, sub_class_accuracy=0.208, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train Super Class loss: 3.6338819952671306 Super Class acc: 0.6848787069320679\n",
            "Sub Class loss: 6.9557834789571045 Sub Class acc: 0.15045477449893951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 val: 100%|██████████| 23/23 [00:00<00:00, 25.63batch/s, loss=10.7, sub_class_accuracy=0.0333, super_class_accuracy=0.767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 val Super Class loss: 3.3248427055512204 Super Class acc: 0.7384195923805237\n",
            "Sub Class loss: 6.853907699481018 Sub Class acc: 0.18119890987873077\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 train: 100%|██████████| 495/495 [00:28<00:00, 17.08batch/s, loss=10.2, sub_class_accuracy=0.208, super_class_accuracy=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train Super Class loss: 3.4320608419923846 Super Class acc: 0.7083754539489746\n",
            "Sub Class loss: 6.647474350623256 Sub Class acc: 0.17477260529994965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 val: 100%|██████████| 23/23 [00:00<00:00, 25.93batch/s, loss=12, sub_class_accuracy=0.0333, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 val Super Class loss: 3.200872546970357 Super Class acc: 0.7370572090148926\n",
            "Sub Class loss: 6.745702221218182 Sub Class acc: 0.19891007244586945\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 train: 100%|██████████| 495/495 [00:29<00:00, 16.90batch/s, loss=8.36, sub_class_accuracy=0.292, super_class_accuracy=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 train Super Class loss: 3.3611003398714554 Super Class acc: 0.716713011264801\n",
            "Sub Class loss: 6.490049989612612 Sub Class acc: 0.1843734234571457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 val: 100%|██████████| 23/23 [00:01<00:00, 19.62batch/s, loss=10.6, sub_class_accuracy=0.0667, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 val Super Class loss: 2.8514592572843673 Super Class acc: 0.7724795341491699\n",
            "Sub Class loss: 6.589387319393314 Sub Class acc: 0.18256130814552307\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 train: 100%|██████████| 495/495 [00:29<00:00, 16.85batch/s, loss=8.59, sub_class_accuracy=0.208, super_class_accuracy=0.792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 train Super Class loss: 3.267097496335828 Super Class acc: 0.7259979844093323\n",
            "Sub Class loss: 6.343342673844795 Sub Class acc: 0.193279430270195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 val: 100%|██████████| 23/23 [00:00<00:00, 25.22batch/s, loss=10.3, sub_class_accuracy=0.1, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 val Super Class loss: 3.062692168460555 Super Class acc: 0.7506811618804932\n",
            "Sub Class loss: 6.758338207120142 Sub Class acc: 0.19891007244586945\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 train: 100%|██████████| 495/495 [00:28<00:00, 17.17batch/s, loss=9.71, sub_class_accuracy=0.125, super_class_accuracy=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 train Super Class loss: 3.159582997103301 Super Class acc: 0.7374936938285828\n",
            "Sub Class loss: 6.211187295446256 Sub Class acc: 0.20837543904781342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 val: 100%|██████████| 23/23 [00:00<00:00, 26.83batch/s, loss=10.9, sub_class_accuracy=0.0333, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 val Super Class loss: 3.026217949000626 Super Class acc: 0.7561307549476624\n",
            "Sub Class loss: 6.579327609298664 Sub Class acc: 0.20299726724624634\n",
            "--------------------\n",
            "Best Super Class val acc: 0.7724795341491699\n",
            "Best Sub Class val acc: 0.20299726724624634\n",
            "Average Time taken for an epoch: 30.490694999694824 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 6\n",
        "initial_epoch = 5\n",
        "learning_rate = 2e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    augmented_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Augment_Joint_SwinT_semi_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSkS1b4WO-vc"
      },
      "source": [
        "###### Unfreeze all the layers in the network (phase 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDGUpbVXO-vc",
        "outputId": "c883133f-78f3-4f6d-8b06-da5304eac359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "          Linear-152                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,922,940\n",
            "Trainable params: 18,922,940\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.19\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with everything unfrozen)\n",
        "for param in augmented_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "summary(augmented_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in augmented_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLB3JeycO-vc",
        "outputId": "2774e011-71fb-40bd-a9e1-a4749f8781c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 train: 100%|██████████| 495/495 [00:50<00:00,  9.88batch/s, loss=6.34, sub_class_accuracy=0.208, super_class_accuracy=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 train Super Class loss: 2.90409160298853 Super Class acc: 0.763327419757843\n",
            "Sub Class loss: 6.010507477359859 Sub Class acc: 0.2151339054107666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 val: 100%|██████████| 23/23 [00:00<00:00, 24.40batch/s, loss=9.34, sub_class_accuracy=0.2, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 val Super Class loss: 2.5961006995117955 Super Class acc: 0.7806539535522461\n",
            "Sub Class loss: 6.081120549495603 Sub Class acc: 0.2193460464477539\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 train: 100%|██████████| 495/495 [00:50<00:00,  9.75batch/s, loss=6.74, sub_class_accuracy=0.25, super_class_accuracy=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 train Super Class loss: 2.1779163803730186 Super Class acc: 0.8294593095779419\n",
            "Sub Class loss: 5.0498851688899675 Sub Class acc: 0.30185699462890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 val: 100%|██████████| 23/23 [00:00<00:00, 25.43batch/s, loss=8.85, sub_class_accuracy=0.1, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 val Super Class loss: 2.008878727943436 Super Class acc: 0.8542234301567078\n",
            "Sub Class loss: 5.704824654217962 Sub Class acc: 0.24523159861564636\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 train: 100%|██████████| 495/495 [00:50<00:00,  9.71batch/s, loss=6.25, sub_class_accuracy=0.417, super_class_accuracy=0.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 train Super Class loss: 1.769314571695535 Super Class acc: 0.8657150268554688\n",
            "Sub Class loss: 4.38700241220907 Sub Class acc: 0.3740525543689728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 val: 100%|██████████| 23/23 [00:00<00:00, 25.60batch/s, loss=9.15, sub_class_accuracy=0.133, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 val Super Class loss: 2.0964675938725796 Super Class acc: 0.8405994176864624\n",
            "Sub Class loss: 5.832951414487667 Sub Class acc: 0.26294276118278503\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 train: 100%|██████████| 495/495 [00:50<00:00,  9.76batch/s, loss=5.26, sub_class_accuracy=0.583, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 train Super Class loss: 1.4283555354913597 Super Class acc: 0.8899065256118774\n",
            "Sub Class loss: 3.8273927357053443 Sub Class acc: 0.43923699855804443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 val: 100%|██████████| 23/23 [00:00<00:00, 24.75batch/s, loss=8.87, sub_class_accuracy=0.167, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 val Super Class loss: 2.2238092156944225 Super Class acc: 0.8501362204551697\n",
            "Sub Class loss: 5.9135843817479605 Sub Class acc: 0.23841962218284607\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 train: 100%|██████████| 495/495 [00:49<00:00,  9.95batch/s, loss=4.97, sub_class_accuracy=0.625, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 train Super Class loss: 1.1798915530151644 Super Class acc: 0.9120768308639526\n",
            "Sub Class loss: 3.283147601902997 Sub Class acc: 0.5072005987167358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 val: 100%|██████████| 23/23 [00:00<00:00, 24.78batch/s, loss=10.5, sub_class_accuracy=0.1, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 val Super Class loss: 2.041301733791341 Super Class acc: 0.8678473830223083\n",
            "Sub Class loss: 6.338790350454055 Sub Class acc: 0.25476840138435364\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 train: 100%|██████████| 495/495 [00:49<00:00,  9.92batch/s, loss=4.56, sub_class_accuracy=0.667, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 train Super Class loss: 0.9046003106132549 Super Class acc: 0.9309626221656799\n",
            "Sub Class loss: 2.7710710521175623 Sub Class acc: 0.5711849331855774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 val: 100%|██████████| 23/23 [00:00<00:00, 25.34batch/s, loss=13, sub_class_accuracy=0.267, super_class_accuracy=0.767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 val Super Class loss: 2.470603538144187 Super Class acc: 0.85694819688797\n",
            "Sub Class loss: 6.699765192390463 Sub Class acc: 0.2711171507835388\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 train: 100%|██████████| 495/495 [00:51<00:00,  9.69batch/s, loss=3.04, sub_class_accuracy=0.625, super_class_accuracy=0.958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 train Super Class loss: 0.7698123219991013 Super Class acc: 0.9424583315849304\n",
            "Sub Class loss: 2.338210242634292 Sub Class acc: 0.6321374177932739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 val: 100%|██████████| 23/23 [00:00<00:00, 24.96batch/s, loss=11, sub_class_accuracy=0.233, super_class_accuracy=0.767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 val Super Class loss: 2.391195175433354 Super Class acc: 0.8610354065895081\n",
            "Sub Class loss: 6.498975449751768 Sub Class acc: 0.29836511611938477\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 train: 100%|██████████| 495/495 [00:49<00:00,  9.91batch/s, loss=2.29, sub_class_accuracy=0.667, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 train Super Class loss: 0.595147209183161 Super Class acc: 0.9578701257705688\n",
            "Sub Class loss: 1.9522463711540528 Sub Class acc: 0.6884790062904358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 val: 100%|██████████| 23/23 [00:00<00:00, 24.70batch/s, loss=10.4, sub_class_accuracy=0.3, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 val Super Class loss: 2.8064099680987624 Super Class acc: 0.8555858135223389\n",
            "Sub Class loss: 7.3316411504303725 Sub Class acc: 0.2643051743507385\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 train: 100%|██████████| 495/495 [00:50<00:00,  9.76batch/s, loss=1.87, sub_class_accuracy=0.75, super_class_accuracy=0.958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 train Super Class loss: 0.5399684086225517 Super Class acc: 0.9596387147903442\n",
            "Sub Class loss: 1.662152551472217 Sub Class acc: 0.7351566553115845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 val: 100%|██████████| 23/23 [00:00<00:00, 25.19batch/s, loss=15.3, sub_class_accuracy=0.2, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 val Super Class loss: 3.2287623170935817 Super Class acc: 0.829700231552124\n",
            "Sub Class loss: 7.812186436042474 Sub Class acc: 0.2738419473171234\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 train: 100%|██████████| 495/495 [00:49<00:00,  9.94batch/s, loss=2.43, sub_class_accuracy=0.625, super_class_accuracy=0.958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 train Super Class loss: 0.4583072795910538 Super Class acc: 0.9677867889404297\n",
            "Sub Class loss: 1.3806180893139985 Sub Class acc: 0.77311772108078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 val: 100%|██████████| 23/23 [00:00<00:00, 25.54batch/s, loss=12, sub_class_accuracy=0.367, super_class_accuracy=0.833]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 val Super Class loss: 2.557687013935328 Super Class acc: 0.8623977899551392\n",
            "Sub Class loss: 7.668273746480084 Sub Class acc: 0.290190726518631\n",
            "--------------------\n",
            "Best Super Class val acc: 0.8678473830223083\n",
            "Best Sub Class val acc: 0.29836511611938477\n",
            "Average Time taken for an epoch: 51.51663687229156 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "initial_epoch = 11\n",
        "learning_rate = 4e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    augmented_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Augment_Joint_SwinT_unfrozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmented EfficientNetB3 Joint Super Sub Class model"
      ],
      "metadata": {
        "id": "tjrcICcQZ3Pj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMFVoQ63eBlj"
      },
      "source": [
        "##### Joint training utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu0U9fkCeBlj"
      },
      "outputs": [],
      "source": [
        "# Will contain utility functions used for training the model\n",
        "import torch\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "#Training Function\n",
        "def fit_classifier(model, train_loader, val_loader, optimizer, loss_func, epochs=10, initial_epoch=0, device='cpu', name='effnetb6'):\n",
        "    '''\n",
        "    function to train a classifier model.\n",
        "    args:\n",
        "        model - the model to be trained\n",
        "        train_loader - Dataloader() for train set\n",
        "        val_loader - Dataloader() for val set\n",
        "        optimizer - optimization algorithm for updating weights\n",
        "        loss_func - loss function to be used\n",
        "    \n",
        "    keyword args:\n",
        "        epochs - Number of training epochs (default=10)\n",
        "        initial_epoch - The starting epoch\n",
        "        device - the device for training (default='cpu')\n",
        "        name - Name for saving the model\n",
        "    \n",
        "    returns: Nothing\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    model = model.to(device, non_blocking=True)\n",
        "    \n",
        "    # Save the models based on the super and sub class validation accuracies\n",
        "    best_super_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    best_sub_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    \n",
        "    #create the logger object\n",
        "    writer = SummaryWriter()\n",
        "    start_time = time.time()\n",
        "    \n",
        "    #Iterate epochs\n",
        "    for epoch in range(initial_epoch, initial_epoch + epochs):\n",
        "        #Each epoch has a training phase and validation phase\n",
        "        for phase in ['train','val']:\n",
        "            data_loader = None\n",
        "            if phase == 'train':\n",
        "                #Set train mode\n",
        "                model.train()\n",
        "                data_loader = train_loader\n",
        "            else:\n",
        "                #Set Eval mode\n",
        "                model.eval()\n",
        "                data_loader = val_loader\n",
        "          \n",
        "            running_super_loss = 0.\n",
        "            running_sub_loss = 0.\n",
        "            running_super_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            running_sub_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            \n",
        "            #tqdm for observing the progress\n",
        "            with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
        "                #Iterate batches\n",
        "                for itr, (images, super_labels, sub_labels) in enumerate(tepoch):\n",
        "                    tepoch.set_description(f\"Epoch {(epoch)} {phase}\")\n",
        "                    images = images.to(device, non_blocking=True)\n",
        "\n",
        "                    super_labels = super_labels.long().to(device, non_blocking=True)\n",
        "                    sub_labels = sub_labels.long().to(device, non_blocking=True)\n",
        "                    \n",
        "                    optimizer.zero_grad()\n",
        "                    \n",
        "                    #Set gradient calculation only for training phase\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        super_outputs, sub_outputs = model(images)\n",
        "\n",
        "                        super_loss = loss_func(super_outputs, super_labels)\n",
        "                        sub_loss = loss_func(sub_outputs, sub_labels)\n",
        "\n",
        "                        super_preds = torch.argmax(super_outputs, dim=1)\n",
        "                        sub_preds = torch.argmax(sub_outputs, dim=1)\n",
        "\n",
        "                        loss = 5 * super_loss + 2 * sub_loss\n",
        "                        \n",
        "                        #Do backprop only during training\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                    \n",
        "                    running_super_loss += 5 * super_loss.item() * images.size(0)\n",
        "                    running_sub_loss += 2 * sub_loss.item() * images.size(0)\n",
        "                    running_super_corrects += torch.sum(super_preds == super_labels)\n",
        "                    running_sub_corrects += torch.sum(sub_preds == sub_labels)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        writer.add_scalar(\"Batch_Loss/\" + phase, loss.item(), epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Super_Class/\" + phase,\n",
        "                                          (torch.sum(super_preds == super_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Sub_Class/\" + phase,\n",
        "                                          (torch.sum(sub_preds == sub_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                    \n",
        "                    tepoch.set_postfix(loss=loss.item(),\n",
        "                              super_class_accuracy=(torch.sum(super_preds == super_labels)/(images.shape[0])).item(),\n",
        "                              sub_class_accuracy=(torch.sum(sub_preds == sub_labels)/(images.shape[0])).item())\n",
        "                \n",
        "                epoch_super_loss = running_super_loss / len(data_loader.dataset)\n",
        "                epoch_sub_loss = running_sub_loss / len(data_loader.dataset)\n",
        "                epoch_super_acc = running_super_corrects.float() / (len(data_loader.dataset))\n",
        "                epoch_sub_acc = running_sub_corrects.float() / (len(data_loader.dataset))\n",
        "\n",
        "                print(f\"Epoch {(epoch)} {phase} Super Class loss: {epoch_super_loss} Super Class acc: {epoch_super_acc.item()}\")\n",
        "                print(f\"Sub Class loss: {epoch_sub_loss} Sub Class acc: {epoch_sub_acc.item()}\")\n",
        "\n",
        "                writer.add_scalar(\"Epoch_Loss_Super_Class/\" + phase, epoch_super_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Loss_Sub_Class/\" + phase, epoch_sub_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Super_Class/\" + phase, epoch_super_acc, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Sub_Class/\" + phase, epoch_sub_acc, epoch)\n",
        "                \n",
        "                # #Saving best model based on super class accuracy\n",
        "                if phase == 'val' and epoch_super_acc > best_super_acc:\n",
        "                    best_super_acc = epoch_super_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SuperClass.pth\")\n",
        "\n",
        "                #Saving best model based on sub class accuracy\n",
        "                if phase == 'val' and epoch_sub_acc > best_sub_acc:\n",
        "                    best_sub_acc = epoch_sub_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SubClass.pth\")    \n",
        "                \n",
        "        print('-'*20)\n",
        "    \n",
        "    #End of Training \n",
        "    end_time = time.time()  \n",
        "    writer.close()\n",
        "    print('Best Super Class val acc: {}'.format(best_super_acc.item()))\n",
        "    print('Best Sub Class val acc: {}'.format(best_sub_acc.item()))\n",
        "    print(f\"Average Time taken for an epoch: {(end_time - start_time)/epochs} sec\")\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j7G1YPGZ9fh"
      },
      "source": [
        "##### Create the EfficientNetB3 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ugTE6OlZ9fi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142,
          "referenced_widgets": [
            "18d214b88c574650969a45d9d420c1c9",
            "19a809866b8e42e6924aaaa904e28b04",
            "dd69ec46a99f4cd2a26abcb140aeb1f3",
            "4cd66c9f83694608816a91914d062af6",
            "7258ceb06a5d4f48ba52c97768f5cb88",
            "a831b8c34c65433983f64fceda28cc3a",
            "6411991615c644499971f682f18cbea4",
            "fbee345af0024e6ba568e4d6c1ccbc17",
            "7c6e4b75a4954aa4869191387c2302c9",
            "3677a94a957248c68732c90042ac26d1",
            "b7f2793ee25e404b87c1e5c868bb8b4a"
          ]
        },
        "outputId": "6a934eed-71f6-486b-de18-6bd49a9354d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-cf984f9c.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-cf984f9c.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/47.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18d214b88c574650969a45d9d420c1c9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# Load the EfficientNetB3 model trained on ImageNet\n",
        "backbone_model = torchvision.models.efficientnet_b3(weights='IMAGENET1K_V1')\n",
        "backbone_model.classifier = nn.Identity()\n",
        "\n",
        "\n",
        "class EffnetB3JointModel(nn.Module):\n",
        "    def __init__(self, backbone) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        # 3 super classes\n",
        "        self.superclass = nn.Linear(in_features = 1536, out_features = 3)\n",
        "        # 89 sub classes\n",
        "        self.subclass = nn.Linear(in_features = 1536, out_features = 89)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.backbone(x)\n",
        "        super_class_out = self.superclass(out)\n",
        "        sub_class_out = self.subclass(out)\n",
        "        return super_class_out, sub_class_out\n",
        "\n",
        "# Create the baseline model\n",
        "effnetb3_joint_model = EffnetB3JointModel(backbone_model)\n",
        "effnetb3_joint_model = effnetb3_joint_model.to(device, non_blocking = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwSwDhXscTkD"
      },
      "source": [
        "##### Train the EfficientNetB3 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69AU6pgKcTkD"
      },
      "source": [
        "###### Freeze all the layers except Classifier layers (phase 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870dda3e-8e1a-499b-d6ab-6ace5ca6ae57",
        "id": "pMj3fC9ocTkD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 40, 32, 32]           1,080\n",
            "       BatchNorm2d-2           [-1, 40, 32, 32]              80\n",
            "              SiLU-3           [-1, 40, 32, 32]               0\n",
            "            Conv2d-4           [-1, 40, 32, 32]             360\n",
            "       BatchNorm2d-5           [-1, 40, 32, 32]              80\n",
            "              SiLU-6           [-1, 40, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 40, 1, 1]               0\n",
            "            Conv2d-8             [-1, 10, 1, 1]             410\n",
            "              SiLU-9             [-1, 10, 1, 1]               0\n",
            "           Conv2d-10             [-1, 40, 1, 1]             440\n",
            "          Sigmoid-11             [-1, 40, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 40, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]             960\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-19             [-1, 24, 1, 1]               0\n",
            "           Conv2d-20              [-1, 6, 1, 1]             150\n",
            "             SiLU-21              [-1, 6, 1, 1]               0\n",
            "           Conv2d-22             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-23             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-24           [-1, 24, 32, 32]               0\n",
            "           Conv2d-25           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-27           [-1, 24, 32, 32]               0\n",
            "           MBConv-28           [-1, 24, 32, 32]               0\n",
            "           Conv2d-29          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-30          [-1, 144, 32, 32]             288\n",
            "             SiLU-31          [-1, 144, 32, 32]               0\n",
            "           Conv2d-32          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-33          [-1, 144, 16, 16]             288\n",
            "             SiLU-34          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-35            [-1, 144, 1, 1]               0\n",
            "           Conv2d-36              [-1, 6, 1, 1]             870\n",
            "             SiLU-37              [-1, 6, 1, 1]               0\n",
            "           Conv2d-38            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-39            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-40          [-1, 144, 16, 16]               0\n",
            "           Conv2d-41           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-42           [-1, 32, 16, 16]              64\n",
            "           MBConv-43           [-1, 32, 16, 16]               0\n",
            "           Conv2d-44          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-45          [-1, 192, 16, 16]             384\n",
            "             SiLU-46          [-1, 192, 16, 16]               0\n",
            "           Conv2d-47          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-48          [-1, 192, 16, 16]             384\n",
            "             SiLU-49          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-50            [-1, 192, 1, 1]               0\n",
            "           Conv2d-51              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-52              [-1, 8, 1, 1]               0\n",
            "           Conv2d-53            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-54            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-55          [-1, 192, 16, 16]               0\n",
            "           Conv2d-56           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-57           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-58           [-1, 32, 16, 16]               0\n",
            "           MBConv-59           [-1, 32, 16, 16]               0\n",
            "           Conv2d-60          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-61          [-1, 192, 16, 16]             384\n",
            "             SiLU-62          [-1, 192, 16, 16]               0\n",
            "           Conv2d-63          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-64          [-1, 192, 16, 16]             384\n",
            "             SiLU-65          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-66            [-1, 192, 1, 1]               0\n",
            "           Conv2d-67              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-68              [-1, 8, 1, 1]               0\n",
            "           Conv2d-69            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-70            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-71          [-1, 192, 16, 16]               0\n",
            "           Conv2d-72           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-73           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-74           [-1, 32, 16, 16]               0\n",
            "           MBConv-75           [-1, 32, 16, 16]               0\n",
            "           Conv2d-76          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-77          [-1, 192, 16, 16]             384\n",
            "             SiLU-78          [-1, 192, 16, 16]               0\n",
            "           Conv2d-79            [-1, 192, 8, 8]           4,800\n",
            "      BatchNorm2d-80            [-1, 192, 8, 8]             384\n",
            "             SiLU-81            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-82            [-1, 192, 1, 1]               0\n",
            "           Conv2d-83              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-84              [-1, 8, 1, 1]               0\n",
            "           Conv2d-85            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-86            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-87            [-1, 192, 8, 8]               0\n",
            "           Conv2d-88             [-1, 48, 8, 8]           9,216\n",
            "      BatchNorm2d-89             [-1, 48, 8, 8]              96\n",
            "           MBConv-90             [-1, 48, 8, 8]               0\n",
            "           Conv2d-91            [-1, 288, 8, 8]          13,824\n",
            "      BatchNorm2d-92            [-1, 288, 8, 8]             576\n",
            "             SiLU-93            [-1, 288, 8, 8]               0\n",
            "           Conv2d-94            [-1, 288, 8, 8]           7,200\n",
            "      BatchNorm2d-95            [-1, 288, 8, 8]             576\n",
            "             SiLU-96            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-97            [-1, 288, 1, 1]               0\n",
            "           Conv2d-98             [-1, 12, 1, 1]           3,468\n",
            "             SiLU-99             [-1, 12, 1, 1]               0\n",
            "          Conv2d-100            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-101            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-102            [-1, 288, 8, 8]               0\n",
            "          Conv2d-103             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-104             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-105             [-1, 48, 8, 8]               0\n",
            "          MBConv-106             [-1, 48, 8, 8]               0\n",
            "          Conv2d-107            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-108            [-1, 288, 8, 8]             576\n",
            "            SiLU-109            [-1, 288, 8, 8]               0\n",
            "          Conv2d-110            [-1, 288, 8, 8]           7,200\n",
            "     BatchNorm2d-111            [-1, 288, 8, 8]             576\n",
            "            SiLU-112            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-113            [-1, 288, 1, 1]               0\n",
            "          Conv2d-114             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-115             [-1, 12, 1, 1]               0\n",
            "          Conv2d-116            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-117            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-118            [-1, 288, 8, 8]               0\n",
            "          Conv2d-119             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-121             [-1, 48, 8, 8]               0\n",
            "          MBConv-122             [-1, 48, 8, 8]               0\n",
            "          Conv2d-123            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-124            [-1, 288, 8, 8]             576\n",
            "            SiLU-125            [-1, 288, 8, 8]               0\n",
            "          Conv2d-126            [-1, 288, 4, 4]           2,592\n",
            "     BatchNorm2d-127            [-1, 288, 4, 4]             576\n",
            "            SiLU-128            [-1, 288, 4, 4]               0\n",
            "AdaptiveAvgPool2d-129            [-1, 288, 1, 1]               0\n",
            "          Conv2d-130             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-131             [-1, 12, 1, 1]               0\n",
            "          Conv2d-132            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-133            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-134            [-1, 288, 4, 4]               0\n",
            "          Conv2d-135             [-1, 96, 4, 4]          27,648\n",
            "     BatchNorm2d-136             [-1, 96, 4, 4]             192\n",
            "          MBConv-137             [-1, 96, 4, 4]               0\n",
            "          Conv2d-138            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-139            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-140            [-1, 576, 4, 4]               0\n",
            "          Conv2d-141            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-142            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-143            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-144            [-1, 576, 1, 1]               0\n",
            "          Conv2d-145             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-146             [-1, 24, 1, 1]               0\n",
            "          Conv2d-147            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-148            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-149            [-1, 576, 4, 4]               0\n",
            "          Conv2d-150             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-151             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-152             [-1, 96, 4, 4]               0\n",
            "          MBConv-153             [-1, 96, 4, 4]               0\n",
            "          Conv2d-154            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-155            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-156            [-1, 576, 4, 4]               0\n",
            "          Conv2d-157            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-158            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-159            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-160            [-1, 576, 1, 1]               0\n",
            "          Conv2d-161             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-162             [-1, 24, 1, 1]               0\n",
            "          Conv2d-163            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-164            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-165            [-1, 576, 4, 4]               0\n",
            "          Conv2d-166             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-167             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-168             [-1, 96, 4, 4]               0\n",
            "          MBConv-169             [-1, 96, 4, 4]               0\n",
            "          Conv2d-170            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-171            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-172            [-1, 576, 4, 4]               0\n",
            "          Conv2d-173            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-174            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-175            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-176            [-1, 576, 1, 1]               0\n",
            "          Conv2d-177             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-178             [-1, 24, 1, 1]               0\n",
            "          Conv2d-179            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-180            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-181            [-1, 576, 4, 4]               0\n",
            "          Conv2d-182             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-183             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-184             [-1, 96, 4, 4]               0\n",
            "          MBConv-185             [-1, 96, 4, 4]               0\n",
            "          Conv2d-186            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-187            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-188            [-1, 576, 4, 4]               0\n",
            "          Conv2d-189            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-190            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-191            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-192            [-1, 576, 1, 1]               0\n",
            "          Conv2d-193             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-194             [-1, 24, 1, 1]               0\n",
            "          Conv2d-195            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-196            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-197            [-1, 576, 4, 4]               0\n",
            "          Conv2d-198             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-199             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-200             [-1, 96, 4, 4]               0\n",
            "          MBConv-201             [-1, 96, 4, 4]               0\n",
            "          Conv2d-202            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-203            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-204            [-1, 576, 4, 4]               0\n",
            "          Conv2d-205            [-1, 576, 4, 4]          14,400\n",
            "     BatchNorm2d-206            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-207            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-208            [-1, 576, 1, 1]               0\n",
            "          Conv2d-209             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-210             [-1, 24, 1, 1]               0\n",
            "          Conv2d-211            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-212            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-213            [-1, 576, 4, 4]               0\n",
            "          Conv2d-214            [-1, 136, 4, 4]          78,336\n",
            "     BatchNorm2d-215            [-1, 136, 4, 4]             272\n",
            "          MBConv-216            [-1, 136, 4, 4]               0\n",
            "          Conv2d-217            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-218            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-219            [-1, 816, 4, 4]               0\n",
            "          Conv2d-220            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-221            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-222            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-223            [-1, 816, 1, 1]               0\n",
            "          Conv2d-224             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-225             [-1, 34, 1, 1]               0\n",
            "          Conv2d-226            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-227            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-228            [-1, 816, 4, 4]               0\n",
            "          Conv2d-229            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-230            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-231            [-1, 136, 4, 4]               0\n",
            "          MBConv-232            [-1, 136, 4, 4]               0\n",
            "          Conv2d-233            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-234            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-235            [-1, 816, 4, 4]               0\n",
            "          Conv2d-236            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-237            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-238            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-239            [-1, 816, 1, 1]               0\n",
            "          Conv2d-240             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-241             [-1, 34, 1, 1]               0\n",
            "          Conv2d-242            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-243            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-244            [-1, 816, 4, 4]               0\n",
            "          Conv2d-245            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-246            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-247            [-1, 136, 4, 4]               0\n",
            "          MBConv-248            [-1, 136, 4, 4]               0\n",
            "          Conv2d-249            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-250            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-251            [-1, 816, 4, 4]               0\n",
            "          Conv2d-252            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-253            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-254            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-255            [-1, 816, 1, 1]               0\n",
            "          Conv2d-256             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-257             [-1, 34, 1, 1]               0\n",
            "          Conv2d-258            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-259            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-260            [-1, 816, 4, 4]               0\n",
            "          Conv2d-261            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-262            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-263            [-1, 136, 4, 4]               0\n",
            "          MBConv-264            [-1, 136, 4, 4]               0\n",
            "          Conv2d-265            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-266            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-267            [-1, 816, 4, 4]               0\n",
            "          Conv2d-268            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-269            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-270            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-271            [-1, 816, 1, 1]               0\n",
            "          Conv2d-272             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-273             [-1, 34, 1, 1]               0\n",
            "          Conv2d-274            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-275            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-276            [-1, 816, 4, 4]               0\n",
            "          Conv2d-277            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-278            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-279            [-1, 136, 4, 4]               0\n",
            "          MBConv-280            [-1, 136, 4, 4]               0\n",
            "          Conv2d-281            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-282            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-283            [-1, 816, 4, 4]               0\n",
            "          Conv2d-284            [-1, 816, 2, 2]          20,400\n",
            "     BatchNorm2d-285            [-1, 816, 2, 2]           1,632\n",
            "            SiLU-286            [-1, 816, 2, 2]               0\n",
            "AdaptiveAvgPool2d-287            [-1, 816, 1, 1]               0\n",
            "          Conv2d-288             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-289             [-1, 34, 1, 1]               0\n",
            "          Conv2d-290            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-291            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-292            [-1, 816, 2, 2]               0\n",
            "          Conv2d-293            [-1, 232, 2, 2]         189,312\n",
            "     BatchNorm2d-294            [-1, 232, 2, 2]             464\n",
            "          MBConv-295            [-1, 232, 2, 2]               0\n",
            "          Conv2d-296           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-297           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-298           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-299           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-300           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-301           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-302           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-303             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-304             [-1, 58, 1, 1]               0\n",
            "          Conv2d-305           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-306           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-307           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-308            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-309            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-310            [-1, 232, 2, 2]               0\n",
            "          MBConv-311            [-1, 232, 2, 2]               0\n",
            "          Conv2d-312           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-313           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-314           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-315           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-316           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-317           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-318           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-319             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-320             [-1, 58, 1, 1]               0\n",
            "          Conv2d-321           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-322           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-323           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-324            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-325            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-326            [-1, 232, 2, 2]               0\n",
            "          MBConv-327            [-1, 232, 2, 2]               0\n",
            "          Conv2d-328           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-329           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-330           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-331           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-332           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-333           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-334           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-335             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-336             [-1, 58, 1, 1]               0\n",
            "          Conv2d-337           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-338           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-339           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-340            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-341            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-342            [-1, 232, 2, 2]               0\n",
            "          MBConv-343            [-1, 232, 2, 2]               0\n",
            "          Conv2d-344           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-345           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-346           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-347           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-348           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-349           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-350           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-351             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-352             [-1, 58, 1, 1]               0\n",
            "          Conv2d-353           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-354           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-355           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-356            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-357            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-358            [-1, 232, 2, 2]               0\n",
            "          MBConv-359            [-1, 232, 2, 2]               0\n",
            "          Conv2d-360           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-361           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-362           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-363           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-364           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-365           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-366           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-367             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-368             [-1, 58, 1, 1]               0\n",
            "          Conv2d-369           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-370           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-371           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-372            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-373            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-374            [-1, 232, 2, 2]               0\n",
            "          MBConv-375            [-1, 232, 2, 2]               0\n",
            "          Conv2d-376           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-377           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-378           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1392, 2, 2]          12,528\n",
            "     BatchNorm2d-380           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-381           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-382           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-383             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-384             [-1, 58, 1, 1]               0\n",
            "          Conv2d-385           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-386           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-387           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-388            [-1, 384, 2, 2]         534,528\n",
            "     BatchNorm2d-389            [-1, 384, 2, 2]             768\n",
            "          MBConv-390            [-1, 384, 2, 2]               0\n",
            "          Conv2d-391           [-1, 2304, 2, 2]         884,736\n",
            "     BatchNorm2d-392           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-393           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-394           [-1, 2304, 2, 2]          20,736\n",
            "     BatchNorm2d-395           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-396           [-1, 2304, 2, 2]               0\n",
            "AdaptiveAvgPool2d-397           [-1, 2304, 1, 1]               0\n",
            "          Conv2d-398             [-1, 96, 1, 1]         221,280\n",
            "            SiLU-399             [-1, 96, 1, 1]               0\n",
            "          Conv2d-400           [-1, 2304, 1, 1]         223,488\n",
            "         Sigmoid-401           [-1, 2304, 1, 1]               0\n",
            "SqueezeExcitation-402           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-403            [-1, 384, 2, 2]         884,736\n",
            "     BatchNorm2d-404            [-1, 384, 2, 2]             768\n",
            " StochasticDepth-405            [-1, 384, 2, 2]               0\n",
            "          MBConv-406            [-1, 384, 2, 2]               0\n",
            "          Conv2d-407           [-1, 1536, 2, 2]         589,824\n",
            "     BatchNorm2d-408           [-1, 1536, 2, 2]           3,072\n",
            "            SiLU-409           [-1, 1536, 2, 2]               0\n",
            "AdaptiveAvgPool2d-410           [-1, 1536, 1, 1]               0\n",
            "        Identity-411                 [-1, 1536]               0\n",
            "    EfficientNet-412                 [-1, 1536]               0\n",
            "          Linear-413                    [-1, 3]           4,611\n",
            "          Linear-414                   [-1, 89]         136,793\n",
            "================================================================\n",
            "Total params: 10,837,636\n",
            "Trainable params: 141,404\n",
            "Non-trainable params: 10,696,232\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 28.31\n",
            "Params size (MB): 41.34\n",
            "Estimated Total Size (MB): 69.70\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with all backbone frozen)\n",
        "for param in effnetb3_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in effnetb3_joint_model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(effnetb3_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb3_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e6e0b5d-0f03-4854-8c72-e8765b5ad794",
        "id": "18KifZ8PcTkD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 train: 100%|██████████| 495/495 [00:22<00:00, 21.68batch/s, loss=13.6, sub_class_accuracy=0, super_class_accuracy=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train Super Class loss: 5.154709285892219 Super Class acc: 0.46551287174224854\n",
            "Sub Class loss: 8.907699087161257 Sub Class acc: 0.020780697464942932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 val: 100%|██████████| 23/23 [00:00<00:00, 27.01batch/s, loss=13.6, sub_class_accuracy=0, super_class_accuracy=0.533]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 val Super Class loss: 4.9173444460783085 Super Class acc: 0.5299727320671082\n",
            "Sub Class loss: 8.821673120399911 Sub Class acc: 0.029972750693559647\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 train: 100%|██████████| 495/495 [00:23<00:00, 20.70batch/s, loss=13.1, sub_class_accuracy=0, super_class_accuracy=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train Super Class loss: 4.797294731240131 Super Class acc: 0.5414982438087463\n",
            "Sub Class loss: 8.618030500387892 Sub Class acc: 0.04194037243723869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 val: 100%|██████████| 23/23 [00:00<00:00, 25.76batch/s, loss=13.3, sub_class_accuracy=0, super_class_accuracy=0.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 val Super Class loss: 4.821040640897257 Super Class acc: 0.5749318599700928\n",
            "Sub Class loss: 8.693347457968896 Sub Class acc: 0.04359672963619232\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 train: 100%|██████████| 495/495 [00:23<00:00, 21.34batch/s, loss=13.6, sub_class_accuracy=0.0417, super_class_accuracy=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train Super Class loss: 4.688876484186135 Super Class acc: 0.5567205548286438\n",
            "Sub Class loss: 8.419576119629646 Sub Class acc: 0.06284739822149277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 val: 100%|██████████| 23/23 [00:00<00:00, 25.99batch/s, loss=13.7, sub_class_accuracy=0.0333, super_class_accuracy=0.467]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 val Super Class loss: 4.671958075881979 Super Class acc: 0.5885558724403381\n",
            "Sub Class loss: 8.570282187708717 Sub Class acc: 0.047683924436569214\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 train: 100%|██████████| 495/495 [00:22<00:00, 21.68batch/s, loss=13.3, sub_class_accuracy=0.0833, super_class_accuracy=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train Super Class loss: 4.634066871346218 Super Class acc: 0.5668267011642456\n",
            "Sub Class loss: 8.27061823487824 Sub Class acc: 0.0741536095738411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 val: 100%|██████████| 23/23 [00:00<00:00, 24.83batch/s, loss=12.9, sub_class_accuracy=0.0333, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 val Super Class loss: 4.67648205786375 Super Class acc: 0.5653951168060303\n",
            "Sub Class loss: 8.550964794626678 Sub Class acc: 0.058583106845617294\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 train: 100%|██████████| 495/495 [00:22<00:00, 21.55batch/s, loss=11.9, sub_class_accuracy=0.0833, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train Super Class loss: 4.598122831695666 Super Class acc: 0.5768696069717407\n",
            "Sub Class loss: 8.15479433253415 Sub Class acc: 0.08084891736507416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 val: 100%|██████████| 23/23 [00:00<00:00, 26.86batch/s, loss=13.1, sub_class_accuracy=0.0333, super_class_accuracy=0.667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 val Super Class loss: 4.62255221621542 Super Class acc: 0.580381453037262\n",
            "Sub Class loss: 8.541774128698199 Sub Class acc: 0.05040871724486351\n",
            "--------------------\n",
            "Best Super Class val acc: 0.5885558724403381\n",
            "Best Sub Class val acc: 0.058583106845617294\n",
            "Average Time taken for an epoch: 24.235797739028932 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "initial_epoch = 0\n",
        "learning_rate = 1e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb3_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Augment_Joint_EffnetB3_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0y5wmnmcTkD"
      },
      "source": [
        "###### Unfreeze some layers of the backbone network (phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a16cec-5881-4bc4-9490-4a76a643f0da",
        "id": "xk7_JjHycTkE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 40, 32, 32]           1,080\n",
            "       BatchNorm2d-2           [-1, 40, 32, 32]              80\n",
            "              SiLU-3           [-1, 40, 32, 32]               0\n",
            "            Conv2d-4           [-1, 40, 32, 32]             360\n",
            "       BatchNorm2d-5           [-1, 40, 32, 32]              80\n",
            "              SiLU-6           [-1, 40, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 40, 1, 1]               0\n",
            "            Conv2d-8             [-1, 10, 1, 1]             410\n",
            "              SiLU-9             [-1, 10, 1, 1]               0\n",
            "           Conv2d-10             [-1, 40, 1, 1]             440\n",
            "          Sigmoid-11             [-1, 40, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 40, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]             960\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-19             [-1, 24, 1, 1]               0\n",
            "           Conv2d-20              [-1, 6, 1, 1]             150\n",
            "             SiLU-21              [-1, 6, 1, 1]               0\n",
            "           Conv2d-22             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-23             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-24           [-1, 24, 32, 32]               0\n",
            "           Conv2d-25           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-27           [-1, 24, 32, 32]               0\n",
            "           MBConv-28           [-1, 24, 32, 32]               0\n",
            "           Conv2d-29          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-30          [-1, 144, 32, 32]             288\n",
            "             SiLU-31          [-1, 144, 32, 32]               0\n",
            "           Conv2d-32          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-33          [-1, 144, 16, 16]             288\n",
            "             SiLU-34          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-35            [-1, 144, 1, 1]               0\n",
            "           Conv2d-36              [-1, 6, 1, 1]             870\n",
            "             SiLU-37              [-1, 6, 1, 1]               0\n",
            "           Conv2d-38            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-39            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-40          [-1, 144, 16, 16]               0\n",
            "           Conv2d-41           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-42           [-1, 32, 16, 16]              64\n",
            "           MBConv-43           [-1, 32, 16, 16]               0\n",
            "           Conv2d-44          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-45          [-1, 192, 16, 16]             384\n",
            "             SiLU-46          [-1, 192, 16, 16]               0\n",
            "           Conv2d-47          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-48          [-1, 192, 16, 16]             384\n",
            "             SiLU-49          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-50            [-1, 192, 1, 1]               0\n",
            "           Conv2d-51              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-52              [-1, 8, 1, 1]               0\n",
            "           Conv2d-53            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-54            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-55          [-1, 192, 16, 16]               0\n",
            "           Conv2d-56           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-57           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-58           [-1, 32, 16, 16]               0\n",
            "           MBConv-59           [-1, 32, 16, 16]               0\n",
            "           Conv2d-60          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-61          [-1, 192, 16, 16]             384\n",
            "             SiLU-62          [-1, 192, 16, 16]               0\n",
            "           Conv2d-63          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-64          [-1, 192, 16, 16]             384\n",
            "             SiLU-65          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-66            [-1, 192, 1, 1]               0\n",
            "           Conv2d-67              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-68              [-1, 8, 1, 1]               0\n",
            "           Conv2d-69            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-70            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-71          [-1, 192, 16, 16]               0\n",
            "           Conv2d-72           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-73           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-74           [-1, 32, 16, 16]               0\n",
            "           MBConv-75           [-1, 32, 16, 16]               0\n",
            "           Conv2d-76          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-77          [-1, 192, 16, 16]             384\n",
            "             SiLU-78          [-1, 192, 16, 16]               0\n",
            "           Conv2d-79            [-1, 192, 8, 8]           4,800\n",
            "      BatchNorm2d-80            [-1, 192, 8, 8]             384\n",
            "             SiLU-81            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-82            [-1, 192, 1, 1]               0\n",
            "           Conv2d-83              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-84              [-1, 8, 1, 1]               0\n",
            "           Conv2d-85            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-86            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-87            [-1, 192, 8, 8]               0\n",
            "           Conv2d-88             [-1, 48, 8, 8]           9,216\n",
            "      BatchNorm2d-89             [-1, 48, 8, 8]              96\n",
            "           MBConv-90             [-1, 48, 8, 8]               0\n",
            "           Conv2d-91            [-1, 288, 8, 8]          13,824\n",
            "      BatchNorm2d-92            [-1, 288, 8, 8]             576\n",
            "             SiLU-93            [-1, 288, 8, 8]               0\n",
            "           Conv2d-94            [-1, 288, 8, 8]           7,200\n",
            "      BatchNorm2d-95            [-1, 288, 8, 8]             576\n",
            "             SiLU-96            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-97            [-1, 288, 1, 1]               0\n",
            "           Conv2d-98             [-1, 12, 1, 1]           3,468\n",
            "             SiLU-99             [-1, 12, 1, 1]               0\n",
            "          Conv2d-100            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-101            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-102            [-1, 288, 8, 8]               0\n",
            "          Conv2d-103             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-104             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-105             [-1, 48, 8, 8]               0\n",
            "          MBConv-106             [-1, 48, 8, 8]               0\n",
            "          Conv2d-107            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-108            [-1, 288, 8, 8]             576\n",
            "            SiLU-109            [-1, 288, 8, 8]               0\n",
            "          Conv2d-110            [-1, 288, 8, 8]           7,200\n",
            "     BatchNorm2d-111            [-1, 288, 8, 8]             576\n",
            "            SiLU-112            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-113            [-1, 288, 1, 1]               0\n",
            "          Conv2d-114             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-115             [-1, 12, 1, 1]               0\n",
            "          Conv2d-116            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-117            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-118            [-1, 288, 8, 8]               0\n",
            "          Conv2d-119             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-121             [-1, 48, 8, 8]               0\n",
            "          MBConv-122             [-1, 48, 8, 8]               0\n",
            "          Conv2d-123            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-124            [-1, 288, 8, 8]             576\n",
            "            SiLU-125            [-1, 288, 8, 8]               0\n",
            "          Conv2d-126            [-1, 288, 4, 4]           2,592\n",
            "     BatchNorm2d-127            [-1, 288, 4, 4]             576\n",
            "            SiLU-128            [-1, 288, 4, 4]               0\n",
            "AdaptiveAvgPool2d-129            [-1, 288, 1, 1]               0\n",
            "          Conv2d-130             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-131             [-1, 12, 1, 1]               0\n",
            "          Conv2d-132            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-133            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-134            [-1, 288, 4, 4]               0\n",
            "          Conv2d-135             [-1, 96, 4, 4]          27,648\n",
            "     BatchNorm2d-136             [-1, 96, 4, 4]             192\n",
            "          MBConv-137             [-1, 96, 4, 4]               0\n",
            "          Conv2d-138            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-139            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-140            [-1, 576, 4, 4]               0\n",
            "          Conv2d-141            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-142            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-143            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-144            [-1, 576, 1, 1]               0\n",
            "          Conv2d-145             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-146             [-1, 24, 1, 1]               0\n",
            "          Conv2d-147            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-148            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-149            [-1, 576, 4, 4]               0\n",
            "          Conv2d-150             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-151             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-152             [-1, 96, 4, 4]               0\n",
            "          MBConv-153             [-1, 96, 4, 4]               0\n",
            "          Conv2d-154            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-155            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-156            [-1, 576, 4, 4]               0\n",
            "          Conv2d-157            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-158            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-159            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-160            [-1, 576, 1, 1]               0\n",
            "          Conv2d-161             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-162             [-1, 24, 1, 1]               0\n",
            "          Conv2d-163            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-164            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-165            [-1, 576, 4, 4]               0\n",
            "          Conv2d-166             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-167             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-168             [-1, 96, 4, 4]               0\n",
            "          MBConv-169             [-1, 96, 4, 4]               0\n",
            "          Conv2d-170            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-171            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-172            [-1, 576, 4, 4]               0\n",
            "          Conv2d-173            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-174            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-175            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-176            [-1, 576, 1, 1]               0\n",
            "          Conv2d-177             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-178             [-1, 24, 1, 1]               0\n",
            "          Conv2d-179            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-180            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-181            [-1, 576, 4, 4]               0\n",
            "          Conv2d-182             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-183             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-184             [-1, 96, 4, 4]               0\n",
            "          MBConv-185             [-1, 96, 4, 4]               0\n",
            "          Conv2d-186            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-187            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-188            [-1, 576, 4, 4]               0\n",
            "          Conv2d-189            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-190            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-191            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-192            [-1, 576, 1, 1]               0\n",
            "          Conv2d-193             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-194             [-1, 24, 1, 1]               0\n",
            "          Conv2d-195            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-196            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-197            [-1, 576, 4, 4]               0\n",
            "          Conv2d-198             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-199             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-200             [-1, 96, 4, 4]               0\n",
            "          MBConv-201             [-1, 96, 4, 4]               0\n",
            "          Conv2d-202            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-203            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-204            [-1, 576, 4, 4]               0\n",
            "          Conv2d-205            [-1, 576, 4, 4]          14,400\n",
            "     BatchNorm2d-206            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-207            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-208            [-1, 576, 1, 1]               0\n",
            "          Conv2d-209             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-210             [-1, 24, 1, 1]               0\n",
            "          Conv2d-211            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-212            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-213            [-1, 576, 4, 4]               0\n",
            "          Conv2d-214            [-1, 136, 4, 4]          78,336\n",
            "     BatchNorm2d-215            [-1, 136, 4, 4]             272\n",
            "          MBConv-216            [-1, 136, 4, 4]               0\n",
            "          Conv2d-217            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-218            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-219            [-1, 816, 4, 4]               0\n",
            "          Conv2d-220            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-221            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-222            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-223            [-1, 816, 1, 1]               0\n",
            "          Conv2d-224             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-225             [-1, 34, 1, 1]               0\n",
            "          Conv2d-226            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-227            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-228            [-1, 816, 4, 4]               0\n",
            "          Conv2d-229            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-230            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-231            [-1, 136, 4, 4]               0\n",
            "          MBConv-232            [-1, 136, 4, 4]               0\n",
            "          Conv2d-233            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-234            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-235            [-1, 816, 4, 4]               0\n",
            "          Conv2d-236            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-237            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-238            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-239            [-1, 816, 1, 1]               0\n",
            "          Conv2d-240             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-241             [-1, 34, 1, 1]               0\n",
            "          Conv2d-242            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-243            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-244            [-1, 816, 4, 4]               0\n",
            "          Conv2d-245            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-246            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-247            [-1, 136, 4, 4]               0\n",
            "          MBConv-248            [-1, 136, 4, 4]               0\n",
            "          Conv2d-249            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-250            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-251            [-1, 816, 4, 4]               0\n",
            "          Conv2d-252            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-253            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-254            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-255            [-1, 816, 1, 1]               0\n",
            "          Conv2d-256             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-257             [-1, 34, 1, 1]               0\n",
            "          Conv2d-258            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-259            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-260            [-1, 816, 4, 4]               0\n",
            "          Conv2d-261            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-262            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-263            [-1, 136, 4, 4]               0\n",
            "          MBConv-264            [-1, 136, 4, 4]               0\n",
            "          Conv2d-265            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-266            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-267            [-1, 816, 4, 4]               0\n",
            "          Conv2d-268            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-269            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-270            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-271            [-1, 816, 1, 1]               0\n",
            "          Conv2d-272             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-273             [-1, 34, 1, 1]               0\n",
            "          Conv2d-274            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-275            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-276            [-1, 816, 4, 4]               0\n",
            "          Conv2d-277            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-278            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-279            [-1, 136, 4, 4]               0\n",
            "          MBConv-280            [-1, 136, 4, 4]               0\n",
            "          Conv2d-281            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-282            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-283            [-1, 816, 4, 4]               0\n",
            "          Conv2d-284            [-1, 816, 2, 2]          20,400\n",
            "     BatchNorm2d-285            [-1, 816, 2, 2]           1,632\n",
            "            SiLU-286            [-1, 816, 2, 2]               0\n",
            "AdaptiveAvgPool2d-287            [-1, 816, 1, 1]               0\n",
            "          Conv2d-288             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-289             [-1, 34, 1, 1]               0\n",
            "          Conv2d-290            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-291            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-292            [-1, 816, 2, 2]               0\n",
            "          Conv2d-293            [-1, 232, 2, 2]         189,312\n",
            "     BatchNorm2d-294            [-1, 232, 2, 2]             464\n",
            "          MBConv-295            [-1, 232, 2, 2]               0\n",
            "          Conv2d-296           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-297           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-298           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-299           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-300           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-301           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-302           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-303             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-304             [-1, 58, 1, 1]               0\n",
            "          Conv2d-305           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-306           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-307           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-308            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-309            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-310            [-1, 232, 2, 2]               0\n",
            "          MBConv-311            [-1, 232, 2, 2]               0\n",
            "          Conv2d-312           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-313           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-314           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-315           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-316           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-317           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-318           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-319             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-320             [-1, 58, 1, 1]               0\n",
            "          Conv2d-321           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-322           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-323           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-324            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-325            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-326            [-1, 232, 2, 2]               0\n",
            "          MBConv-327            [-1, 232, 2, 2]               0\n",
            "          Conv2d-328           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-329           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-330           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-331           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-332           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-333           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-334           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-335             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-336             [-1, 58, 1, 1]               0\n",
            "          Conv2d-337           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-338           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-339           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-340            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-341            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-342            [-1, 232, 2, 2]               0\n",
            "          MBConv-343            [-1, 232, 2, 2]               0\n",
            "          Conv2d-344           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-345           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-346           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-347           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-348           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-349           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-350           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-351             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-352             [-1, 58, 1, 1]               0\n",
            "          Conv2d-353           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-354           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-355           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-356            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-357            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-358            [-1, 232, 2, 2]               0\n",
            "          MBConv-359            [-1, 232, 2, 2]               0\n",
            "          Conv2d-360           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-361           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-362           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-363           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-364           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-365           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-366           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-367             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-368             [-1, 58, 1, 1]               0\n",
            "          Conv2d-369           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-370           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-371           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-372            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-373            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-374            [-1, 232, 2, 2]               0\n",
            "          MBConv-375            [-1, 232, 2, 2]               0\n",
            "          Conv2d-376           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-377           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-378           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1392, 2, 2]          12,528\n",
            "     BatchNorm2d-380           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-381           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-382           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-383             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-384             [-1, 58, 1, 1]               0\n",
            "          Conv2d-385           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-386           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-387           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-388            [-1, 384, 2, 2]         534,528\n",
            "     BatchNorm2d-389            [-1, 384, 2, 2]             768\n",
            "          MBConv-390            [-1, 384, 2, 2]               0\n",
            "          Conv2d-391           [-1, 2304, 2, 2]         884,736\n",
            "     BatchNorm2d-392           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-393           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-394           [-1, 2304, 2, 2]          20,736\n",
            "     BatchNorm2d-395           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-396           [-1, 2304, 2, 2]               0\n",
            "AdaptiveAvgPool2d-397           [-1, 2304, 1, 1]               0\n",
            "          Conv2d-398             [-1, 96, 1, 1]         221,280\n",
            "            SiLU-399             [-1, 96, 1, 1]               0\n",
            "          Conv2d-400           [-1, 2304, 1, 1]         223,488\n",
            "         Sigmoid-401           [-1, 2304, 1, 1]               0\n",
            "SqueezeExcitation-402           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-403            [-1, 384, 2, 2]         884,736\n",
            "     BatchNorm2d-404            [-1, 384, 2, 2]             768\n",
            " StochasticDepth-405            [-1, 384, 2, 2]               0\n",
            "          MBConv-406            [-1, 384, 2, 2]               0\n",
            "          Conv2d-407           [-1, 1536, 2, 2]         589,824\n",
            "     BatchNorm2d-408           [-1, 1536, 2, 2]           3,072\n",
            "            SiLU-409           [-1, 1536, 2, 2]               0\n",
            "AdaptiveAvgPool2d-410           [-1, 1536, 1, 1]               0\n",
            "        Identity-411                 [-1, 1536]               0\n",
            "    EfficientNet-412                 [-1, 1536]               0\n",
            "          Linear-413                    [-1, 3]           4,611\n",
            "          Linear-414                   [-1, 89]         136,793\n",
            "================================================================\n",
            "Total params: 10,837,636\n",
            "Trainable params: 4,018,518\n",
            "Non-trainable params: 6,819,118\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 28.31\n",
            "Params size (MB): 41.34\n",
            "Estimated Total Size (MB): 69.70\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with some backbone frozen)\n",
        "for param in effnetb3_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in effnetb3_joint_model.backbone.features[:7].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(effnetb3_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb3_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89cfd11e-a283-47d9-d519-2d067e0b35b8",
        "id": "oxkZbvqycTkE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 train: 100%|██████████| 495/495 [00:25<00:00, 19.24batch/s, loss=10.1, sub_class_accuracy=0.292, super_class_accuracy=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train Super Class loss: 4.209537612271466 Super Class acc: 0.6260105967521667\n",
            "Sub Class loss: 7.664932960570009 Sub Class acc: 0.10680899769067764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 val: 100%|██████████| 23/23 [00:00<00:00, 26.60batch/s, loss=12.1, sub_class_accuracy=0.0333, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 val Super Class loss: 3.8054716846923413 Super Class acc: 0.6743869185447693\n",
            "Sub Class loss: 7.769146157870176 Sub Class acc: 0.09945503622293472\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 train: 100%|██████████| 495/495 [00:27<00:00, 18.31batch/s, loss=10.4, sub_class_accuracy=0.25, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train Super Class loss: 3.7797248012613562 Super Class acc: 0.671298623085022\n",
            "Sub Class loss: 7.039763798070352 Sub Class acc: 0.14818090200424194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 val: 100%|██████████| 23/23 [00:00<00:00, 26.34batch/s, loss=11.6, sub_class_accuracy=0.1, super_class_accuracy=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 val Super Class loss: 3.830016174173485 Super Class acc: 0.6798365116119385\n",
            "Sub Class loss: 7.554420721953181 Sub Class acc: 0.11580381542444229\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 train: 100%|██████████| 495/495 [00:25<00:00, 19.34batch/s, loss=8.86, sub_class_accuracy=0.125, super_class_accuracy=0.792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train Super Class loss: 3.5806321063205533 Super Class acc: 0.6884158849716187\n",
            "Sub Class loss: 6.66895954773967 Sub Class acc: 0.17445679008960724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 val: 100%|██████████| 23/23 [00:00<00:00, 27.26batch/s, loss=12, sub_class_accuracy=0.0667, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 val Super Class loss: 3.7332749374880776 Super Class acc: 0.6607629060745239\n",
            "Sub Class loss: 7.52568271179615 Sub Class acc: 0.10762942582368851\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 train: 100%|██████████| 495/495 [00:25<00:00, 19.20batch/s, loss=10.5, sub_class_accuracy=0.167, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 train Super Class loss: 3.357493525927208 Super Class acc: 0.7140601277351379\n",
            "Sub Class loss: 6.375044985333135 Sub Class acc: 0.20149065554141998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 val: 100%|██████████| 23/23 [00:00<00:00, 26.09batch/s, loss=12.2, sub_class_accuracy=0.0333, super_class_accuracy=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 val Super Class loss: 3.6458208052598815 Super Class acc: 0.6798365116119385\n",
            "Sub Class loss: 7.480375128805799 Sub Class acc: 0.09809264540672302\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 train: 100%|██████████| 495/495 [00:26<00:00, 19.03batch/s, loss=8.67, sub_class_accuracy=0.208, super_class_accuracy=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 train Super Class loss: 3.239613444652143 Super Class acc: 0.7285245060920715\n",
            "Sub Class loss: 6.086754673836869 Sub Class acc: 0.22909297049045563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 val: 100%|██████████| 23/23 [00:00<00:00, 26.43batch/s, loss=11.8, sub_class_accuracy=0.0333, super_class_accuracy=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 val Super Class loss: 3.508326636185763 Super Class acc: 0.6934604644775391\n",
            "Sub Class loss: 7.519376099921702 Sub Class acc: 0.1089918240904808\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 train: 100%|██████████| 495/495 [00:26<00:00, 18.47batch/s, loss=9.05, sub_class_accuracy=0.333, super_class_accuracy=0.792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 train Super Class loss: 3.100412232277067 Super Class acc: 0.7350934743881226\n",
            "Sub Class loss: 5.826086495367188 Sub Class acc: 0.24955785274505615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 val: 100%|██████████| 23/23 [00:01<00:00, 18.84batch/s, loss=12.4, sub_class_accuracy=0.167, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 val Super Class loss: 3.706071711366118 Super Class acc: 0.6594005227088928\n",
            "Sub Class loss: 7.559822264419265 Sub Class acc: 0.13079018890857697\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 train: 100%|██████████| 495/495 [00:26<00:00, 19.00batch/s, loss=7.04, sub_class_accuracy=0.375, super_class_accuracy=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 train Super Class loss: 2.9917170105858726 Super Class acc: 0.7468418478965759\n",
            "Sub Class loss: 5.591209875928928 Sub Class acc: 0.279560387134552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 val: 100%|██████████| 23/23 [00:00<00:00, 25.92batch/s, loss=12.1, sub_class_accuracy=0.133, super_class_accuracy=0.667]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 val Super Class loss: 3.7814724071798924 Super Class acc: 0.6893733143806458\n",
            "Sub Class loss: 7.7429101629543045 Sub Class acc: 0.10762942582368851\n",
            "--------------------\n",
            "Best Super Class val acc: 0.6934604644775391\n",
            "Best Sub Class val acc: 0.13079018890857697\n",
            "Average Time taken for an epoch: 27.20611776624407 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 7\n",
        "initial_epoch = 5\n",
        "learning_rate = 3e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb3_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Augment_Joint_EffnetB3_semi_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LOrX8CFcTkE"
      },
      "source": [
        "###### Unfreeze all the layers in the network (phase 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f641cea-fce6-4e7a-c38b-fe07f9f3346e",
        "id": "MRT5m4E1cTkE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 40, 32, 32]           1,080\n",
            "       BatchNorm2d-2           [-1, 40, 32, 32]              80\n",
            "              SiLU-3           [-1, 40, 32, 32]               0\n",
            "            Conv2d-4           [-1, 40, 32, 32]             360\n",
            "       BatchNorm2d-5           [-1, 40, 32, 32]              80\n",
            "              SiLU-6           [-1, 40, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 40, 1, 1]               0\n",
            "            Conv2d-8             [-1, 10, 1, 1]             410\n",
            "              SiLU-9             [-1, 10, 1, 1]               0\n",
            "           Conv2d-10             [-1, 40, 1, 1]             440\n",
            "          Sigmoid-11             [-1, 40, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 40, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]             960\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-19             [-1, 24, 1, 1]               0\n",
            "           Conv2d-20              [-1, 6, 1, 1]             150\n",
            "             SiLU-21              [-1, 6, 1, 1]               0\n",
            "           Conv2d-22             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-23             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-24           [-1, 24, 32, 32]               0\n",
            "           Conv2d-25           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-27           [-1, 24, 32, 32]               0\n",
            "           MBConv-28           [-1, 24, 32, 32]               0\n",
            "           Conv2d-29          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-30          [-1, 144, 32, 32]             288\n",
            "             SiLU-31          [-1, 144, 32, 32]               0\n",
            "           Conv2d-32          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-33          [-1, 144, 16, 16]             288\n",
            "             SiLU-34          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-35            [-1, 144, 1, 1]               0\n",
            "           Conv2d-36              [-1, 6, 1, 1]             870\n",
            "             SiLU-37              [-1, 6, 1, 1]               0\n",
            "           Conv2d-38            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-39            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-40          [-1, 144, 16, 16]               0\n",
            "           Conv2d-41           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-42           [-1, 32, 16, 16]              64\n",
            "           MBConv-43           [-1, 32, 16, 16]               0\n",
            "           Conv2d-44          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-45          [-1, 192, 16, 16]             384\n",
            "             SiLU-46          [-1, 192, 16, 16]               0\n",
            "           Conv2d-47          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-48          [-1, 192, 16, 16]             384\n",
            "             SiLU-49          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-50            [-1, 192, 1, 1]               0\n",
            "           Conv2d-51              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-52              [-1, 8, 1, 1]               0\n",
            "           Conv2d-53            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-54            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-55          [-1, 192, 16, 16]               0\n",
            "           Conv2d-56           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-57           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-58           [-1, 32, 16, 16]               0\n",
            "           MBConv-59           [-1, 32, 16, 16]               0\n",
            "           Conv2d-60          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-61          [-1, 192, 16, 16]             384\n",
            "             SiLU-62          [-1, 192, 16, 16]               0\n",
            "           Conv2d-63          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-64          [-1, 192, 16, 16]             384\n",
            "             SiLU-65          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-66            [-1, 192, 1, 1]               0\n",
            "           Conv2d-67              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-68              [-1, 8, 1, 1]               0\n",
            "           Conv2d-69            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-70            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-71          [-1, 192, 16, 16]               0\n",
            "           Conv2d-72           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-73           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-74           [-1, 32, 16, 16]               0\n",
            "           MBConv-75           [-1, 32, 16, 16]               0\n",
            "           Conv2d-76          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-77          [-1, 192, 16, 16]             384\n",
            "             SiLU-78          [-1, 192, 16, 16]               0\n",
            "           Conv2d-79            [-1, 192, 8, 8]           4,800\n",
            "      BatchNorm2d-80            [-1, 192, 8, 8]             384\n",
            "             SiLU-81            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-82            [-1, 192, 1, 1]               0\n",
            "           Conv2d-83              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-84              [-1, 8, 1, 1]               0\n",
            "           Conv2d-85            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-86            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-87            [-1, 192, 8, 8]               0\n",
            "           Conv2d-88             [-1, 48, 8, 8]           9,216\n",
            "      BatchNorm2d-89             [-1, 48, 8, 8]              96\n",
            "           MBConv-90             [-1, 48, 8, 8]               0\n",
            "           Conv2d-91            [-1, 288, 8, 8]          13,824\n",
            "      BatchNorm2d-92            [-1, 288, 8, 8]             576\n",
            "             SiLU-93            [-1, 288, 8, 8]               0\n",
            "           Conv2d-94            [-1, 288, 8, 8]           7,200\n",
            "      BatchNorm2d-95            [-1, 288, 8, 8]             576\n",
            "             SiLU-96            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-97            [-1, 288, 1, 1]               0\n",
            "           Conv2d-98             [-1, 12, 1, 1]           3,468\n",
            "             SiLU-99             [-1, 12, 1, 1]               0\n",
            "          Conv2d-100            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-101            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-102            [-1, 288, 8, 8]               0\n",
            "          Conv2d-103             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-104             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-105             [-1, 48, 8, 8]               0\n",
            "          MBConv-106             [-1, 48, 8, 8]               0\n",
            "          Conv2d-107            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-108            [-1, 288, 8, 8]             576\n",
            "            SiLU-109            [-1, 288, 8, 8]               0\n",
            "          Conv2d-110            [-1, 288, 8, 8]           7,200\n",
            "     BatchNorm2d-111            [-1, 288, 8, 8]             576\n",
            "            SiLU-112            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-113            [-1, 288, 1, 1]               0\n",
            "          Conv2d-114             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-115             [-1, 12, 1, 1]               0\n",
            "          Conv2d-116            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-117            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-118            [-1, 288, 8, 8]               0\n",
            "          Conv2d-119             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-121             [-1, 48, 8, 8]               0\n",
            "          MBConv-122             [-1, 48, 8, 8]               0\n",
            "          Conv2d-123            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-124            [-1, 288, 8, 8]             576\n",
            "            SiLU-125            [-1, 288, 8, 8]               0\n",
            "          Conv2d-126            [-1, 288, 4, 4]           2,592\n",
            "     BatchNorm2d-127            [-1, 288, 4, 4]             576\n",
            "            SiLU-128            [-1, 288, 4, 4]               0\n",
            "AdaptiveAvgPool2d-129            [-1, 288, 1, 1]               0\n",
            "          Conv2d-130             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-131             [-1, 12, 1, 1]               0\n",
            "          Conv2d-132            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-133            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-134            [-1, 288, 4, 4]               0\n",
            "          Conv2d-135             [-1, 96, 4, 4]          27,648\n",
            "     BatchNorm2d-136             [-1, 96, 4, 4]             192\n",
            "          MBConv-137             [-1, 96, 4, 4]               0\n",
            "          Conv2d-138            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-139            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-140            [-1, 576, 4, 4]               0\n",
            "          Conv2d-141            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-142            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-143            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-144            [-1, 576, 1, 1]               0\n",
            "          Conv2d-145             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-146             [-1, 24, 1, 1]               0\n",
            "          Conv2d-147            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-148            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-149            [-1, 576, 4, 4]               0\n",
            "          Conv2d-150             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-151             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-152             [-1, 96, 4, 4]               0\n",
            "          MBConv-153             [-1, 96, 4, 4]               0\n",
            "          Conv2d-154            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-155            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-156            [-1, 576, 4, 4]               0\n",
            "          Conv2d-157            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-158            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-159            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-160            [-1, 576, 1, 1]               0\n",
            "          Conv2d-161             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-162             [-1, 24, 1, 1]               0\n",
            "          Conv2d-163            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-164            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-165            [-1, 576, 4, 4]               0\n",
            "          Conv2d-166             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-167             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-168             [-1, 96, 4, 4]               0\n",
            "          MBConv-169             [-1, 96, 4, 4]               0\n",
            "          Conv2d-170            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-171            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-172            [-1, 576, 4, 4]               0\n",
            "          Conv2d-173            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-174            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-175            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-176            [-1, 576, 1, 1]               0\n",
            "          Conv2d-177             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-178             [-1, 24, 1, 1]               0\n",
            "          Conv2d-179            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-180            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-181            [-1, 576, 4, 4]               0\n",
            "          Conv2d-182             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-183             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-184             [-1, 96, 4, 4]               0\n",
            "          MBConv-185             [-1, 96, 4, 4]               0\n",
            "          Conv2d-186            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-187            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-188            [-1, 576, 4, 4]               0\n",
            "          Conv2d-189            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-190            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-191            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-192            [-1, 576, 1, 1]               0\n",
            "          Conv2d-193             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-194             [-1, 24, 1, 1]               0\n",
            "          Conv2d-195            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-196            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-197            [-1, 576, 4, 4]               0\n",
            "          Conv2d-198             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-199             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-200             [-1, 96, 4, 4]               0\n",
            "          MBConv-201             [-1, 96, 4, 4]               0\n",
            "          Conv2d-202            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-203            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-204            [-1, 576, 4, 4]               0\n",
            "          Conv2d-205            [-1, 576, 4, 4]          14,400\n",
            "     BatchNorm2d-206            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-207            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-208            [-1, 576, 1, 1]               0\n",
            "          Conv2d-209             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-210             [-1, 24, 1, 1]               0\n",
            "          Conv2d-211            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-212            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-213            [-1, 576, 4, 4]               0\n",
            "          Conv2d-214            [-1, 136, 4, 4]          78,336\n",
            "     BatchNorm2d-215            [-1, 136, 4, 4]             272\n",
            "          MBConv-216            [-1, 136, 4, 4]               0\n",
            "          Conv2d-217            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-218            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-219            [-1, 816, 4, 4]               0\n",
            "          Conv2d-220            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-221            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-222            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-223            [-1, 816, 1, 1]               0\n",
            "          Conv2d-224             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-225             [-1, 34, 1, 1]               0\n",
            "          Conv2d-226            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-227            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-228            [-1, 816, 4, 4]               0\n",
            "          Conv2d-229            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-230            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-231            [-1, 136, 4, 4]               0\n",
            "          MBConv-232            [-1, 136, 4, 4]               0\n",
            "          Conv2d-233            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-234            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-235            [-1, 816, 4, 4]               0\n",
            "          Conv2d-236            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-237            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-238            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-239            [-1, 816, 1, 1]               0\n",
            "          Conv2d-240             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-241             [-1, 34, 1, 1]               0\n",
            "          Conv2d-242            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-243            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-244            [-1, 816, 4, 4]               0\n",
            "          Conv2d-245            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-246            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-247            [-1, 136, 4, 4]               0\n",
            "          MBConv-248            [-1, 136, 4, 4]               0\n",
            "          Conv2d-249            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-250            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-251            [-1, 816, 4, 4]               0\n",
            "          Conv2d-252            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-253            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-254            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-255            [-1, 816, 1, 1]               0\n",
            "          Conv2d-256             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-257             [-1, 34, 1, 1]               0\n",
            "          Conv2d-258            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-259            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-260            [-1, 816, 4, 4]               0\n",
            "          Conv2d-261            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-262            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-263            [-1, 136, 4, 4]               0\n",
            "          MBConv-264            [-1, 136, 4, 4]               0\n",
            "          Conv2d-265            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-266            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-267            [-1, 816, 4, 4]               0\n",
            "          Conv2d-268            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-269            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-270            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-271            [-1, 816, 1, 1]               0\n",
            "          Conv2d-272             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-273             [-1, 34, 1, 1]               0\n",
            "          Conv2d-274            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-275            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-276            [-1, 816, 4, 4]               0\n",
            "          Conv2d-277            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-278            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-279            [-1, 136, 4, 4]               0\n",
            "          MBConv-280            [-1, 136, 4, 4]               0\n",
            "          Conv2d-281            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-282            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-283            [-1, 816, 4, 4]               0\n",
            "          Conv2d-284            [-1, 816, 2, 2]          20,400\n",
            "     BatchNorm2d-285            [-1, 816, 2, 2]           1,632\n",
            "            SiLU-286            [-1, 816, 2, 2]               0\n",
            "AdaptiveAvgPool2d-287            [-1, 816, 1, 1]               0\n",
            "          Conv2d-288             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-289             [-1, 34, 1, 1]               0\n",
            "          Conv2d-290            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-291            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-292            [-1, 816, 2, 2]               0\n",
            "          Conv2d-293            [-1, 232, 2, 2]         189,312\n",
            "     BatchNorm2d-294            [-1, 232, 2, 2]             464\n",
            "          MBConv-295            [-1, 232, 2, 2]               0\n",
            "          Conv2d-296           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-297           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-298           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-299           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-300           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-301           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-302           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-303             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-304             [-1, 58, 1, 1]               0\n",
            "          Conv2d-305           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-306           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-307           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-308            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-309            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-310            [-1, 232, 2, 2]               0\n",
            "          MBConv-311            [-1, 232, 2, 2]               0\n",
            "          Conv2d-312           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-313           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-314           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-315           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-316           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-317           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-318           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-319             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-320             [-1, 58, 1, 1]               0\n",
            "          Conv2d-321           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-322           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-323           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-324            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-325            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-326            [-1, 232, 2, 2]               0\n",
            "          MBConv-327            [-1, 232, 2, 2]               0\n",
            "          Conv2d-328           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-329           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-330           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-331           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-332           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-333           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-334           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-335             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-336             [-1, 58, 1, 1]               0\n",
            "          Conv2d-337           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-338           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-339           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-340            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-341            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-342            [-1, 232, 2, 2]               0\n",
            "          MBConv-343            [-1, 232, 2, 2]               0\n",
            "          Conv2d-344           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-345           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-346           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-347           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-348           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-349           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-350           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-351             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-352             [-1, 58, 1, 1]               0\n",
            "          Conv2d-353           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-354           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-355           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-356            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-357            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-358            [-1, 232, 2, 2]               0\n",
            "          MBConv-359            [-1, 232, 2, 2]               0\n",
            "          Conv2d-360           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-361           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-362           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-363           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-364           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-365           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-366           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-367             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-368             [-1, 58, 1, 1]               0\n",
            "          Conv2d-369           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-370           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-371           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-372            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-373            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-374            [-1, 232, 2, 2]               0\n",
            "          MBConv-375            [-1, 232, 2, 2]               0\n",
            "          Conv2d-376           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-377           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-378           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1392, 2, 2]          12,528\n",
            "     BatchNorm2d-380           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-381           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-382           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-383             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-384             [-1, 58, 1, 1]               0\n",
            "          Conv2d-385           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-386           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-387           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-388            [-1, 384, 2, 2]         534,528\n",
            "     BatchNorm2d-389            [-1, 384, 2, 2]             768\n",
            "          MBConv-390            [-1, 384, 2, 2]               0\n",
            "          Conv2d-391           [-1, 2304, 2, 2]         884,736\n",
            "     BatchNorm2d-392           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-393           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-394           [-1, 2304, 2, 2]          20,736\n",
            "     BatchNorm2d-395           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-396           [-1, 2304, 2, 2]               0\n",
            "AdaptiveAvgPool2d-397           [-1, 2304, 1, 1]               0\n",
            "          Conv2d-398             [-1, 96, 1, 1]         221,280\n",
            "            SiLU-399             [-1, 96, 1, 1]               0\n",
            "          Conv2d-400           [-1, 2304, 1, 1]         223,488\n",
            "         Sigmoid-401           [-1, 2304, 1, 1]               0\n",
            "SqueezeExcitation-402           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-403            [-1, 384, 2, 2]         884,736\n",
            "     BatchNorm2d-404            [-1, 384, 2, 2]             768\n",
            " StochasticDepth-405            [-1, 384, 2, 2]               0\n",
            "          MBConv-406            [-1, 384, 2, 2]               0\n",
            "          Conv2d-407           [-1, 1536, 2, 2]         589,824\n",
            "     BatchNorm2d-408           [-1, 1536, 2, 2]           3,072\n",
            "            SiLU-409           [-1, 1536, 2, 2]               0\n",
            "AdaptiveAvgPool2d-410           [-1, 1536, 1, 1]               0\n",
            "        Identity-411                 [-1, 1536]               0\n",
            "    EfficientNet-412                 [-1, 1536]               0\n",
            "          Linear-413                    [-1, 3]           4,611\n",
            "          Linear-414                   [-1, 89]         136,793\n",
            "================================================================\n",
            "Total params: 10,837,636\n",
            "Trainable params: 10,837,636\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 28.31\n",
            "Params size (MB): 41.34\n",
            "Estimated Total Size (MB): 69.70\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with everything unfrozen)\n",
        "for param in effnetb3_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "summary(effnetb3_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb3_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "182fb866-7b30-4ea0-d307-c75df4c6d9d0",
        "id": "1CRxZrgecTkE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 train: 100%|██████████| 495/495 [00:55<00:00,  9.00batch/s, loss=8, sub_class_accuracy=0.292, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 train Super Class loss: 2.6805449351329522 Super Class acc: 0.7785497903823853\n",
            "Sub Class loss: 5.245873436053152 Sub Class acc: 0.30097270011901855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 val: 100%|██████████| 23/23 [00:00<00:00, 23.62batch/s, loss=8.62, sub_class_accuracy=0.2, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 val Super Class loss: 2.537018246238173 Super Class acc: 0.7942779064178467\n",
            "Sub Class loss: 6.547255312064688 Sub Class acc: 0.18528610467910767\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 train: 100%|██████████| 495/495 [00:55<00:00,  8.91batch/s, loss=5.68, sub_class_accuracy=0.417, super_class_accuracy=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 train Super Class loss: 1.8020821010723085 Super Class acc: 0.8578196167945862\n",
            "Sub Class loss: 4.058249134436709 Sub Class acc: 0.43273118138313293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 val: 100%|██████████| 23/23 [00:00<00:00, 26.06batch/s, loss=9.85, sub_class_accuracy=0.233, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 val Super Class loss: 2.585096673517201 Super Class acc: 0.8051770925521851\n",
            "Sub Class loss: 6.62879465971071 Sub Class acc: 0.20572206377983093\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 train: 100%|██████████| 495/495 [00:54<00:00,  9.11batch/s, loss=3.43, sub_class_accuracy=0.667, super_class_accuracy=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 train Super Class loss: 1.1656529360750578 Super Class acc: 0.9125189781188965\n",
            "Sub Class loss: 2.9954167668900147 Sub Class acc: 0.565563440322876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 val: 100%|██████████| 23/23 [00:00<00:00, 25.31batch/s, loss=9.17, sub_class_accuracy=0.2, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 val Super Class loss: 2.523644311145476 Super Class acc: 0.8269754648208618\n",
            "Sub Class loss: 6.816163102027831 Sub Class acc: 0.2193460464477539\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 train: 100%|██████████| 495/495 [00:54<00:00,  9.04batch/s, loss=2.53, sub_class_accuracy=0.625, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 train Super Class loss: 0.7457028958662223 Super Class acc: 0.9436584115028381\n",
            "Sub Class loss: 2.1002498919943355 Sub Class acc: 0.6931530833244324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 val: 100%|██████████| 23/23 [00:00<00:00, 25.58batch/s, loss=9.36, sub_class_accuracy=0.233, super_class_accuracy=0.767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 val Super Class loss: 2.877853246816822 Super Class acc: 0.8188011050224304\n",
            "Sub Class loss: 7.144142145681771 Sub Class acc: 0.23024523258209229\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 train: 100%|██████████| 495/495 [00:54<00:00,  9.13batch/s, loss=2.32, sub_class_accuracy=0.75, super_class_accuracy=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 train Super Class loss: 0.6332701836449591 Super Class acc: 0.9525012373924255\n",
            "Sub Class loss: 1.5787762387826505 Sub Class acc: 0.7744441628456116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 val: 100%|██████████| 23/23 [00:00<00:00, 26.12batch/s, loss=10.2, sub_class_accuracy=0.167, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 val Super Class loss: 2.8862348755146567 Super Class acc: 0.8283378481864929\n",
            "Sub Class loss: 7.481370593286665 Sub Class acc: 0.2261580377817154\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 train: 100%|██████████| 495/495 [00:53<00:00,  9.25batch/s, loss=2.16, sub_class_accuracy=0.792, super_class_accuracy=0.958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 train Super Class loss: 0.5192794179813979 Super Class acc: 0.9619125723838806\n",
            "Sub Class loss: 1.179212431705257 Sub Class acc: 0.829206645488739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 val: 100%|██████████| 23/23 [00:00<00:00, 24.77batch/s, loss=8.8, sub_class_accuracy=0.233, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 val Super Class loss: 2.9944177804266077 Super Class acc: 0.8365122675895691\n",
            "Sub Class loss: 8.034971420381634 Sub Class acc: 0.2166212499141693\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 train: 100%|██████████| 495/495 [00:55<00:00,  8.97batch/s, loss=3.12, sub_class_accuracy=0.75, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 train Super Class loss: 0.43006872330491536 Super Class acc: 0.9701869487762451\n",
            "Sub Class loss: 0.853621964234183 Sub Class acc: 0.8802425265312195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 val: 100%|██████████| 23/23 [00:00<00:00, 24.81batch/s, loss=9.82, sub_class_accuracy=0.267, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 val Super Class loss: 3.122325611455564 Super Class acc: 0.8392370343208313\n",
            "Sub Class loss: 8.219114776528174 Sub Class acc: 0.2288828343153\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 train: 100%|██████████| 495/495 [00:53<00:00,  9.17batch/s, loss=1.4, sub_class_accuracy=0.792, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 train Super Class loss: 0.3807624521525977 Super Class acc: 0.9735977649688721\n",
            "Sub Class loss: 0.7358348239184992 Sub Class acc: 0.8955280184745789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 val: 100%|██████████| 23/23 [00:00<00:00, 26.77batch/s, loss=11.4, sub_class_accuracy=0.333, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 val Super Class loss: 3.315200755316815 Super Class acc: 0.8283378481864929\n",
            "Sub Class loss: 8.42726004545955 Sub Class acc: 0.20708446204662323\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 train: 100%|██████████| 495/495 [00:54<00:00,  9.15batch/s, loss=0.986, sub_class_accuracy=0.875, super_class_accuracy=0.958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 train Super Class loss: 0.3499263991141045 Super Class acc: 0.9760611653327942\n",
            "Sub Class loss: 0.6134947946783628 Sub Class acc: 0.9123294353485107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 val: 100%|██████████| 23/23 [00:00<00:00, 25.72batch/s, loss=14, sub_class_accuracy=0.267, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 val Super Class loss: 3.7286427267890536 Super Class acc: 0.8188011050224304\n",
            "Sub Class loss: 8.757420955626776 Sub Class acc: 0.2288828343153\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 train: 100%|██████████| 495/495 [00:53<00:00,  9.30batch/s, loss=1.2, sub_class_accuracy=0.833, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 train Super Class loss: 0.3177391367052889 Super Class acc: 0.9780823588371277\n",
            "Sub Class loss: 0.5284634585510667 Sub Class acc: 0.924330472946167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 val: 100%|██████████| 23/23 [00:00<00:00, 25.96batch/s, loss=13.5, sub_class_accuracy=0.2, super_class_accuracy=0.833]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 val Super Class loss: 3.418962889698611 Super Class acc: 0.8337874412536621\n",
            "Sub Class loss: 9.241045377559818 Sub Class acc: 0.21253405511379242\n",
            "--------------------\n",
            "Best Super Class val acc: 0.8392370343208313\n",
            "Best Sub Class val acc: 0.23024523258209229\n",
            "Average Time taken for an epoch: 55.44719407558441 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "initial_epoch = 12\n",
        "learning_rate = 4e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb3_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='Augment_Joint_EffnetB3_unfrozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout + Augmented EfficientNetB3 Joint Super Sub Class"
      ],
      "metadata": {
        "id": "34SVkW_pcDU6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-XWSNZOeC6q"
      },
      "source": [
        "##### Joint training utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NVQgEoeeC6q"
      },
      "outputs": [],
      "source": [
        "# Will contain utility functions used for training the model\n",
        "import torch\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "#Training Function\n",
        "def fit_classifier(model, train_loader, val_loader, optimizer, loss_func, epochs=10, initial_epoch=0, device='cpu', name='effnetb6'):\n",
        "    '''\n",
        "    function to train a classifier model.\n",
        "    args:\n",
        "        model - the model to be trained\n",
        "        train_loader - Dataloader() for train set\n",
        "        val_loader - Dataloader() for val set\n",
        "        optimizer - optimization algorithm for updating weights\n",
        "        loss_func - loss function to be used\n",
        "    \n",
        "    keyword args:\n",
        "        epochs - Number of training epochs (default=10)\n",
        "        initial_epoch - The starting epoch\n",
        "        device - the device for training (default='cpu')\n",
        "        name - Name for saving the model\n",
        "    \n",
        "    returns: Nothing\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    model = model.to(device, non_blocking=True)\n",
        "    \n",
        "    # Save the models based on the super and sub class validation accuracies\n",
        "    best_super_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    best_sub_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    \n",
        "    #create the logger object\n",
        "    writer = SummaryWriter()\n",
        "    start_time = time.time()\n",
        "    \n",
        "    #Iterate epochs\n",
        "    for epoch in range(initial_epoch, initial_epoch + epochs):\n",
        "        #Each epoch has a training phase and validation phase\n",
        "        for phase in ['train','val']:\n",
        "            data_loader = None\n",
        "            if phase == 'train':\n",
        "                #Set train mode\n",
        "                model.train()\n",
        "                data_loader = train_loader\n",
        "            else:\n",
        "                #Set Eval mode\n",
        "                model.eval()\n",
        "                data_loader = val_loader\n",
        "          \n",
        "            running_super_loss = 0.\n",
        "            running_sub_loss = 0.\n",
        "            running_super_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            running_sub_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            \n",
        "            #tqdm for observing the progress\n",
        "            with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
        "                #Iterate batches\n",
        "                for itr, (images, super_labels, sub_labels) in enumerate(tepoch):\n",
        "                    tepoch.set_description(f\"Epoch {(epoch)} {phase}\")\n",
        "                    images = images.to(device, non_blocking=True)\n",
        "\n",
        "                    super_labels = super_labels.long().to(device, non_blocking=True)\n",
        "                    sub_labels = sub_labels.long().to(device, non_blocking=True)\n",
        "                    \n",
        "                    optimizer.zero_grad()\n",
        "                    \n",
        "                    #Set gradient calculation only for training phase\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        super_outputs, sub_outputs = model(images)\n",
        "\n",
        "                        super_loss = loss_func(super_outputs, super_labels)\n",
        "                        sub_loss = loss_func(sub_outputs, sub_labels)\n",
        "\n",
        "                        super_preds = torch.argmax(super_outputs, dim=1)\n",
        "                        sub_preds = torch.argmax(sub_outputs, dim=1)\n",
        "\n",
        "                        loss = 5 * super_loss + 2 * sub_loss\n",
        "                        \n",
        "                        #Do backprop only during training\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                    \n",
        "                    running_super_loss += 5 * super_loss.item() * images.size(0)\n",
        "                    running_sub_loss += 2 * sub_loss.item() * images.size(0)\n",
        "                    running_super_corrects += torch.sum(super_preds == super_labels)\n",
        "                    running_sub_corrects += torch.sum(sub_preds == sub_labels)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        writer.add_scalar(\"Batch_Loss/\" + phase, loss.item(), epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Super_Class/\" + phase,\n",
        "                                          (torch.sum(super_preds == super_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Sub_Class/\" + phase,\n",
        "                                          (torch.sum(sub_preds == sub_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                    \n",
        "                    tepoch.set_postfix(loss=loss.item(),\n",
        "                              super_class_accuracy=(torch.sum(super_preds == super_labels)/(images.shape[0])).item(),\n",
        "                              sub_class_accuracy=(torch.sum(sub_preds == sub_labels)/(images.shape[0])).item())\n",
        "                \n",
        "                epoch_super_loss = running_super_loss / len(data_loader.dataset)\n",
        "                epoch_sub_loss = running_sub_loss / len(data_loader.dataset)\n",
        "                epoch_super_acc = running_super_corrects.float() / (len(data_loader.dataset))\n",
        "                epoch_sub_acc = running_sub_corrects.float() / (len(data_loader.dataset))\n",
        "\n",
        "                print(f\"Epoch {(epoch)} {phase} Super Class loss: {epoch_super_loss} Super Class acc: {epoch_super_acc.item()}\")\n",
        "                print(f\"Sub Class loss: {epoch_sub_loss} Sub Class acc: {epoch_sub_acc.item()}\")\n",
        "\n",
        "                writer.add_scalar(\"Epoch_Loss_Super_Class/\" + phase, epoch_super_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Loss_Sub_Class/\" + phase, epoch_sub_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Super_Class/\" + phase, epoch_super_acc, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Sub_Class/\" + phase, epoch_sub_acc, epoch)\n",
        "                \n",
        "                # #Saving best model based on super class accuracy\n",
        "                if phase == 'val' and epoch_super_acc > best_super_acc:\n",
        "                    best_super_acc = epoch_super_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SuperClass.pth\")\n",
        "\n",
        "                #Saving best model based on sub class accuracy\n",
        "                if phase == 'val' and epoch_sub_acc > best_sub_acc:\n",
        "                    best_sub_acc = epoch_sub_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SubClass.pth\")    \n",
        "                \n",
        "        print('-'*20)\n",
        "    \n",
        "    #End of Training \n",
        "    end_time = time.time()  \n",
        "    writer.close()\n",
        "    print('Best Super Class val acc: {}'.format(best_super_acc.item()))\n",
        "    print('Best Sub Class val acc: {}'.format(best_sub_acc.item()))\n",
        "    print(f\"Average Time taken for an epoch: {(end_time - start_time)/epochs} sec\")\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e178FOdcTkD"
      },
      "source": [
        "##### Create the EfficientNetB3 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bs6c7ngcTkD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# Load the EfficientNetB3 model trained on ImageNet\n",
        "backbone_model = torchvision.models.efficientnet_b3(weights='IMAGENET1K_V1')\n",
        "backbone_model.classifier = nn.Identity()\n",
        "\n",
        "\n",
        "# Add Dropout layers after the activation function as per this paper http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf\n",
        "#backbone_model.features[0].add_module('3', nn.Dropout(p = 0.2))\n",
        "\n",
        "#backbone_model.features[1][0].block[0].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[1][1].block[0].add_module('3', nn.Dropout(p = 0.1))\n",
        "\n",
        "#backbone_model.features[2][0].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[2][1].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[2][2].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "\n",
        "backbone_model.features[3][0].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[3][1].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[3][2].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "\n",
        "backbone_model.features[4][0].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[4][1].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[4][2].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[4][3].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "\n",
        "backbone_model.features[5][0].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[5][1].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[5][2].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[5][3].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "\n",
        "backbone_model.features[6][0].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][1].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][2].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][3].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][4].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][5].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "\n",
        "backbone_model.features[7][0].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[7][1].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "\n",
        "# print(backbone_model)\n",
        "\n",
        "class EffnetB3JointModel(nn.Module):\n",
        "    def __init__(self, backbone) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        # 3 super classes\n",
        "        self.superclass = nn.Linear(in_features = 1536, out_features = 3)\n",
        "        # 89 sub classes\n",
        "        self.subclass = nn.Linear(in_features = 1536, out_features = 89)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.backbone(x)\n",
        "        super_class_out = self.superclass(out)\n",
        "        sub_class_out = self.subclass(out)\n",
        "        return super_class_out, sub_class_out\n",
        "\n",
        "# Create the baseline model\n",
        "effnetb3_joint_model = EffnetB3JointModel(backbone_model)\n",
        "effnetb3_joint_model = effnetb3_joint_model.to(device, non_blocking = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIltngkfZ9fi"
      },
      "source": [
        "##### Train the EfficientNetB3 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFwkSEVRZ9fi"
      },
      "source": [
        "###### Freeze all the layers except Classifier layers (phase 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59f3ec2-0f79-41a7-89cb-10ccda79059d",
        "id": "p1b7fL_LZ9fi"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 40, 32, 32]           1,080\n",
            "       BatchNorm2d-2           [-1, 40, 32, 32]              80\n",
            "              SiLU-3           [-1, 40, 32, 32]               0\n",
            "            Conv2d-4           [-1, 40, 32, 32]             360\n",
            "       BatchNorm2d-5           [-1, 40, 32, 32]              80\n",
            "              SiLU-6           [-1, 40, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 40, 1, 1]               0\n",
            "            Conv2d-8             [-1, 10, 1, 1]             410\n",
            "              SiLU-9             [-1, 10, 1, 1]               0\n",
            "           Conv2d-10             [-1, 40, 1, 1]             440\n",
            "          Sigmoid-11             [-1, 40, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 40, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]             960\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "          Dropout-19           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-20             [-1, 24, 1, 1]               0\n",
            "           Conv2d-21              [-1, 6, 1, 1]             150\n",
            "             SiLU-22              [-1, 6, 1, 1]               0\n",
            "           Conv2d-23             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-24             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-25           [-1, 24, 32, 32]               0\n",
            "           Conv2d-26           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-27           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-28           [-1, 24, 32, 32]               0\n",
            "           MBConv-29           [-1, 24, 32, 32]               0\n",
            "           Conv2d-30          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-31          [-1, 144, 32, 32]             288\n",
            "             SiLU-32          [-1, 144, 32, 32]               0\n",
            "           Conv2d-33          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-34          [-1, 144, 16, 16]             288\n",
            "             SiLU-35          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-36            [-1, 144, 1, 1]               0\n",
            "           Conv2d-37              [-1, 6, 1, 1]             870\n",
            "             SiLU-38              [-1, 6, 1, 1]               0\n",
            "           Conv2d-39            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-40            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-41          [-1, 144, 16, 16]               0\n",
            "           Conv2d-42           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "           MBConv-44           [-1, 32, 16, 16]               0\n",
            "           Conv2d-45          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-46          [-1, 192, 16, 16]             384\n",
            "             SiLU-47          [-1, 192, 16, 16]               0\n",
            "           Conv2d-48          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-49          [-1, 192, 16, 16]             384\n",
            "             SiLU-50          [-1, 192, 16, 16]               0\n",
            "          Dropout-51          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-52            [-1, 192, 1, 1]               0\n",
            "           Conv2d-53              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-54              [-1, 8, 1, 1]               0\n",
            "           Conv2d-55            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-56            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-57          [-1, 192, 16, 16]               0\n",
            "           Conv2d-58           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-60           [-1, 32, 16, 16]               0\n",
            "           MBConv-61           [-1, 32, 16, 16]               0\n",
            "           Conv2d-62          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-63          [-1, 192, 16, 16]             384\n",
            "             SiLU-64          [-1, 192, 16, 16]               0\n",
            "           Conv2d-65          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-66          [-1, 192, 16, 16]             384\n",
            "             SiLU-67          [-1, 192, 16, 16]               0\n",
            "          Dropout-68          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-69            [-1, 192, 1, 1]               0\n",
            "           Conv2d-70              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-71              [-1, 8, 1, 1]               0\n",
            "           Conv2d-72            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-73            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-74          [-1, 192, 16, 16]               0\n",
            "           Conv2d-75           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-76           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-77           [-1, 32, 16, 16]               0\n",
            "           MBConv-78           [-1, 32, 16, 16]               0\n",
            "           Conv2d-79          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-80          [-1, 192, 16, 16]             384\n",
            "             SiLU-81          [-1, 192, 16, 16]               0\n",
            "           Conv2d-82            [-1, 192, 8, 8]           4,800\n",
            "      BatchNorm2d-83            [-1, 192, 8, 8]             384\n",
            "             SiLU-84            [-1, 192, 8, 8]               0\n",
            "          Dropout-85            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-86            [-1, 192, 1, 1]               0\n",
            "           Conv2d-87              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-88              [-1, 8, 1, 1]               0\n",
            "           Conv2d-89            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-90            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-91            [-1, 192, 8, 8]               0\n",
            "           Conv2d-92             [-1, 48, 8, 8]           9,216\n",
            "      BatchNorm2d-93             [-1, 48, 8, 8]              96\n",
            "           MBConv-94             [-1, 48, 8, 8]               0\n",
            "           Conv2d-95            [-1, 288, 8, 8]          13,824\n",
            "      BatchNorm2d-96            [-1, 288, 8, 8]             576\n",
            "             SiLU-97            [-1, 288, 8, 8]               0\n",
            "           Conv2d-98            [-1, 288, 8, 8]           7,200\n",
            "      BatchNorm2d-99            [-1, 288, 8, 8]             576\n",
            "            SiLU-100            [-1, 288, 8, 8]               0\n",
            "         Dropout-101            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-102            [-1, 288, 1, 1]               0\n",
            "          Conv2d-103             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-104             [-1, 12, 1, 1]               0\n",
            "          Conv2d-105            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-106            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-107            [-1, 288, 8, 8]               0\n",
            "          Conv2d-108             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-109             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-110             [-1, 48, 8, 8]               0\n",
            "          MBConv-111             [-1, 48, 8, 8]               0\n",
            "          Conv2d-112            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-113            [-1, 288, 8, 8]             576\n",
            "            SiLU-114            [-1, 288, 8, 8]               0\n",
            "          Conv2d-115            [-1, 288, 8, 8]           7,200\n",
            "     BatchNorm2d-116            [-1, 288, 8, 8]             576\n",
            "            SiLU-117            [-1, 288, 8, 8]               0\n",
            "         Dropout-118            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-119            [-1, 288, 1, 1]               0\n",
            "          Conv2d-120             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-121             [-1, 12, 1, 1]               0\n",
            "          Conv2d-122            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-123            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-124            [-1, 288, 8, 8]               0\n",
            "          Conv2d-125             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-126             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-127             [-1, 48, 8, 8]               0\n",
            "          MBConv-128             [-1, 48, 8, 8]               0\n",
            "          Conv2d-129            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-130            [-1, 288, 8, 8]             576\n",
            "            SiLU-131            [-1, 288, 8, 8]               0\n",
            "          Conv2d-132            [-1, 288, 4, 4]           2,592\n",
            "     BatchNorm2d-133            [-1, 288, 4, 4]             576\n",
            "            SiLU-134            [-1, 288, 4, 4]               0\n",
            "         Dropout-135            [-1, 288, 4, 4]               0\n",
            "AdaptiveAvgPool2d-136            [-1, 288, 1, 1]               0\n",
            "          Conv2d-137             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-138             [-1, 12, 1, 1]               0\n",
            "          Conv2d-139            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-140            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-141            [-1, 288, 4, 4]               0\n",
            "          Conv2d-142             [-1, 96, 4, 4]          27,648\n",
            "     BatchNorm2d-143             [-1, 96, 4, 4]             192\n",
            "          MBConv-144             [-1, 96, 4, 4]               0\n",
            "          Conv2d-145            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-146            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-147            [-1, 576, 4, 4]               0\n",
            "          Conv2d-148            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-149            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-150            [-1, 576, 4, 4]               0\n",
            "         Dropout-151            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-152            [-1, 576, 1, 1]               0\n",
            "          Conv2d-153             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-154             [-1, 24, 1, 1]               0\n",
            "          Conv2d-155            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-156            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-157            [-1, 576, 4, 4]               0\n",
            "          Conv2d-158             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-159             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-160             [-1, 96, 4, 4]               0\n",
            "          MBConv-161             [-1, 96, 4, 4]               0\n",
            "          Conv2d-162            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-163            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-164            [-1, 576, 4, 4]               0\n",
            "          Conv2d-165            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-166            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-167            [-1, 576, 4, 4]               0\n",
            "         Dropout-168            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-169            [-1, 576, 1, 1]               0\n",
            "          Conv2d-170             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-171             [-1, 24, 1, 1]               0\n",
            "          Conv2d-172            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-173            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-174            [-1, 576, 4, 4]               0\n",
            "          Conv2d-175             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-176             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-177             [-1, 96, 4, 4]               0\n",
            "          MBConv-178             [-1, 96, 4, 4]               0\n",
            "          Conv2d-179            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-180            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-181            [-1, 576, 4, 4]               0\n",
            "          Conv2d-182            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-183            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-184            [-1, 576, 4, 4]               0\n",
            "         Dropout-185            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-186            [-1, 576, 1, 1]               0\n",
            "          Conv2d-187             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-188             [-1, 24, 1, 1]               0\n",
            "          Conv2d-189            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-190            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-191            [-1, 576, 4, 4]               0\n",
            "          Conv2d-192             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-193             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-194             [-1, 96, 4, 4]               0\n",
            "          MBConv-195             [-1, 96, 4, 4]               0\n",
            "          Conv2d-196            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-197            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-198            [-1, 576, 4, 4]               0\n",
            "          Conv2d-199            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-200            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-201            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-202            [-1, 576, 1, 1]               0\n",
            "          Conv2d-203             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-204             [-1, 24, 1, 1]               0\n",
            "          Conv2d-205            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-206            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-207            [-1, 576, 4, 4]               0\n",
            "          Conv2d-208             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-209             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-210             [-1, 96, 4, 4]               0\n",
            "          MBConv-211             [-1, 96, 4, 4]               0\n",
            "          Conv2d-212            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-213            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-214            [-1, 576, 4, 4]               0\n",
            "          Conv2d-215            [-1, 576, 4, 4]          14,400\n",
            "     BatchNorm2d-216            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-217            [-1, 576, 4, 4]               0\n",
            "         Dropout-218            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-219            [-1, 576, 1, 1]               0\n",
            "          Conv2d-220             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-221             [-1, 24, 1, 1]               0\n",
            "          Conv2d-222            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-223            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-224            [-1, 576, 4, 4]               0\n",
            "          Conv2d-225            [-1, 136, 4, 4]          78,336\n",
            "     BatchNorm2d-226            [-1, 136, 4, 4]             272\n",
            "          MBConv-227            [-1, 136, 4, 4]               0\n",
            "          Conv2d-228            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-229            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-230            [-1, 816, 4, 4]               0\n",
            "          Conv2d-231            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-232            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-233            [-1, 816, 4, 4]               0\n",
            "         Dropout-234            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-235            [-1, 816, 1, 1]               0\n",
            "          Conv2d-236             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-237             [-1, 34, 1, 1]               0\n",
            "          Conv2d-238            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-239            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-240            [-1, 816, 4, 4]               0\n",
            "          Conv2d-241            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-242            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-243            [-1, 136, 4, 4]               0\n",
            "          MBConv-244            [-1, 136, 4, 4]               0\n",
            "          Conv2d-245            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-246            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-247            [-1, 816, 4, 4]               0\n",
            "          Conv2d-248            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-249            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-250            [-1, 816, 4, 4]               0\n",
            "         Dropout-251            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-252            [-1, 816, 1, 1]               0\n",
            "          Conv2d-253             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-254             [-1, 34, 1, 1]               0\n",
            "          Conv2d-255            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-256            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-257            [-1, 816, 4, 4]               0\n",
            "          Conv2d-258            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-259            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-260            [-1, 136, 4, 4]               0\n",
            "          MBConv-261            [-1, 136, 4, 4]               0\n",
            "          Conv2d-262            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-263            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-264            [-1, 816, 4, 4]               0\n",
            "          Conv2d-265            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-266            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-267            [-1, 816, 4, 4]               0\n",
            "         Dropout-268            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-269            [-1, 816, 1, 1]               0\n",
            "          Conv2d-270             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-271             [-1, 34, 1, 1]               0\n",
            "          Conv2d-272            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-273            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-274            [-1, 816, 4, 4]               0\n",
            "          Conv2d-275            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-276            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-277            [-1, 136, 4, 4]               0\n",
            "          MBConv-278            [-1, 136, 4, 4]               0\n",
            "          Conv2d-279            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-280            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-281            [-1, 816, 4, 4]               0\n",
            "          Conv2d-282            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-283            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-284            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-285            [-1, 816, 1, 1]               0\n",
            "          Conv2d-286             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-287             [-1, 34, 1, 1]               0\n",
            "          Conv2d-288            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-289            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-290            [-1, 816, 4, 4]               0\n",
            "          Conv2d-291            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-292            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-293            [-1, 136, 4, 4]               0\n",
            "          MBConv-294            [-1, 136, 4, 4]               0\n",
            "          Conv2d-295            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-296            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-297            [-1, 816, 4, 4]               0\n",
            "          Conv2d-298            [-1, 816, 2, 2]          20,400\n",
            "     BatchNorm2d-299            [-1, 816, 2, 2]           1,632\n",
            "            SiLU-300            [-1, 816, 2, 2]               0\n",
            "         Dropout-301            [-1, 816, 2, 2]               0\n",
            "AdaptiveAvgPool2d-302            [-1, 816, 1, 1]               0\n",
            "          Conv2d-303             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-304             [-1, 34, 1, 1]               0\n",
            "          Conv2d-305            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-306            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-307            [-1, 816, 2, 2]               0\n",
            "          Conv2d-308            [-1, 232, 2, 2]         189,312\n",
            "     BatchNorm2d-309            [-1, 232, 2, 2]             464\n",
            "          MBConv-310            [-1, 232, 2, 2]               0\n",
            "          Conv2d-311           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-312           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-313           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-314           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-315           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-316           [-1, 1392, 2, 2]               0\n",
            "         Dropout-317           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-318           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-319             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-320             [-1, 58, 1, 1]               0\n",
            "          Conv2d-321           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-322           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-323           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-324            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-325            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-326            [-1, 232, 2, 2]               0\n",
            "          MBConv-327            [-1, 232, 2, 2]               0\n",
            "          Conv2d-328           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-329           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-330           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-331           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-332           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-333           [-1, 1392, 2, 2]               0\n",
            "         Dropout-334           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-335           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-336             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-337             [-1, 58, 1, 1]               0\n",
            "          Conv2d-338           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-339           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-340           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-341            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-342            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-343            [-1, 232, 2, 2]               0\n",
            "          MBConv-344            [-1, 232, 2, 2]               0\n",
            "          Conv2d-345           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-346           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-347           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-348           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-349           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-350           [-1, 1392, 2, 2]               0\n",
            "         Dropout-351           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-352           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-353             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-354             [-1, 58, 1, 1]               0\n",
            "          Conv2d-355           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-356           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-357           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-358            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-359            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-360            [-1, 232, 2, 2]               0\n",
            "          MBConv-361            [-1, 232, 2, 2]               0\n",
            "          Conv2d-362           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-363           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-364           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-365           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-366           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-367           [-1, 1392, 2, 2]               0\n",
            "         Dropout-368           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-369           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-370             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-371             [-1, 58, 1, 1]               0\n",
            "          Conv2d-372           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-373           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-374           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-375            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-376            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-377            [-1, 232, 2, 2]               0\n",
            "          MBConv-378            [-1, 232, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-380           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-381           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-382           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-383           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-384           [-1, 1392, 2, 2]               0\n",
            "         Dropout-385           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-386           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-387             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-388             [-1, 58, 1, 1]               0\n",
            "          Conv2d-389           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-390           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-391           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-392            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-393            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-394            [-1, 232, 2, 2]               0\n",
            "          MBConv-395            [-1, 232, 2, 2]               0\n",
            "          Conv2d-396           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-397           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-398           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-399           [-1, 1392, 2, 2]          12,528\n",
            "     BatchNorm2d-400           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-401           [-1, 1392, 2, 2]               0\n",
            "         Dropout-402           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-403           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-404             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-405             [-1, 58, 1, 1]               0\n",
            "          Conv2d-406           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-407           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-408           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-409            [-1, 384, 2, 2]         534,528\n",
            "     BatchNorm2d-410            [-1, 384, 2, 2]             768\n",
            "          MBConv-411            [-1, 384, 2, 2]               0\n",
            "          Conv2d-412           [-1, 2304, 2, 2]         884,736\n",
            "     BatchNorm2d-413           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-414           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-415           [-1, 2304, 2, 2]          20,736\n",
            "     BatchNorm2d-416           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-417           [-1, 2304, 2, 2]               0\n",
            "         Dropout-418           [-1, 2304, 2, 2]               0\n",
            "AdaptiveAvgPool2d-419           [-1, 2304, 1, 1]               0\n",
            "          Conv2d-420             [-1, 96, 1, 1]         221,280\n",
            "            SiLU-421             [-1, 96, 1, 1]               0\n",
            "          Conv2d-422           [-1, 2304, 1, 1]         223,488\n",
            "         Sigmoid-423           [-1, 2304, 1, 1]               0\n",
            "SqueezeExcitation-424           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-425            [-1, 384, 2, 2]         884,736\n",
            "     BatchNorm2d-426            [-1, 384, 2, 2]             768\n",
            " StochasticDepth-427            [-1, 384, 2, 2]               0\n",
            "          MBConv-428            [-1, 384, 2, 2]               0\n",
            "          Conv2d-429           [-1, 1536, 2, 2]         589,824\n",
            "     BatchNorm2d-430           [-1, 1536, 2, 2]           3,072\n",
            "            SiLU-431           [-1, 1536, 2, 2]               0\n",
            "AdaptiveAvgPool2d-432           [-1, 1536, 1, 1]               0\n",
            "        Identity-433                 [-1, 1536]               0\n",
            "    EfficientNet-434                 [-1, 1536]               0\n",
            "          Linear-435                    [-1, 3]           4,611\n",
            "          Linear-436                   [-1, 89]         136,793\n",
            "================================================================\n",
            "Total params: 10,837,636\n",
            "Trainable params: 141,404\n",
            "Non-trainable params: 10,696,232\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 30.59\n",
            "Params size (MB): 41.34\n",
            "Estimated Total Size (MB): 71.98\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with all backbone frozen)\n",
        "for param in effnetb3_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in effnetb3_joint_model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(effnetb3_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb3_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f618ab5-828a-4ce1-f343-ec5bbb0f76fb",
        "id": "oWRwxYC3Z9fi"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 train: 100%|██████████| 495/495 [00:22<00:00, 21.69batch/s, loss=14.3, sub_class_accuracy=0, super_class_accuracy=0.417]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train Super Class loss: 5.302411928931049 Super Class acc: 0.4340575933456421\n",
            "Sub Class loss: 8.969053840926346 Sub Class acc: 0.0156644769012928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 val: 100%|██████████| 23/23 [00:00<00:00, 26.75batch/s, loss=14, sub_class_accuracy=0, super_class_accuracy=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 val Super Class loss: 4.9219664492789015 Super Class acc: 0.5040872097015381\n",
            "Sub Class loss: 8.86778015531701 Sub Class acc: 0.025885557755827904\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 train: 100%|██████████| 495/495 [00:23<00:00, 20.93batch/s, loss=13.6, sub_class_accuracy=0, super_class_accuracy=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train Super Class loss: 5.120258005566522 Super Class acc: 0.48010358214378357\n",
            "Sub Class loss: 8.859968029772048 Sub Class acc: 0.02387569472193718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 val: 100%|██████████| 23/23 [00:00<00:00, 27.00batch/s, loss=13.4, sub_class_accuracy=0, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 val Super Class loss: 4.817773829688818 Super Class acc: 0.5381471514701843\n",
            "Sub Class loss: 8.767902532780203 Sub Class acc: 0.024523161351680756\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 train: 100%|██████████| 495/495 [00:22<00:00, 22.21batch/s, loss=13.8, sub_class_accuracy=0.0417, super_class_accuracy=0.417]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train Super Class loss: 5.046160516562999 Super Class acc: 0.4938731789588928\n",
            "Sub Class loss: 8.768305982827778 Sub Class acc: 0.030634159222245216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 val: 100%|██████████| 23/23 [00:00<00:00, 27.42batch/s, loss=13.2, sub_class_accuracy=0, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 val Super Class loss: 4.692465422588733 Super Class acc: 0.5667575001716614\n",
            "Sub Class loss: 8.666921748127535 Sub Class acc: 0.05040871724486351\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 train: 100%|██████████| 495/495 [00:22<00:00, 22.01batch/s, loss=13.7, sub_class_accuracy=0.0833, super_class_accuracy=0.417]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train Super Class loss: 5.008617619813965 Super Class acc: 0.5045477747917175\n",
            "Sub Class loss: 8.70051661641264 Sub Class acc: 0.033287014812231064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 val: 100%|██████████| 23/23 [00:00<00:00, 26.68batch/s, loss=13.1, sub_class_accuracy=0.0333, super_class_accuracy=0.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 val Super Class loss: 4.647954790078977 Super Class acc: 0.5790190696716309\n",
            "Sub Class loss: 8.596884504001212 Sub Class acc: 0.04904632270336151\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 train: 100%|██████████| 495/495 [00:22<00:00, 21.72batch/s, loss=13.3, sub_class_accuracy=0.0417, super_class_accuracy=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train Super Class loss: 4.979723752930407 Super Class acc: 0.5077690482139587\n",
            "Sub Class loss: 8.656200317375102 Sub Class acc: 0.03625568374991417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 val: 100%|██████████| 23/23 [00:00<00:00, 27.08batch/s, loss=12.9, sub_class_accuracy=0.0333, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 val Super Class loss: 4.60327772174934 Super Class acc: 0.5735694766044617\n",
            "Sub Class loss: 8.532769216178874 Sub Class acc: 0.05994550138711929\n",
            "--------------------\n",
            "Best Super Class val acc: 0.5790190696716309\n",
            "Best Sub Class val acc: 0.05994550138711929\n",
            "Average Time taken for an epoch: 23.87728409767151 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "initial_epoch = 0\n",
        "learning_rate = 1e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb3_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='DropOut_Augment_Joint_EffnetB3_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J8GoWL1Z9fi"
      },
      "source": [
        "###### Unfreeze some layers of the backbone network (phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd825a38-3706-4410-afcb-bbda2c9cf4f6",
        "id": "C9Xq8lvCZ9fi"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 40, 32, 32]           1,080\n",
            "       BatchNorm2d-2           [-1, 40, 32, 32]              80\n",
            "              SiLU-3           [-1, 40, 32, 32]               0\n",
            "            Conv2d-4           [-1, 40, 32, 32]             360\n",
            "       BatchNorm2d-5           [-1, 40, 32, 32]              80\n",
            "              SiLU-6           [-1, 40, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 40, 1, 1]               0\n",
            "            Conv2d-8             [-1, 10, 1, 1]             410\n",
            "              SiLU-9             [-1, 10, 1, 1]               0\n",
            "           Conv2d-10             [-1, 40, 1, 1]             440\n",
            "          Sigmoid-11             [-1, 40, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 40, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]             960\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "          Dropout-19           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-20             [-1, 24, 1, 1]               0\n",
            "           Conv2d-21              [-1, 6, 1, 1]             150\n",
            "             SiLU-22              [-1, 6, 1, 1]               0\n",
            "           Conv2d-23             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-24             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-25           [-1, 24, 32, 32]               0\n",
            "           Conv2d-26           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-27           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-28           [-1, 24, 32, 32]               0\n",
            "           MBConv-29           [-1, 24, 32, 32]               0\n",
            "           Conv2d-30          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-31          [-1, 144, 32, 32]             288\n",
            "             SiLU-32          [-1, 144, 32, 32]               0\n",
            "           Conv2d-33          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-34          [-1, 144, 16, 16]             288\n",
            "             SiLU-35          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-36            [-1, 144, 1, 1]               0\n",
            "           Conv2d-37              [-1, 6, 1, 1]             870\n",
            "             SiLU-38              [-1, 6, 1, 1]               0\n",
            "           Conv2d-39            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-40            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-41          [-1, 144, 16, 16]               0\n",
            "           Conv2d-42           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "           MBConv-44           [-1, 32, 16, 16]               0\n",
            "           Conv2d-45          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-46          [-1, 192, 16, 16]             384\n",
            "             SiLU-47          [-1, 192, 16, 16]               0\n",
            "           Conv2d-48          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-49          [-1, 192, 16, 16]             384\n",
            "             SiLU-50          [-1, 192, 16, 16]               0\n",
            "          Dropout-51          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-52            [-1, 192, 1, 1]               0\n",
            "           Conv2d-53              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-54              [-1, 8, 1, 1]               0\n",
            "           Conv2d-55            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-56            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-57          [-1, 192, 16, 16]               0\n",
            "           Conv2d-58           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-60           [-1, 32, 16, 16]               0\n",
            "           MBConv-61           [-1, 32, 16, 16]               0\n",
            "           Conv2d-62          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-63          [-1, 192, 16, 16]             384\n",
            "             SiLU-64          [-1, 192, 16, 16]               0\n",
            "           Conv2d-65          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-66          [-1, 192, 16, 16]             384\n",
            "             SiLU-67          [-1, 192, 16, 16]               0\n",
            "          Dropout-68          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-69            [-1, 192, 1, 1]               0\n",
            "           Conv2d-70              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-71              [-1, 8, 1, 1]               0\n",
            "           Conv2d-72            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-73            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-74          [-1, 192, 16, 16]               0\n",
            "           Conv2d-75           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-76           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-77           [-1, 32, 16, 16]               0\n",
            "           MBConv-78           [-1, 32, 16, 16]               0\n",
            "           Conv2d-79          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-80          [-1, 192, 16, 16]             384\n",
            "             SiLU-81          [-1, 192, 16, 16]               0\n",
            "           Conv2d-82            [-1, 192, 8, 8]           4,800\n",
            "      BatchNorm2d-83            [-1, 192, 8, 8]             384\n",
            "             SiLU-84            [-1, 192, 8, 8]               0\n",
            "          Dropout-85            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-86            [-1, 192, 1, 1]               0\n",
            "           Conv2d-87              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-88              [-1, 8, 1, 1]               0\n",
            "           Conv2d-89            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-90            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-91            [-1, 192, 8, 8]               0\n",
            "           Conv2d-92             [-1, 48, 8, 8]           9,216\n",
            "      BatchNorm2d-93             [-1, 48, 8, 8]              96\n",
            "           MBConv-94             [-1, 48, 8, 8]               0\n",
            "           Conv2d-95            [-1, 288, 8, 8]          13,824\n",
            "      BatchNorm2d-96            [-1, 288, 8, 8]             576\n",
            "             SiLU-97            [-1, 288, 8, 8]               0\n",
            "           Conv2d-98            [-1, 288, 8, 8]           7,200\n",
            "      BatchNorm2d-99            [-1, 288, 8, 8]             576\n",
            "            SiLU-100            [-1, 288, 8, 8]               0\n",
            "         Dropout-101            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-102            [-1, 288, 1, 1]               0\n",
            "          Conv2d-103             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-104             [-1, 12, 1, 1]               0\n",
            "          Conv2d-105            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-106            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-107            [-1, 288, 8, 8]               0\n",
            "          Conv2d-108             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-109             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-110             [-1, 48, 8, 8]               0\n",
            "          MBConv-111             [-1, 48, 8, 8]               0\n",
            "          Conv2d-112            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-113            [-1, 288, 8, 8]             576\n",
            "            SiLU-114            [-1, 288, 8, 8]               0\n",
            "          Conv2d-115            [-1, 288, 8, 8]           7,200\n",
            "     BatchNorm2d-116            [-1, 288, 8, 8]             576\n",
            "            SiLU-117            [-1, 288, 8, 8]               0\n",
            "         Dropout-118            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-119            [-1, 288, 1, 1]               0\n",
            "          Conv2d-120             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-121             [-1, 12, 1, 1]               0\n",
            "          Conv2d-122            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-123            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-124            [-1, 288, 8, 8]               0\n",
            "          Conv2d-125             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-126             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-127             [-1, 48, 8, 8]               0\n",
            "          MBConv-128             [-1, 48, 8, 8]               0\n",
            "          Conv2d-129            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-130            [-1, 288, 8, 8]             576\n",
            "            SiLU-131            [-1, 288, 8, 8]               0\n",
            "          Conv2d-132            [-1, 288, 4, 4]           2,592\n",
            "     BatchNorm2d-133            [-1, 288, 4, 4]             576\n",
            "            SiLU-134            [-1, 288, 4, 4]               0\n",
            "         Dropout-135            [-1, 288, 4, 4]               0\n",
            "AdaptiveAvgPool2d-136            [-1, 288, 1, 1]               0\n",
            "          Conv2d-137             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-138             [-1, 12, 1, 1]               0\n",
            "          Conv2d-139            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-140            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-141            [-1, 288, 4, 4]               0\n",
            "          Conv2d-142             [-1, 96, 4, 4]          27,648\n",
            "     BatchNorm2d-143             [-1, 96, 4, 4]             192\n",
            "          MBConv-144             [-1, 96, 4, 4]               0\n",
            "          Conv2d-145            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-146            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-147            [-1, 576, 4, 4]               0\n",
            "          Conv2d-148            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-149            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-150            [-1, 576, 4, 4]               0\n",
            "         Dropout-151            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-152            [-1, 576, 1, 1]               0\n",
            "          Conv2d-153             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-154             [-1, 24, 1, 1]               0\n",
            "          Conv2d-155            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-156            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-157            [-1, 576, 4, 4]               0\n",
            "          Conv2d-158             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-159             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-160             [-1, 96, 4, 4]               0\n",
            "          MBConv-161             [-1, 96, 4, 4]               0\n",
            "          Conv2d-162            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-163            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-164            [-1, 576, 4, 4]               0\n",
            "          Conv2d-165            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-166            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-167            [-1, 576, 4, 4]               0\n",
            "         Dropout-168            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-169            [-1, 576, 1, 1]               0\n",
            "          Conv2d-170             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-171             [-1, 24, 1, 1]               0\n",
            "          Conv2d-172            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-173            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-174            [-1, 576, 4, 4]               0\n",
            "          Conv2d-175             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-176             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-177             [-1, 96, 4, 4]               0\n",
            "          MBConv-178             [-1, 96, 4, 4]               0\n",
            "          Conv2d-179            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-180            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-181            [-1, 576, 4, 4]               0\n",
            "          Conv2d-182            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-183            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-184            [-1, 576, 4, 4]               0\n",
            "         Dropout-185            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-186            [-1, 576, 1, 1]               0\n",
            "          Conv2d-187             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-188             [-1, 24, 1, 1]               0\n",
            "          Conv2d-189            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-190            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-191            [-1, 576, 4, 4]               0\n",
            "          Conv2d-192             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-193             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-194             [-1, 96, 4, 4]               0\n",
            "          MBConv-195             [-1, 96, 4, 4]               0\n",
            "          Conv2d-196            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-197            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-198            [-1, 576, 4, 4]               0\n",
            "          Conv2d-199            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-200            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-201            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-202            [-1, 576, 1, 1]               0\n",
            "          Conv2d-203             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-204             [-1, 24, 1, 1]               0\n",
            "          Conv2d-205            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-206            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-207            [-1, 576, 4, 4]               0\n",
            "          Conv2d-208             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-209             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-210             [-1, 96, 4, 4]               0\n",
            "          MBConv-211             [-1, 96, 4, 4]               0\n",
            "          Conv2d-212            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-213            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-214            [-1, 576, 4, 4]               0\n",
            "          Conv2d-215            [-1, 576, 4, 4]          14,400\n",
            "     BatchNorm2d-216            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-217            [-1, 576, 4, 4]               0\n",
            "         Dropout-218            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-219            [-1, 576, 1, 1]               0\n",
            "          Conv2d-220             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-221             [-1, 24, 1, 1]               0\n",
            "          Conv2d-222            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-223            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-224            [-1, 576, 4, 4]               0\n",
            "          Conv2d-225            [-1, 136, 4, 4]          78,336\n",
            "     BatchNorm2d-226            [-1, 136, 4, 4]             272\n",
            "          MBConv-227            [-1, 136, 4, 4]               0\n",
            "          Conv2d-228            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-229            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-230            [-1, 816, 4, 4]               0\n",
            "          Conv2d-231            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-232            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-233            [-1, 816, 4, 4]               0\n",
            "         Dropout-234            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-235            [-1, 816, 1, 1]               0\n",
            "          Conv2d-236             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-237             [-1, 34, 1, 1]               0\n",
            "          Conv2d-238            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-239            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-240            [-1, 816, 4, 4]               0\n",
            "          Conv2d-241            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-242            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-243            [-1, 136, 4, 4]               0\n",
            "          MBConv-244            [-1, 136, 4, 4]               0\n",
            "          Conv2d-245            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-246            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-247            [-1, 816, 4, 4]               0\n",
            "          Conv2d-248            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-249            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-250            [-1, 816, 4, 4]               0\n",
            "         Dropout-251            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-252            [-1, 816, 1, 1]               0\n",
            "          Conv2d-253             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-254             [-1, 34, 1, 1]               0\n",
            "          Conv2d-255            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-256            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-257            [-1, 816, 4, 4]               0\n",
            "          Conv2d-258            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-259            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-260            [-1, 136, 4, 4]               0\n",
            "          MBConv-261            [-1, 136, 4, 4]               0\n",
            "          Conv2d-262            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-263            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-264            [-1, 816, 4, 4]               0\n",
            "          Conv2d-265            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-266            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-267            [-1, 816, 4, 4]               0\n",
            "         Dropout-268            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-269            [-1, 816, 1, 1]               0\n",
            "          Conv2d-270             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-271             [-1, 34, 1, 1]               0\n",
            "          Conv2d-272            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-273            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-274            [-1, 816, 4, 4]               0\n",
            "          Conv2d-275            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-276            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-277            [-1, 136, 4, 4]               0\n",
            "          MBConv-278            [-1, 136, 4, 4]               0\n",
            "          Conv2d-279            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-280            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-281            [-1, 816, 4, 4]               0\n",
            "          Conv2d-282            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-283            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-284            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-285            [-1, 816, 1, 1]               0\n",
            "          Conv2d-286             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-287             [-1, 34, 1, 1]               0\n",
            "          Conv2d-288            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-289            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-290            [-1, 816, 4, 4]               0\n",
            "          Conv2d-291            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-292            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-293            [-1, 136, 4, 4]               0\n",
            "          MBConv-294            [-1, 136, 4, 4]               0\n",
            "          Conv2d-295            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-296            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-297            [-1, 816, 4, 4]               0\n",
            "          Conv2d-298            [-1, 816, 2, 2]          20,400\n",
            "     BatchNorm2d-299            [-1, 816, 2, 2]           1,632\n",
            "            SiLU-300            [-1, 816, 2, 2]               0\n",
            "         Dropout-301            [-1, 816, 2, 2]               0\n",
            "AdaptiveAvgPool2d-302            [-1, 816, 1, 1]               0\n",
            "          Conv2d-303             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-304             [-1, 34, 1, 1]               0\n",
            "          Conv2d-305            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-306            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-307            [-1, 816, 2, 2]               0\n",
            "          Conv2d-308            [-1, 232, 2, 2]         189,312\n",
            "     BatchNorm2d-309            [-1, 232, 2, 2]             464\n",
            "          MBConv-310            [-1, 232, 2, 2]               0\n",
            "          Conv2d-311           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-312           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-313           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-314           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-315           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-316           [-1, 1392, 2, 2]               0\n",
            "         Dropout-317           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-318           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-319             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-320             [-1, 58, 1, 1]               0\n",
            "          Conv2d-321           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-322           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-323           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-324            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-325            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-326            [-1, 232, 2, 2]               0\n",
            "          MBConv-327            [-1, 232, 2, 2]               0\n",
            "          Conv2d-328           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-329           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-330           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-331           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-332           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-333           [-1, 1392, 2, 2]               0\n",
            "         Dropout-334           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-335           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-336             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-337             [-1, 58, 1, 1]               0\n",
            "          Conv2d-338           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-339           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-340           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-341            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-342            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-343            [-1, 232, 2, 2]               0\n",
            "          MBConv-344            [-1, 232, 2, 2]               0\n",
            "          Conv2d-345           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-346           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-347           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-348           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-349           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-350           [-1, 1392, 2, 2]               0\n",
            "         Dropout-351           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-352           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-353             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-354             [-1, 58, 1, 1]               0\n",
            "          Conv2d-355           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-356           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-357           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-358            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-359            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-360            [-1, 232, 2, 2]               0\n",
            "          MBConv-361            [-1, 232, 2, 2]               0\n",
            "          Conv2d-362           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-363           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-364           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-365           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-366           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-367           [-1, 1392, 2, 2]               0\n",
            "         Dropout-368           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-369           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-370             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-371             [-1, 58, 1, 1]               0\n",
            "          Conv2d-372           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-373           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-374           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-375            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-376            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-377            [-1, 232, 2, 2]               0\n",
            "          MBConv-378            [-1, 232, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-380           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-381           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-382           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-383           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-384           [-1, 1392, 2, 2]               0\n",
            "         Dropout-385           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-386           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-387             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-388             [-1, 58, 1, 1]               0\n",
            "          Conv2d-389           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-390           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-391           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-392            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-393            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-394            [-1, 232, 2, 2]               0\n",
            "          MBConv-395            [-1, 232, 2, 2]               0\n",
            "          Conv2d-396           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-397           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-398           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-399           [-1, 1392, 2, 2]          12,528\n",
            "     BatchNorm2d-400           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-401           [-1, 1392, 2, 2]               0\n",
            "         Dropout-402           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-403           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-404             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-405             [-1, 58, 1, 1]               0\n",
            "          Conv2d-406           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-407           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-408           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-409            [-1, 384, 2, 2]         534,528\n",
            "     BatchNorm2d-410            [-1, 384, 2, 2]             768\n",
            "          MBConv-411            [-1, 384, 2, 2]               0\n",
            "          Conv2d-412           [-1, 2304, 2, 2]         884,736\n",
            "     BatchNorm2d-413           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-414           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-415           [-1, 2304, 2, 2]          20,736\n",
            "     BatchNorm2d-416           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-417           [-1, 2304, 2, 2]               0\n",
            "         Dropout-418           [-1, 2304, 2, 2]               0\n",
            "AdaptiveAvgPool2d-419           [-1, 2304, 1, 1]               0\n",
            "          Conv2d-420             [-1, 96, 1, 1]         221,280\n",
            "            SiLU-421             [-1, 96, 1, 1]               0\n",
            "          Conv2d-422           [-1, 2304, 1, 1]         223,488\n",
            "         Sigmoid-423           [-1, 2304, 1, 1]               0\n",
            "SqueezeExcitation-424           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-425            [-1, 384, 2, 2]         884,736\n",
            "     BatchNorm2d-426            [-1, 384, 2, 2]             768\n",
            " StochasticDepth-427            [-1, 384, 2, 2]               0\n",
            "          MBConv-428            [-1, 384, 2, 2]               0\n",
            "          Conv2d-429           [-1, 1536, 2, 2]         589,824\n",
            "     BatchNorm2d-430           [-1, 1536, 2, 2]           3,072\n",
            "            SiLU-431           [-1, 1536, 2, 2]               0\n",
            "AdaptiveAvgPool2d-432           [-1, 1536, 1, 1]               0\n",
            "        Identity-433                 [-1, 1536]               0\n",
            "    EfficientNet-434                 [-1, 1536]               0\n",
            "          Linear-435                    [-1, 3]           4,611\n",
            "          Linear-436                   [-1, 89]         136,793\n",
            "================================================================\n",
            "Total params: 10,837,636\n",
            "Trainable params: 4,018,518\n",
            "Non-trainable params: 6,819,118\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 30.59\n",
            "Params size (MB): 41.34\n",
            "Estimated Total Size (MB): 71.98\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with some backbone frozen)\n",
        "for param in effnetb3_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in effnetb3_joint_model.backbone.features[:7].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(effnetb3_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb3_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76e7e4c-6855-4b5f-e258-37eabed44e50",
        "id": "5l287dvNZ9fj"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 train: 100%|██████████| 495/495 [00:25<00:00, 19.50batch/s, loss=12.8, sub_class_accuracy=0.0833, super_class_accuracy=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train Super Class loss: 4.7864117769655286 Super Class acc: 0.5370136499404907\n",
            "Sub Class loss: 8.393641234287534 Sub Class acc: 0.047498736530542374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 val: 100%|██████████| 23/23 [00:00<00:00, 27.09batch/s, loss=11.7, sub_class_accuracy=0, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 val Super Class loss: 4.061679001237781 Super Class acc: 0.6267029643058777\n",
            "Sub Class loss: 7.971830105586663 Sub Class acc: 0.07765667140483856\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 train: 100%|██████████| 495/495 [00:27<00:00, 18.05batch/s, loss=12.2, sub_class_accuracy=0.0417, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train Super Class loss: 4.538684173206177 Super Class acc: 0.5747852325439453\n",
            "Sub Class loss: 8.099794087595503 Sub Class acc: 0.061394643038511276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 val: 100%|██████████| 23/23 [00:00<00:00, 26.53batch/s, loss=11.6, sub_class_accuracy=0, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 val Super Class loss: 3.822490250544587 Super Class acc: 0.6634877324104309\n",
            "Sub Class loss: 7.735055650612314 Sub Class acc: 0.10354223102331161\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 train: 100%|██████████| 495/495 [00:25<00:00, 19.33batch/s, loss=11.8, sub_class_accuracy=0.125, super_class_accuracy=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train Super Class loss: 4.441033266390617 Super Class acc: 0.5865336060523987\n",
            "Sub Class loss: 7.948602085344836 Sub Class acc: 0.0727008581161499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 val: 100%|██████████| 23/23 [00:00<00:00, 27.38batch/s, loss=11.2, sub_class_accuracy=0.0333, super_class_accuracy=0.767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 val Super Class loss: 3.888058313232027 Super Class acc: 0.6416893601417542\n",
            "Sub Class loss: 7.649046997933037 Sub Class acc: 0.10354223102331161\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 train: 100%|██████████| 495/495 [00:25<00:00, 19.56batch/s, loss=12.3, sub_class_accuracy=0.0833, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 train Super Class loss: 4.374200604279997 Super Class acc: 0.5931025743484497\n",
            "Sub Class loss: 7.872649340270565 Sub Class acc: 0.07585901767015457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 val: 100%|██████████| 23/23 [00:00<00:00, 27.57batch/s, loss=11.3, sub_class_accuracy=0.0333, super_class_accuracy=0.767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 val Super Class loss: 3.6729775283901827 Super Class acc: 0.6852861046791077\n",
            "Sub Class loss: 7.49209434265012 Sub Class acc: 0.09400545060634613\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 train: 100%|██████████| 495/495 [00:25<00:00, 19.35batch/s, loss=12.5, sub_class_accuracy=0.125, super_class_accuracy=0.458]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 train Super Class loss: 4.307176735348145 Super Class acc: 0.6040298342704773\n",
            "Sub Class loss: 7.789302302828457 Sub Class acc: 0.08407023549079895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 val: 100%|██████████| 23/23 [00:00<00:00, 27.14batch/s, loss=11.4, sub_class_accuracy=0, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 val Super Class loss: 3.5770697920134022 Super Class acc: 0.6825612783432007\n",
            "Sub Class loss: 7.388827586368904 Sub Class acc: 0.1103542223572731\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 train: 100%|██████████| 495/495 [00:26<00:00, 18.74batch/s, loss=12.3, sub_class_accuracy=0, super_class_accuracy=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 train Super Class loss: 4.2896470508833255 Super Class acc: 0.6064299941062927\n",
            "Sub Class loss: 7.760109419531145 Sub Class acc: 0.08337543904781342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 val: 100%|██████████| 23/23 [00:00<00:00, 26.57batch/s, loss=11.1, sub_class_accuracy=0.0333, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 val Super Class loss: 3.522900265796308 Super Class acc: 0.7138964533805847\n",
            "Sub Class loss: 7.4058525464840095 Sub Class acc: 0.1130790188908577\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 train: 100%|██████████| 495/495 [00:25<00:00, 19.46batch/s, loss=11.2, sub_class_accuracy=0.0417, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 train Super Class loss: 4.264498742437532 Super Class acc: 0.6092091798782349\n",
            "Sub Class loss: 7.684028193949448 Sub Class acc: 0.08855482935905457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 val: 100%|██████████| 23/23 [00:00<00:00, 27.37batch/s, loss=11, sub_class_accuracy=0.0333, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 val Super Class loss: 3.609063479166265 Super Class acc: 0.6811988949775696\n",
            "Sub Class loss: 7.36858236302472 Sub Class acc: 0.1103542223572731\n",
            "--------------------\n",
            "Best Super Class val acc: 0.7138964533805847\n",
            "Best Sub Class val acc: 0.1130790188908577\n",
            "Average Time taken for an epoch: 26.904880455562047 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 7\n",
        "initial_epoch = 5\n",
        "learning_rate = 3e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb3_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='DropOut_Augment_Joint_EffnetB3_semi_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XBiyWJUZ9fj"
      },
      "source": [
        "###### Unfreeze all the layers in the network (phase 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b789fc8-53a2-47e0-ca98-5bc2c270ef5c",
        "id": "Vg1p5gikZ9fj"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 40, 32, 32]           1,080\n",
            "       BatchNorm2d-2           [-1, 40, 32, 32]              80\n",
            "              SiLU-3           [-1, 40, 32, 32]               0\n",
            "            Conv2d-4           [-1, 40, 32, 32]             360\n",
            "       BatchNorm2d-5           [-1, 40, 32, 32]              80\n",
            "              SiLU-6           [-1, 40, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 40, 1, 1]               0\n",
            "            Conv2d-8             [-1, 10, 1, 1]             410\n",
            "              SiLU-9             [-1, 10, 1, 1]               0\n",
            "           Conv2d-10             [-1, 40, 1, 1]             440\n",
            "          Sigmoid-11             [-1, 40, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 40, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]             960\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "          Dropout-19           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-20             [-1, 24, 1, 1]               0\n",
            "           Conv2d-21              [-1, 6, 1, 1]             150\n",
            "             SiLU-22              [-1, 6, 1, 1]               0\n",
            "           Conv2d-23             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-24             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-25           [-1, 24, 32, 32]               0\n",
            "           Conv2d-26           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-27           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-28           [-1, 24, 32, 32]               0\n",
            "           MBConv-29           [-1, 24, 32, 32]               0\n",
            "           Conv2d-30          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-31          [-1, 144, 32, 32]             288\n",
            "             SiLU-32          [-1, 144, 32, 32]               0\n",
            "           Conv2d-33          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-34          [-1, 144, 16, 16]             288\n",
            "             SiLU-35          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-36            [-1, 144, 1, 1]               0\n",
            "           Conv2d-37              [-1, 6, 1, 1]             870\n",
            "             SiLU-38              [-1, 6, 1, 1]               0\n",
            "           Conv2d-39            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-40            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-41          [-1, 144, 16, 16]               0\n",
            "           Conv2d-42           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "           MBConv-44           [-1, 32, 16, 16]               0\n",
            "           Conv2d-45          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-46          [-1, 192, 16, 16]             384\n",
            "             SiLU-47          [-1, 192, 16, 16]               0\n",
            "           Conv2d-48          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-49          [-1, 192, 16, 16]             384\n",
            "             SiLU-50          [-1, 192, 16, 16]               0\n",
            "          Dropout-51          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-52            [-1, 192, 1, 1]               0\n",
            "           Conv2d-53              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-54              [-1, 8, 1, 1]               0\n",
            "           Conv2d-55            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-56            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-57          [-1, 192, 16, 16]               0\n",
            "           Conv2d-58           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-60           [-1, 32, 16, 16]               0\n",
            "           MBConv-61           [-1, 32, 16, 16]               0\n",
            "           Conv2d-62          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-63          [-1, 192, 16, 16]             384\n",
            "             SiLU-64          [-1, 192, 16, 16]               0\n",
            "           Conv2d-65          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-66          [-1, 192, 16, 16]             384\n",
            "             SiLU-67          [-1, 192, 16, 16]               0\n",
            "          Dropout-68          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-69            [-1, 192, 1, 1]               0\n",
            "           Conv2d-70              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-71              [-1, 8, 1, 1]               0\n",
            "           Conv2d-72            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-73            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-74          [-1, 192, 16, 16]               0\n",
            "           Conv2d-75           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-76           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-77           [-1, 32, 16, 16]               0\n",
            "           MBConv-78           [-1, 32, 16, 16]               0\n",
            "           Conv2d-79          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-80          [-1, 192, 16, 16]             384\n",
            "             SiLU-81          [-1, 192, 16, 16]               0\n",
            "           Conv2d-82            [-1, 192, 8, 8]           4,800\n",
            "      BatchNorm2d-83            [-1, 192, 8, 8]             384\n",
            "             SiLU-84            [-1, 192, 8, 8]               0\n",
            "          Dropout-85            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-86            [-1, 192, 1, 1]               0\n",
            "           Conv2d-87              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-88              [-1, 8, 1, 1]               0\n",
            "           Conv2d-89            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-90            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-91            [-1, 192, 8, 8]               0\n",
            "           Conv2d-92             [-1, 48, 8, 8]           9,216\n",
            "      BatchNorm2d-93             [-1, 48, 8, 8]              96\n",
            "           MBConv-94             [-1, 48, 8, 8]               0\n",
            "           Conv2d-95            [-1, 288, 8, 8]          13,824\n",
            "      BatchNorm2d-96            [-1, 288, 8, 8]             576\n",
            "             SiLU-97            [-1, 288, 8, 8]               0\n",
            "           Conv2d-98            [-1, 288, 8, 8]           7,200\n",
            "      BatchNorm2d-99            [-1, 288, 8, 8]             576\n",
            "            SiLU-100            [-1, 288, 8, 8]               0\n",
            "         Dropout-101            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-102            [-1, 288, 1, 1]               0\n",
            "          Conv2d-103             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-104             [-1, 12, 1, 1]               0\n",
            "          Conv2d-105            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-106            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-107            [-1, 288, 8, 8]               0\n",
            "          Conv2d-108             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-109             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-110             [-1, 48, 8, 8]               0\n",
            "          MBConv-111             [-1, 48, 8, 8]               0\n",
            "          Conv2d-112            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-113            [-1, 288, 8, 8]             576\n",
            "            SiLU-114            [-1, 288, 8, 8]               0\n",
            "          Conv2d-115            [-1, 288, 8, 8]           7,200\n",
            "     BatchNorm2d-116            [-1, 288, 8, 8]             576\n",
            "            SiLU-117            [-1, 288, 8, 8]               0\n",
            "         Dropout-118            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-119            [-1, 288, 1, 1]               0\n",
            "          Conv2d-120             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-121             [-1, 12, 1, 1]               0\n",
            "          Conv2d-122            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-123            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-124            [-1, 288, 8, 8]               0\n",
            "          Conv2d-125             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-126             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-127             [-1, 48, 8, 8]               0\n",
            "          MBConv-128             [-1, 48, 8, 8]               0\n",
            "          Conv2d-129            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-130            [-1, 288, 8, 8]             576\n",
            "            SiLU-131            [-1, 288, 8, 8]               0\n",
            "          Conv2d-132            [-1, 288, 4, 4]           2,592\n",
            "     BatchNorm2d-133            [-1, 288, 4, 4]             576\n",
            "            SiLU-134            [-1, 288, 4, 4]               0\n",
            "         Dropout-135            [-1, 288, 4, 4]               0\n",
            "AdaptiveAvgPool2d-136            [-1, 288, 1, 1]               0\n",
            "          Conv2d-137             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-138             [-1, 12, 1, 1]               0\n",
            "          Conv2d-139            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-140            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-141            [-1, 288, 4, 4]               0\n",
            "          Conv2d-142             [-1, 96, 4, 4]          27,648\n",
            "     BatchNorm2d-143             [-1, 96, 4, 4]             192\n",
            "          MBConv-144             [-1, 96, 4, 4]               0\n",
            "          Conv2d-145            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-146            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-147            [-1, 576, 4, 4]               0\n",
            "          Conv2d-148            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-149            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-150            [-1, 576, 4, 4]               0\n",
            "         Dropout-151            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-152            [-1, 576, 1, 1]               0\n",
            "          Conv2d-153             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-154             [-1, 24, 1, 1]               0\n",
            "          Conv2d-155            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-156            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-157            [-1, 576, 4, 4]               0\n",
            "          Conv2d-158             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-159             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-160             [-1, 96, 4, 4]               0\n",
            "          MBConv-161             [-1, 96, 4, 4]               0\n",
            "          Conv2d-162            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-163            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-164            [-1, 576, 4, 4]               0\n",
            "          Conv2d-165            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-166            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-167            [-1, 576, 4, 4]               0\n",
            "         Dropout-168            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-169            [-1, 576, 1, 1]               0\n",
            "          Conv2d-170             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-171             [-1, 24, 1, 1]               0\n",
            "          Conv2d-172            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-173            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-174            [-1, 576, 4, 4]               0\n",
            "          Conv2d-175             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-176             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-177             [-1, 96, 4, 4]               0\n",
            "          MBConv-178             [-1, 96, 4, 4]               0\n",
            "          Conv2d-179            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-180            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-181            [-1, 576, 4, 4]               0\n",
            "          Conv2d-182            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-183            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-184            [-1, 576, 4, 4]               0\n",
            "         Dropout-185            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-186            [-1, 576, 1, 1]               0\n",
            "          Conv2d-187             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-188             [-1, 24, 1, 1]               0\n",
            "          Conv2d-189            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-190            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-191            [-1, 576, 4, 4]               0\n",
            "          Conv2d-192             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-193             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-194             [-1, 96, 4, 4]               0\n",
            "          MBConv-195             [-1, 96, 4, 4]               0\n",
            "          Conv2d-196            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-197            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-198            [-1, 576, 4, 4]               0\n",
            "          Conv2d-199            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-200            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-201            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-202            [-1, 576, 1, 1]               0\n",
            "          Conv2d-203             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-204             [-1, 24, 1, 1]               0\n",
            "          Conv2d-205            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-206            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-207            [-1, 576, 4, 4]               0\n",
            "          Conv2d-208             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-209             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-210             [-1, 96, 4, 4]               0\n",
            "          MBConv-211             [-1, 96, 4, 4]               0\n",
            "          Conv2d-212            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-213            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-214            [-1, 576, 4, 4]               0\n",
            "          Conv2d-215            [-1, 576, 4, 4]          14,400\n",
            "     BatchNorm2d-216            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-217            [-1, 576, 4, 4]               0\n",
            "         Dropout-218            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-219            [-1, 576, 1, 1]               0\n",
            "          Conv2d-220             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-221             [-1, 24, 1, 1]               0\n",
            "          Conv2d-222            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-223            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-224            [-1, 576, 4, 4]               0\n",
            "          Conv2d-225            [-1, 136, 4, 4]          78,336\n",
            "     BatchNorm2d-226            [-1, 136, 4, 4]             272\n",
            "          MBConv-227            [-1, 136, 4, 4]               0\n",
            "          Conv2d-228            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-229            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-230            [-1, 816, 4, 4]               0\n",
            "          Conv2d-231            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-232            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-233            [-1, 816, 4, 4]               0\n",
            "         Dropout-234            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-235            [-1, 816, 1, 1]               0\n",
            "          Conv2d-236             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-237             [-1, 34, 1, 1]               0\n",
            "          Conv2d-238            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-239            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-240            [-1, 816, 4, 4]               0\n",
            "          Conv2d-241            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-242            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-243            [-1, 136, 4, 4]               0\n",
            "          MBConv-244            [-1, 136, 4, 4]               0\n",
            "          Conv2d-245            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-246            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-247            [-1, 816, 4, 4]               0\n",
            "          Conv2d-248            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-249            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-250            [-1, 816, 4, 4]               0\n",
            "         Dropout-251            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-252            [-1, 816, 1, 1]               0\n",
            "          Conv2d-253             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-254             [-1, 34, 1, 1]               0\n",
            "          Conv2d-255            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-256            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-257            [-1, 816, 4, 4]               0\n",
            "          Conv2d-258            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-259            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-260            [-1, 136, 4, 4]               0\n",
            "          MBConv-261            [-1, 136, 4, 4]               0\n",
            "          Conv2d-262            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-263            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-264            [-1, 816, 4, 4]               0\n",
            "          Conv2d-265            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-266            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-267            [-1, 816, 4, 4]               0\n",
            "         Dropout-268            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-269            [-1, 816, 1, 1]               0\n",
            "          Conv2d-270             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-271             [-1, 34, 1, 1]               0\n",
            "          Conv2d-272            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-273            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-274            [-1, 816, 4, 4]               0\n",
            "          Conv2d-275            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-276            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-277            [-1, 136, 4, 4]               0\n",
            "          MBConv-278            [-1, 136, 4, 4]               0\n",
            "          Conv2d-279            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-280            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-281            [-1, 816, 4, 4]               0\n",
            "          Conv2d-282            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-283            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-284            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-285            [-1, 816, 1, 1]               0\n",
            "          Conv2d-286             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-287             [-1, 34, 1, 1]               0\n",
            "          Conv2d-288            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-289            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-290            [-1, 816, 4, 4]               0\n",
            "          Conv2d-291            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-292            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-293            [-1, 136, 4, 4]               0\n",
            "          MBConv-294            [-1, 136, 4, 4]               0\n",
            "          Conv2d-295            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-296            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-297            [-1, 816, 4, 4]               0\n",
            "          Conv2d-298            [-1, 816, 2, 2]          20,400\n",
            "     BatchNorm2d-299            [-1, 816, 2, 2]           1,632\n",
            "            SiLU-300            [-1, 816, 2, 2]               0\n",
            "         Dropout-301            [-1, 816, 2, 2]               0\n",
            "AdaptiveAvgPool2d-302            [-1, 816, 1, 1]               0\n",
            "          Conv2d-303             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-304             [-1, 34, 1, 1]               0\n",
            "          Conv2d-305            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-306            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-307            [-1, 816, 2, 2]               0\n",
            "          Conv2d-308            [-1, 232, 2, 2]         189,312\n",
            "     BatchNorm2d-309            [-1, 232, 2, 2]             464\n",
            "          MBConv-310            [-1, 232, 2, 2]               0\n",
            "          Conv2d-311           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-312           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-313           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-314           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-315           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-316           [-1, 1392, 2, 2]               0\n",
            "         Dropout-317           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-318           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-319             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-320             [-1, 58, 1, 1]               0\n",
            "          Conv2d-321           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-322           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-323           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-324            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-325            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-326            [-1, 232, 2, 2]               0\n",
            "          MBConv-327            [-1, 232, 2, 2]               0\n",
            "          Conv2d-328           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-329           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-330           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-331           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-332           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-333           [-1, 1392, 2, 2]               0\n",
            "         Dropout-334           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-335           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-336             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-337             [-1, 58, 1, 1]               0\n",
            "          Conv2d-338           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-339           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-340           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-341            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-342            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-343            [-1, 232, 2, 2]               0\n",
            "          MBConv-344            [-1, 232, 2, 2]               0\n",
            "          Conv2d-345           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-346           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-347           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-348           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-349           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-350           [-1, 1392, 2, 2]               0\n",
            "         Dropout-351           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-352           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-353             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-354             [-1, 58, 1, 1]               0\n",
            "          Conv2d-355           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-356           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-357           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-358            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-359            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-360            [-1, 232, 2, 2]               0\n",
            "          MBConv-361            [-1, 232, 2, 2]               0\n",
            "          Conv2d-362           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-363           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-364           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-365           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-366           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-367           [-1, 1392, 2, 2]               0\n",
            "         Dropout-368           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-369           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-370             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-371             [-1, 58, 1, 1]               0\n",
            "          Conv2d-372           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-373           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-374           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-375            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-376            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-377            [-1, 232, 2, 2]               0\n",
            "          MBConv-378            [-1, 232, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-380           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-381           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-382           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-383           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-384           [-1, 1392, 2, 2]               0\n",
            "         Dropout-385           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-386           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-387             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-388             [-1, 58, 1, 1]               0\n",
            "          Conv2d-389           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-390           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-391           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-392            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-393            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-394            [-1, 232, 2, 2]               0\n",
            "          MBConv-395            [-1, 232, 2, 2]               0\n",
            "          Conv2d-396           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-397           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-398           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-399           [-1, 1392, 2, 2]          12,528\n",
            "     BatchNorm2d-400           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-401           [-1, 1392, 2, 2]               0\n",
            "         Dropout-402           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-403           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-404             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-405             [-1, 58, 1, 1]               0\n",
            "          Conv2d-406           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-407           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-408           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-409            [-1, 384, 2, 2]         534,528\n",
            "     BatchNorm2d-410            [-1, 384, 2, 2]             768\n",
            "          MBConv-411            [-1, 384, 2, 2]               0\n",
            "          Conv2d-412           [-1, 2304, 2, 2]         884,736\n",
            "     BatchNorm2d-413           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-414           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-415           [-1, 2304, 2, 2]          20,736\n",
            "     BatchNorm2d-416           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-417           [-1, 2304, 2, 2]               0\n",
            "         Dropout-418           [-1, 2304, 2, 2]               0\n",
            "AdaptiveAvgPool2d-419           [-1, 2304, 1, 1]               0\n",
            "          Conv2d-420             [-1, 96, 1, 1]         221,280\n",
            "            SiLU-421             [-1, 96, 1, 1]               0\n",
            "          Conv2d-422           [-1, 2304, 1, 1]         223,488\n",
            "         Sigmoid-423           [-1, 2304, 1, 1]               0\n",
            "SqueezeExcitation-424           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-425            [-1, 384, 2, 2]         884,736\n",
            "     BatchNorm2d-426            [-1, 384, 2, 2]             768\n",
            " StochasticDepth-427            [-1, 384, 2, 2]               0\n",
            "          MBConv-428            [-1, 384, 2, 2]               0\n",
            "          Conv2d-429           [-1, 1536, 2, 2]         589,824\n",
            "     BatchNorm2d-430           [-1, 1536, 2, 2]           3,072\n",
            "            SiLU-431           [-1, 1536, 2, 2]               0\n",
            "AdaptiveAvgPool2d-432           [-1, 1536, 1, 1]               0\n",
            "        Identity-433                 [-1, 1536]               0\n",
            "    EfficientNet-434                 [-1, 1536]               0\n",
            "          Linear-435                    [-1, 3]           4,611\n",
            "          Linear-436                   [-1, 89]         136,793\n",
            "================================================================\n",
            "Total params: 10,837,636\n",
            "Trainable params: 10,837,636\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 30.59\n",
            "Params size (MB): 41.34\n",
            "Estimated Total Size (MB): 71.98\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with everything unfrozen)\n",
        "for param in effnetb3_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "summary(effnetb3_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb3_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f476cc-cde5-4e1d-b4ef-39a910fce935",
        "id": "purE_rDJZ9fj"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 train: 100%|██████████| 495/495 [00:53<00:00,  9.20batch/s, loss=10.4, sub_class_accuracy=0.0417, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 train Super Class loss: 3.415805941853275 Super Class acc: 0.7097018957138062\n",
            "Sub Class loss: 6.953833187030023 Sub Class acc: 0.1327059119939804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 val: 100%|██████████| 23/23 [00:00<00:00, 26.27batch/s, loss=9.5, sub_class_accuracy=0.0333, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 val Super Class loss: 2.226374824544065 Super Class acc: 0.8310626745223999\n",
            "Sub Class loss: 6.463599605196503 Sub Class acc: 0.1648501306772232\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 train: 100%|██████████| 495/495 [00:54<00:00,  9.07batch/s, loss=7.03, sub_class_accuracy=0.25, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 train Super Class loss: 2.8014022297121888 Super Class acc: 0.7753916382789612\n",
            "Sub Class loss: 6.187397120997663 Sub Class acc: 0.18879485130310059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 val: 100%|██████████| 23/23 [00:00<00:00, 25.85batch/s, loss=9.03, sub_class_accuracy=0.167, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 val Super Class loss: 2.0941387068185886 Super Class acc: 0.8365122675895691\n",
            "Sub Class loss: 6.032483117781803 Sub Class acc: 0.20027247071266174\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 train: 100%|██████████| 495/495 [00:53<00:00,  9.22batch/s, loss=9.54, sub_class_accuracy=0.25, super_class_accuracy=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 train Super Class loss: 2.473179044568099 Super Class acc: 0.8019832968711853\n",
            "Sub Class loss: 5.6937304967096685 Sub Class acc: 0.23389337956905365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 val: 100%|██████████| 23/23 [00:00<00:00, 25.44batch/s, loss=8.43, sub_class_accuracy=0.233, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 val Super Class loss: 1.8865958087613213 Super Class acc: 0.8487738370895386\n",
            "Sub Class loss: 5.768833720391712 Sub Class acc: 0.23978200554847717\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 train: 100%|██████████| 495/495 [00:54<00:00,  9.07batch/s, loss=7.99, sub_class_accuracy=0.333, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 train Super Class loss: 2.191246811972537 Super Class acc: 0.8289540410041809\n",
            "Sub Class loss: 5.229125099509819 Sub Class acc: 0.27697068452835083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 val: 100%|██████████| 23/23 [00:00<00:00, 26.18batch/s, loss=8.57, sub_class_accuracy=0.2, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 val Super Class loss: 1.980515613705326 Super Class acc: 0.8501362204551697\n",
            "Sub Class loss: 5.739819018652394 Sub Class acc: 0.24931879341602325\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 train: 100%|██████████| 495/495 [00:53<00:00,  9.19batch/s, loss=9.57, sub_class_accuracy=0.292, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 train Super Class loss: 1.952754188180271 Super Class acc: 0.8472082018852234\n",
            "Sub Class loss: 4.797199007114297 Sub Class acc: 0.3183425962924957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 val: 100%|██████████| 23/23 [00:00<00:00, 25.73batch/s, loss=8.37, sub_class_accuracy=0.233, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 val Super Class loss: 1.9213305316276705 Super Class acc: 0.8610354065895081\n",
            "Sub Class loss: 5.728400470775219 Sub Class acc: 0.2643051743507385\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 train: 100%|██████████| 495/495 [00:54<00:00,  9.08batch/s, loss=5.77, sub_class_accuracy=0.417, super_class_accuracy=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 train Super Class loss: 1.7495184049514763 Super Class acc: 0.8636305928230286\n",
            "Sub Class loss: 4.403672194468848 Sub Class acc: 0.3623041808605194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 val: 100%|██████████| 23/23 [00:00<00:00, 25.67batch/s, loss=7.2, sub_class_accuracy=0.267, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 val Super Class loss: 1.7763912363094594 Super Class acc: 0.8664849996566772\n",
            "Sub Class loss: 5.632181414466463 Sub Class acc: 0.2697547674179077\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 train: 100%|██████████| 495/495 [00:55<00:00,  8.97batch/s, loss=5.93, sub_class_accuracy=0.417, super_class_accuracy=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 train Super Class loss: 1.5440139862670628 Super Class acc: 0.8835270404815674\n",
            "Sub Class loss: 4.008850462693286 Sub Class acc: 0.40683427453041077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 val: 100%|██████████| 23/23 [00:00<00:00, 25.88batch/s, loss=8.92, sub_class_accuracy=0.3, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 val Super Class loss: 2.0695508460257943 Super Class acc: 0.8501362204551697\n",
            "Sub Class loss: 5.851666227023673 Sub Class acc: 0.2792915403842926\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 train: 100%|██████████| 495/495 [00:54<00:00,  9.06batch/s, loss=5.72, sub_class_accuracy=0.333, super_class_accuracy=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 train Super Class loss: 1.3922989763744917 Super Class acc: 0.8943911194801331\n",
            "Sub Class loss: 3.679959895937295 Sub Class acc: 0.4506063759326935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 val: 100%|██████████| 23/23 [00:00<00:00, 25.01batch/s, loss=8.04, sub_class_accuracy=0.167, super_class_accuracy=0.967]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 val Super Class loss: 1.941742133298427 Super Class acc: 0.8732969760894775\n",
            "Sub Class loss: 5.834565308178478 Sub Class acc: 0.2833787500858307\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 train: 100%|██████████| 495/495 [00:54<00:00,  9.02batch/s, loss=7.19, sub_class_accuracy=0.375, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 train Super Class loss: 1.1921111478866984 Super Class acc: 0.9080343842506409\n",
            "Sub Class loss: 3.2841163691153965 Sub Class acc: 0.49930521845817566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 val: 100%|██████████| 23/23 [00:00<00:00, 25.87batch/s, loss=8.3, sub_class_accuracy=0.233, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 val Super Class loss: 2.003006142556505 Super Class acc: 0.8692098259925842\n",
            "Sub Class loss: 5.992078855187107 Sub Class acc: 0.290190726518631\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 train: 100%|██████████| 495/495 [00:53<00:00,  9.18batch/s, loss=4.11, sub_class_accuracy=0.5, super_class_accuracy=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 train Super Class loss: 1.0727548892710954 Super Class acc: 0.9178246855735779\n",
            "Sub Class loss: 2.9624564028436815 Sub Class acc: 0.5468671321868896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 val: 100%|██████████| 23/23 [00:00<00:00, 24.88batch/s, loss=9.19, sub_class_accuracy=0.167, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 val Super Class loss: 1.9292320083694823 Super Class acc: 0.8705722093582153\n",
            "Sub Class loss: 6.121879242421496 Sub Class acc: 0.26566755771636963\n",
            "--------------------\n",
            "Best Super Class val acc: 0.8732969760894775\n",
            "Best Sub Class val acc: 0.290190726518631\n",
            "Average Time taken for an epoch: 55.50453402996063 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "initial_epoch = 12\n",
        "learning_rate = 4e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb3_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='DropOut_Augment_Joint_EffnetB3_unfrozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrMosgYvQgxk"
      },
      "source": [
        "### Ensemble Joint Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nGMaaUtQgxl"
      },
      "source": [
        "##### Joint training utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GhYKTkcwQgxl"
      },
      "outputs": [],
      "source": [
        "# Will contain utility functions used for training the model\n",
        "import torch\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "#Training Function\n",
        "def fit_classifier(model, train_loader, val_loader, optimizer, loss_func, epochs=10, initial_epoch=0, device='cpu', name='effnetb6'):\n",
        "    '''\n",
        "    function to train a classifier model.\n",
        "    args:\n",
        "        model - the model to be trained\n",
        "        train_loader - Dataloader() for train set\n",
        "        val_loader - Dataloader() for val set\n",
        "        optimizer - optimization algorithm for updating weights\n",
        "        loss_func - loss function to be used\n",
        "    \n",
        "    keyword args:\n",
        "        epochs - Number of training epochs (default=10)\n",
        "        initial_epoch - The starting epoch\n",
        "        device - the device for training (default='cpu')\n",
        "        name - Name for saving the model\n",
        "    \n",
        "    returns: Nothing\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    model = model.to(device, non_blocking=True)\n",
        "    \n",
        "    # Save the models based on the super and sub class validation accuracies\n",
        "    best_super_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    best_sub_acc = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "    \n",
        "    #create the logger object\n",
        "    writer = SummaryWriter()\n",
        "    start_time = time.time()\n",
        "    \n",
        "    #Iterate epochs\n",
        "    for epoch in range(initial_epoch, initial_epoch + epochs):\n",
        "        #Each epoch has a training phase and validation phase\n",
        "        for phase in ['train','val']:\n",
        "            data_loader = None\n",
        "            if phase == 'train':\n",
        "                #Set train mode\n",
        "                model.train()\n",
        "                data_loader = train_loader\n",
        "            else:\n",
        "                #Set Eval mode\n",
        "                model.eval()\n",
        "                data_loader = val_loader\n",
        "          \n",
        "            running_super_loss = 0.\n",
        "            running_sub_loss = 0.\n",
        "            running_super_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            running_sub_corrects = torch.tensor([0.]).to(device, non_blocking=True)\n",
        "            \n",
        "            #tqdm for observing the progress\n",
        "            with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
        "                #Iterate batches\n",
        "                for itr, (images, super_labels, sub_labels) in enumerate(tepoch):\n",
        "                    tepoch.set_description(f\"Epoch {(epoch)} {phase}\")\n",
        "                    images = images.to(device, non_blocking=True)\n",
        "\n",
        "                    super_labels = super_labels.long().to(device, non_blocking=True)\n",
        "                    sub_labels = sub_labels.long().to(device, non_blocking=True)\n",
        "                    \n",
        "                    optimizer.zero_grad()\n",
        "                    \n",
        "                    #Set gradient calculation only for training phase\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        super_outputs, sub_outputs = model(images)\n",
        "\n",
        "                        super_loss = loss_func(super_outputs, super_labels)\n",
        "                        sub_loss = loss_func(sub_outputs, sub_labels)\n",
        "\n",
        "                        super_preds = torch.argmax(super_outputs, dim=1)\n",
        "                        sub_preds = torch.argmax(sub_outputs, dim=1)\n",
        "\n",
        "                        loss = 5 * super_loss + 2 * sub_loss\n",
        "                        \n",
        "                        #Do backprop only during training\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                    \n",
        "                    running_super_loss += 5 * super_loss.item() * images.size(0)\n",
        "                    running_sub_loss += 2 * sub_loss.item() * images.size(0)\n",
        "                    running_super_corrects += torch.sum(super_preds == super_labels)\n",
        "                    running_sub_corrects += torch.sum(sub_preds == sub_labels)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        writer.add_scalar(\"Batch_Loss/\" + phase, loss.item(), epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Super_Class/\" + phase,\n",
        "                                          (torch.sum(super_preds == super_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                        writer.add_scalar(\"Batch_Accuracy_Sub_Class/\" + phase,\n",
        "                                          (torch.sum(sub_preds == sub_labels)/(images.shape[0])).item(),\n",
        "                                          epoch * len(data_loader) + itr)\n",
        "                    \n",
        "                    tepoch.set_postfix(loss=loss.item(),\n",
        "                              super_class_accuracy=(torch.sum(super_preds == super_labels)/(images.shape[0])).item(),\n",
        "                              sub_class_accuracy=(torch.sum(sub_preds == sub_labels)/(images.shape[0])).item())\n",
        "                \n",
        "                epoch_super_loss = running_super_loss / len(data_loader.dataset)\n",
        "                epoch_sub_loss = running_sub_loss / len(data_loader.dataset)\n",
        "                epoch_super_acc = running_super_corrects.float() / (len(data_loader.dataset))\n",
        "                epoch_sub_acc = running_sub_corrects.float() / (len(data_loader.dataset))\n",
        "\n",
        "                print(f\"Epoch {(epoch)} {phase} Super Class loss: {epoch_super_loss} Super Class acc: {epoch_super_acc.item()}\")\n",
        "                print(f\"Sub Class loss: {epoch_sub_loss} Sub Class acc: {epoch_sub_acc.item()}\")\n",
        "\n",
        "                writer.add_scalar(\"Epoch_Loss_Super_Class/\" + phase, epoch_super_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Loss_Sub_Class/\" + phase, epoch_sub_loss, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Super_Class/\" + phase, epoch_super_acc, epoch)\n",
        "                writer.add_scalar(\"Epoch_Accuracy_Sub_Class/\" + phase, epoch_sub_acc, epoch)\n",
        "                \n",
        "                # #Saving best model based on super class accuracy\n",
        "                if phase == 'val' and epoch_super_acc > best_super_acc:\n",
        "                    best_super_acc = epoch_super_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SuperClass.pth\")\n",
        "\n",
        "                #Saving best model based on sub class accuracy\n",
        "                if phase == 'val' and epoch_sub_acc > best_sub_acc:\n",
        "                    best_sub_acc = epoch_sub_acc\n",
        "                    os.makedirs('./models', exist_ok = True)\n",
        "                    torch.save({      \n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                    }, f\"./models/{name}_SubClass.pth\")    \n",
        "                \n",
        "        print('-'*20)\n",
        "    \n",
        "    #End of Training \n",
        "    end_time = time.time()  \n",
        "    writer.close()\n",
        "    print('Best Super Class val acc: {}'.format(best_super_acc.item()))\n",
        "    print('Best Sub Class val acc: {}'.format(best_sub_acc.item()))\n",
        "    print(f\"Average Time taken for an epoch: {(end_time - start_time)/epochs} sec\")\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4on0849Qgxl"
      },
      "source": [
        "##### Create the Swin_T model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XjvdSi1eQgxl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "2147900d1d274ca5bbfe1c76e708cee6",
            "fc3f83edb4974ce695469235c7a6d77f",
            "9b28f18573d0459282f1fdde5f785171",
            "f6b7154e1cea4ad8a7b8f4bffb1ad2f5",
            "193c0d3c9e414927a5aae5536f36ce25",
            "a619383f356144918ca7ea573cf75e84",
            "a1bc1c549d72439f89e70c50c11e3410",
            "3bab3268671d422c87a37fd25f22208d",
            "f98a8f4b25c54297a897bc91d11a8880",
            "04a5af5fe4144b998d3d325859f26e2e",
            "79222eb119a449c0813711bdbf1017e1"
          ]
        },
        "outputId": "802d5922-f8e3-4f67-d8ff-3424bff551c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/swin_t-704ceda3.pth\" to /root/.cache/torch/hub/checkpoints/swin_t-704ceda3.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/108M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2147900d1d274ca5bbfe1c76e708cee6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# Load the Swin Transformer model trained on ImageNet\n",
        "backbone_model = torchvision.models.swin_t(weights='IMAGENET1K_V1')\n",
        "backbone_model.head = nn.Identity()\n",
        "\n",
        "# Set the DropOut value in the backbone model\n",
        "def set_dropout_p(m, p):\n",
        "    if isinstance(m, nn.Dropout):\n",
        "        m.p = p\n",
        "\n",
        "backbone_model.apply(lambda m: set_dropout_p(m, p = 0.25))\n",
        "\n",
        "#print(backbone_model)\n",
        "\n",
        "class SwinTJointModel(nn.Module):\n",
        "    def __init__(self, backbone) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        # 3 super classes\n",
        "        self.superclass = nn.Linear(in_features = 768, out_features = 3)\n",
        "        # 89 sub classes\n",
        "        self.subclass = nn.Linear(in_features = 768, out_features = 89)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.backbone(x)\n",
        "        super_class_out = self.superclass(out)\n",
        "        sub_class_out = self.subclass(out)\n",
        "        return super_class_out, sub_class_out\n",
        "\n",
        "# Create the baseline model\n",
        "swin_t_joint_model = SwinTJointModel(backbone_model)\n",
        "swin_t_joint_model = swin_t_joint_model.to(device, non_blocking = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc-1HwYeQgxm"
      },
      "source": [
        "##### Train the Swin_T model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybW80B0fQgxm"
      },
      "source": [
        "###### Freeze all the layers except Classifier layers (phase 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkdjuej8Qgxm",
        "outputId": "6268b3ed-002f-432e-f112-66a36d44dced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "          Linear-152                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,922,940\n",
            "Trainable params: 70,748\n",
            "Non-trainable params: 18,852,192\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.19\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with all backbone frozen)\n",
        "for param in swin_t_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in swin_t_joint_model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(swin_t_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in swin_t_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYO7IQaPQgxm",
        "outputId": "bc25ba82-bdaa-4aa2-d322-62b3298ad7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 train: 100%|██████████| 495/495 [00:26<00:00, 18.53batch/s, loss=13.4, sub_class_accuracy=0, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train Super Class loss: 5.00671358422356 Super Class acc: 0.5\n",
            "Sub Class loss: 8.868096068749951 Sub Class acc: 0.02627589739859104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 val: 100%|██████████| 23/23 [00:00<00:00, 27.50batch/s, loss=13.6, sub_class_accuracy=0, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 val Super Class loss: 4.461601840215418 Super Class acc: 0.5844686627388\n",
            "Sub Class loss: 8.446562738444564 Sub Class acc: 0.0558583103120327\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 train: 100%|██████████| 495/495 [00:18<00:00, 26.23batch/s, loss=12.7, sub_class_accuracy=0.0417, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train Super Class loss: 4.469258045385196 Super Class acc: 0.5958817601203918\n",
            "Sub Class loss: 8.463248387799833 Sub Class acc: 0.05975240096449852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 val: 100%|██████████| 23/23 [00:00<00:00, 27.38batch/s, loss=13.3, sub_class_accuracy=0, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 val Super Class loss: 4.13685097275378 Super Class acc: 0.6307901740074158\n",
            "Sub Class loss: 8.015498948681907 Sub Class acc: 0.09128065407276154\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 train: 100%|██████████| 495/495 [00:18<00:00, 26.46batch/s, loss=11.9, sub_class_accuracy=0.0417, super_class_accuracy=0.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train Super Class loss: 4.254820540946442 Super Class acc: 0.6289792656898499\n",
            "Sub Class loss: 8.205579820818947 Sub Class acc: 0.08287013322114944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 val: 100%|██████████| 23/23 [00:00<00:00, 28.12batch/s, loss=13, sub_class_accuracy=0, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 val Super Class loss: 3.9831774850307435 Super Class acc: 0.6512261629104614\n",
            "Sub Class loss: 7.771852776530003 Sub Class acc: 0.10081743448972702\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 train: 100%|██████████| 495/495 [00:18<00:00, 26.45batch/s, loss=14.2, sub_class_accuracy=0.0417, super_class_accuracy=0.417]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train Super Class loss: 4.169795299311248 Super Class acc: 0.635106086730957\n",
            "Sub Class loss: 8.002631658734307 Sub Class acc: 0.09903991967439651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 val: 100%|██████████| 23/23 [00:00<00:00, 28.29batch/s, loss=12.8, sub_class_accuracy=0.0667, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 val Super Class loss: 4.081579348534264 Super Class acc: 0.6444141864776611\n",
            "Sub Class loss: 7.626472933091 Sub Class acc: 0.11444141715765\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 train: 100%|██████████| 495/495 [00:19<00:00, 25.39batch/s, loss=12.3, sub_class_accuracy=0.167, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train Super Class loss: 4.072040201528558 Super Class acc: 0.6424330472946167\n",
            "Sub Class loss: 7.8410529743366135 Sub Class acc: 0.1093355193734169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 val: 100%|██████████| 23/23 [00:00<00:00, 28.10batch/s, loss=12.8, sub_class_accuracy=0.0333, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 val Super Class loss: 3.9584791099992693 Super Class acc: 0.6621253490447998\n",
            "Sub Class loss: 7.492297486973069 Sub Class acc: 0.11852861195802689\n",
            "--------------------\n",
            "Best Super Class val acc: 0.6621253490447998\n",
            "Best Sub Class val acc: 0.11852861195802689\n",
            "Average Time taken for an epoch: 22.34150447845459 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "initial_epoch = 0\n",
        "learning_rate = 1e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    swin_t_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='EnsembleJoint_SwinT_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxefnWFyQgxm"
      },
      "source": [
        "###### Unfreeze some layers of the backbone network (phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlTdmg_gQgxm",
        "outputId": "319d8622-f52d-495c-eef1-601884c0e466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "          Linear-152                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,922,940\n",
            "Trainable params: 4,796,252\n",
            "Non-trainable params: 14,126,688\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.19\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with some backbone frozen)\n",
        "for param in swin_t_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in swin_t_joint_model.backbone.features[:8].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for idx, (name, param) in enumerate(swin_t_joint_model.backbone.features[7].named_parameters()):\n",
        "    #print(name, idx)\n",
        "    if idx > 15:\n",
        "        param.requires_grad = True\n",
        "\n",
        "summary(swin_t_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in swin_t_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEXxINx8Qgxm",
        "outputId": "5fa8f006-751b-468f-ba06-d2a1263d991f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 train: 100%|██████████| 495/495 [00:22<00:00, 21.95batch/s, loss=12.9, sub_class_accuracy=0.25, super_class_accuracy=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train Super Class loss: 4.023481408052218 Super Class acc: 0.6501389741897583\n",
            "Sub Class loss: 7.537693574971898 Sub Class acc: 0.1164098009467125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 val: 100%|██████████| 23/23 [00:00<00:00, 27.63batch/s, loss=12.9, sub_class_accuracy=0.0333, super_class_accuracy=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 val Super Class loss: 3.926513186105266 Super Class acc: 0.7111716270446777\n",
            "Sub Class loss: 7.25785388478791 Sub Class acc: 0.15667574107646942\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 train: 100%|██████████| 495/495 [00:22<00:00, 22.35batch/s, loss=11.6, sub_class_accuracy=0.0417, super_class_accuracy=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train Super Class loss: 3.7995897392361617 Super Class acc: 0.6760358810424805\n",
            "Sub Class loss: 7.182583390853211 Sub Class acc: 0.1362430453300476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 val: 100%|██████████| 23/23 [00:00<00:00, 27.17batch/s, loss=12.3, sub_class_accuracy=0.0667, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 val Super Class loss: 3.462619842398069 Super Class acc: 0.7343324422836304\n",
            "Sub Class loss: 7.106156364773534 Sub Class acc: 0.1675749272108078\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 train: 100%|██████████| 495/495 [00:21<00:00, 22.62batch/s, loss=10.5, sub_class_accuracy=0.208, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train Super Class loss: 3.6822220511422006 Super Class acc: 0.6838049292564392\n",
            "Sub Class loss: 6.945958687597721 Sub Class acc: 0.15020212531089783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 val: 100%|██████████| 23/23 [00:00<00:00, 27.82batch/s, loss=12.6, sub_class_accuracy=0.167, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 val Super Class loss: 3.240598054445407 Super Class acc: 0.7152588367462158\n",
            "Sub Class loss: 6.995804997166106 Sub Class acc: 0.18119890987873077\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 train: 100%|██████████| 495/495 [00:22<00:00, 21.96batch/s, loss=11.9, sub_class_accuracy=0.125, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 train Super Class loss: 3.5736119360138274 Super Class acc: 0.6953638195991516\n",
            "Sub Class loss: 6.800981610516456 Sub Class acc: 0.16062405705451965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 val: 100%|██████████| 23/23 [00:00<00:00, 27.57batch/s, loss=11.9, sub_class_accuracy=0.0333, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 val Super Class loss: 3.251750792404611 Super Class acc: 0.7329699993133545\n",
            "Sub Class loss: 6.966437843904833 Sub Class acc: 0.1716621220111847\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 train: 100%|██████████| 495/495 [00:22<00:00, 22.32batch/s, loss=11.2, sub_class_accuracy=0.208, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 train Super Class loss: 3.541503068983946 Super Class acc: 0.7007327079772949\n",
            "Sub Class loss: 6.6882944275719645 Sub Class acc: 0.17104598879814148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 val: 100%|██████████| 23/23 [00:00<00:00, 27.30batch/s, loss=10.9, sub_class_accuracy=0.0667, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 val Super Class loss: 3.436225852459588 Super Class acc: 0.7343324422836304\n",
            "Sub Class loss: 7.041351045509775 Sub Class acc: 0.19754767417907715\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 train: 100%|██████████| 495/495 [00:22<00:00, 22.02batch/s, loss=9.74, sub_class_accuracy=0.208, super_class_accuracy=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 train Super Class loss: 3.493172542472992 Super Class acc: 0.6979535222053528\n",
            "Sub Class loss: 6.58886405613279 Sub Class acc: 0.17925719916820526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 val: 100%|██████████| 23/23 [00:00<00:00, 27.46batch/s, loss=11.5, sub_class_accuracy=0.0333, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 val Super Class loss: 3.109237515958843 Super Class acc: 0.7465940117835999\n",
            "Sub Class loss: 7.0046684462627855 Sub Class acc: 0.18392370641231537\n",
            "--------------------\n",
            "Best Super Class val acc: 0.7465940117835999\n",
            "Best Sub Class val acc: 0.19754767417907715\n",
            "Average Time taken for an epoch: 23.435890992482502 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 6\n",
        "initial_epoch = 5\n",
        "learning_rate = 2e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    swin_t_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='EnsembleJoint_SwinT_semi_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4WfLUbpQgxm"
      },
      "source": [
        "###### Unfreeze all the layers in the network (phase 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kap3T24BQgxm",
        "outputId": "9a00d2cd-2913-4ecd-cfef-efba98cd0594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 16, 16]           4,704\n",
            "           Permute-2           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-3           [-1, 16, 16, 96]             192\n",
            "         LayerNorm-4           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 16, 16, 96]               0\n",
            "   StochasticDepth-6           [-1, 16, 16, 96]               0\n",
            "         LayerNorm-7           [-1, 16, 16, 96]             192\n",
            "            Linear-8          [-1, 16, 16, 384]          37,248\n",
            "              GELU-9          [-1, 16, 16, 384]               0\n",
            "          Dropout-10          [-1, 16, 16, 384]               0\n",
            "           Linear-11           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-12           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-13           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-15           [-1, 16, 16, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-17           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-18           [-1, 16, 16, 96]             192\n",
            "           Linear-19          [-1, 16, 16, 384]          37,248\n",
            "             GELU-20          [-1, 16, 16, 384]               0\n",
            "          Dropout-21          [-1, 16, 16, 384]               0\n",
            "           Linear-22           [-1, 16, 16, 96]          36,960\n",
            "          Dropout-23           [-1, 16, 16, 96]               0\n",
            "  StochasticDepth-24           [-1, 16, 16, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 16, 16, 96]               0\n",
            "        LayerNorm-26            [-1, 8, 8, 384]             768\n",
            "           Linear-27            [-1, 8, 8, 192]          73,728\n",
            "     PatchMerging-28            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-29            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-30            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-31            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-32            [-1, 8, 8, 192]             384\n",
            "           Linear-33            [-1, 8, 8, 768]         148,224\n",
            "             GELU-34            [-1, 8, 8, 768]               0\n",
            "          Dropout-35            [-1, 8, 8, 768]               0\n",
            "           Linear-36            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-37            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-38            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-39            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-40            [-1, 8, 8, 192]             384\n",
            "ShiftedWindowAttention-41            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-42            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-43            [-1, 8, 8, 192]             384\n",
            "           Linear-44            [-1, 8, 8, 768]         148,224\n",
            "             GELU-45            [-1, 8, 8, 768]               0\n",
            "          Dropout-46            [-1, 8, 8, 768]               0\n",
            "           Linear-47            [-1, 8, 8, 192]         147,648\n",
            "          Dropout-48            [-1, 8, 8, 192]               0\n",
            "  StochasticDepth-49            [-1, 8, 8, 192]               0\n",
            "SwinTransformerBlock-50            [-1, 8, 8, 192]               0\n",
            "        LayerNorm-51            [-1, 4, 4, 768]           1,536\n",
            "           Linear-52            [-1, 4, 4, 384]         294,912\n",
            "     PatchMerging-53            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-54            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-56            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-57            [-1, 4, 4, 384]             768\n",
            "           Linear-58           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-59           [-1, 4, 4, 1536]               0\n",
            "          Dropout-60           [-1, 4, 4, 1536]               0\n",
            "           Linear-61            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-62            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-63            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-65            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-67            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-68            [-1, 4, 4, 384]             768\n",
            "           Linear-69           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-70           [-1, 4, 4, 1536]               0\n",
            "          Dropout-71           [-1, 4, 4, 1536]               0\n",
            "           Linear-72            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-73            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-74            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-76            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-78            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-79            [-1, 4, 4, 384]             768\n",
            "           Linear-80           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-81           [-1, 4, 4, 1536]               0\n",
            "          Dropout-82           [-1, 4, 4, 1536]               0\n",
            "           Linear-83            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-84            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-85            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-87            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-89            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-90            [-1, 4, 4, 384]             768\n",
            "           Linear-91           [-1, 4, 4, 1536]         591,360\n",
            "             GELU-92           [-1, 4, 4, 1536]               0\n",
            "          Dropout-93           [-1, 4, 4, 1536]               0\n",
            "           Linear-94            [-1, 4, 4, 384]         590,208\n",
            "          Dropout-95            [-1, 4, 4, 384]               0\n",
            "  StochasticDepth-96            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 4, 4, 384]               0\n",
            "        LayerNorm-98            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-100            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-101            [-1, 4, 4, 384]             768\n",
            "          Linear-102           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-103           [-1, 4, 4, 1536]               0\n",
            "         Dropout-104           [-1, 4, 4, 1536]               0\n",
            "          Linear-105            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-106            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-107            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-109            [-1, 4, 4, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-111            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-112            [-1, 4, 4, 384]             768\n",
            "          Linear-113           [-1, 4, 4, 1536]         591,360\n",
            "            GELU-114           [-1, 4, 4, 1536]               0\n",
            "         Dropout-115           [-1, 4, 4, 1536]               0\n",
            "          Linear-116            [-1, 4, 4, 384]         590,208\n",
            "         Dropout-117            [-1, 4, 4, 384]               0\n",
            " StochasticDepth-118            [-1, 4, 4, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 4, 4, 384]               0\n",
            "       LayerNorm-120           [-1, 2, 2, 1536]           3,072\n",
            "          Linear-121            [-1, 2, 2, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-123            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-125            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-126            [-1, 2, 2, 768]           1,536\n",
            "          Linear-127           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-128           [-1, 2, 2, 3072]               0\n",
            "         Dropout-129           [-1, 2, 2, 3072]               0\n",
            "          Linear-130            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-131            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-132            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-134            [-1, 2, 2, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-136            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-137            [-1, 2, 2, 768]           1,536\n",
            "          Linear-138           [-1, 2, 2, 3072]       2,362,368\n",
            "            GELU-139           [-1, 2, 2, 3072]               0\n",
            "         Dropout-140           [-1, 2, 2, 3072]               0\n",
            "          Linear-141            [-1, 2, 2, 768]       2,360,064\n",
            "         Dropout-142            [-1, 2, 2, 768]               0\n",
            " StochasticDepth-143            [-1, 2, 2, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 2, 2, 768]               0\n",
            "       LayerNorm-145            [-1, 2, 2, 768]           1,536\n",
            "         Permute-146            [-1, 768, 2, 2]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "        Identity-149                  [-1, 768]               0\n",
            " SwinTransformer-150                  [-1, 768]               0\n",
            "          Linear-151                    [-1, 3]           2,307\n",
            "          Linear-152                   [-1, 89]          68,441\n",
            "================================================================\n",
            "Total params: 18,922,940\n",
            "Trainable params: 18,922,940\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 19.10\n",
            "Params size (MB): 72.19\n",
            "Estimated Total Size (MB): 91.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with everything unfrozen)\n",
        "for param in swin_t_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "summary(swin_t_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in swin_t_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw8v4CAnQgxm",
        "outputId": "66b0e5d7-6561-450d-d426-dc100d511e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 train: 100%|██████████| 495/495 [00:49<00:00, 10.09batch/s, loss=7.68, sub_class_accuracy=0.25, super_class_accuracy=0.792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 train Super Class loss: 3.115476109256884 Super Class acc: 0.7433678507804871\n",
            "Sub Class loss: 6.323889007828583 Sub Class acc: 0.1953638195991516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 val: 100%|██████████| 23/23 [00:00<00:00, 26.37batch/s, loss=8.35, sub_class_accuracy=0.3, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 val Super Class loss: 2.2807362371147164 Super Class acc: 0.8147138953208923\n",
            "Sub Class loss: 5.974797920570062 Sub Class acc: 0.2179836481809616\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 train: 100%|██████████| 495/495 [00:48<00:00, 10.16batch/s, loss=8.32, sub_class_accuracy=0.292, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 train Super Class loss: 2.2632922546137095 Super Class acc: 0.8220692276954651\n",
            "Sub Class loss: 5.250637678981972 Sub Class acc: 0.2858135402202606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 val: 100%|██████████| 23/23 [00:00<00:00, 26.10batch/s, loss=8.05, sub_class_accuracy=0.1, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 val Super Class loss: 2.0229778288576843 Super Class acc: 0.8514986038208008\n",
            "Sub Class loss: 5.6698570394386065 Sub Class acc: 0.25068119168281555\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 train: 100%|██████████| 495/495 [00:48<00:00, 10.22batch/s, loss=6.89, sub_class_accuracy=0.25, super_class_accuracy=0.792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 train Super Class loss: 1.8069534777028806 Super Class acc: 0.8602198362350464\n",
            "Sub Class loss: 4.586888277633073 Sub Class acc: 0.35213491320610046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 val: 100%|██████████| 23/23 [00:00<00:00, 26.71batch/s, loss=9.21, sub_class_accuracy=0.1, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 val Super Class loss: 2.364338420392382 Super Class acc: 0.8215258717536926\n",
            "Sub Class loss: 5.934763790151404 Sub Class acc: 0.26566755771636963\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 train: 100%|██████████| 495/495 [00:48<00:00, 10.24batch/s, loss=4.33, sub_class_accuracy=0.5, super_class_accuracy=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 train Super Class loss: 1.4850595666489979 Super Class acc: 0.8863062262535095\n",
            "Sub Class loss: 4.001258329166915 Sub Class acc: 0.41915109753608704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 val: 100%|██████████| 23/23 [00:00<00:00, 26.48batch/s, loss=9.9, sub_class_accuracy=0.233, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 val Super Class loss: 2.5133360366080697 Super Class acc: 0.8051770925521851\n",
            "Sub Class loss: 6.191281309569564 Sub Class acc: 0.25068119168281555\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 train: 100%|██████████| 495/495 [00:48<00:00, 10.22batch/s, loss=4.41, sub_class_accuracy=0.5, super_class_accuracy=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 train Super Class loss: 1.1989703288790312 Super Class acc: 0.9101187586784363\n",
            "Sub Class loss: 3.5159583235100222 Sub Class acc: 0.47410309314727783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 val: 100%|██████████| 23/23 [00:00<00:00, 26.41batch/s, loss=9.75, sub_class_accuracy=0.0667, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 val Super Class loss: 2.0728495733289694 Super Class acc: 0.8514986038208008\n",
            "Sub Class loss: 5.999761686662887 Sub Class acc: 0.24659399688243866\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 train: 100%|██████████| 495/495 [00:48<00:00, 10.12batch/s, loss=3.14, sub_class_accuracy=0.583, super_class_accuracy=0.958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 train Super Class loss: 0.9646544998540849 Super Class acc: 0.9262885451316833\n",
            "Sub Class loss: 2.9946785130965825 Sub Class acc: 0.542761504650116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 val: 100%|██████████| 23/23 [00:00<00:00, 26.70batch/s, loss=11.4, sub_class_accuracy=0.2, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 val Super Class loss: 2.7347617050282635 Super Class acc: 0.8310626745223999\n",
            "Sub Class loss: 6.650773788992651 Sub Class acc: 0.2711171507835388\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 train: 100%|██████████| 495/495 [00:48<00:00, 10.20batch/s, loss=3.1, sub_class_accuracy=0.667, super_class_accuracy=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 train Super Class loss: 0.7685065076899625 Super Class acc: 0.9413213729858398\n",
            "Sub Class loss: 2.519363177190109 Sub Class acc: 0.6092091798782349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 val: 100%|██████████| 23/23 [00:00<00:00, 26.23batch/s, loss=9.75, sub_class_accuracy=0.233, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 val Super Class loss: 2.3801599511983285 Super Class acc: 0.8583106398582458\n",
            "Sub Class loss: 6.279680458661321 Sub Class acc: 0.2643051743507385\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 train: 100%|██████████| 495/495 [00:48<00:00, 10.11batch/s, loss=2.95, sub_class_accuracy=0.75, super_class_accuracy=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 train Super Class loss: 0.6303150497636691 Super Class acc: 0.954206645488739\n",
            "Sub Class loss: 2.1028047311540923 Sub Class acc: 0.6669403910636902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 val: 100%|██████████| 23/23 [00:00<00:00, 26.87batch/s, loss=12.4, sub_class_accuracy=0.233, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 val Super Class loss: 2.692416811346683 Super Class acc: 0.8514986038208008\n",
            "Sub Class loss: 7.232512642966954 Sub Class acc: 0.25204360485076904\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 train: 100%|██████████| 495/495 [00:48<00:00, 10.12batch/s, loss=1.68, sub_class_accuracy=0.708, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 train Super Class loss: 0.5596975950470562 Super Class acc: 0.9605861306190491\n",
            "Sub Class loss: 1.7714640518340756 Sub Class acc: 0.7186079025268555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 val: 100%|██████████| 23/23 [00:00<00:00, 26.28batch/s, loss=10.5, sub_class_accuracy=0.3, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 val Super Class loss: 2.562674688789435 Super Class acc: 0.8732969760894775\n",
            "Sub Class loss: 7.272055124391977 Sub Class acc: 0.2779291570186615\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 train: 100%|██████████| 495/495 [00:48<00:00, 10.14batch/s, loss=3.29, sub_class_accuracy=0.75, super_class_accuracy=0.958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 train Super Class loss: 0.4139605852160669 Super Class acc: 0.970313310623169\n",
            "Sub Class loss: 1.4445293173156284 Sub Class acc: 0.7647170424461365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 val: 100%|██████████| 23/23 [00:00<00:00, 26.45batch/s, loss=12.1, sub_class_accuracy=0.267, super_class_accuracy=0.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 val Super Class loss: 3.236036869907899 Super Class acc: 0.8419618606567383\n",
            "Sub Class loss: 7.720874183509266 Sub Class acc: 0.2697547674179077\n",
            "--------------------\n",
            "Best Super Class val acc: 0.8732969760894775\n",
            "Best Sub Class val acc: 0.2779291570186615\n",
            "Average Time taken for an epoch: 49.81716206073761 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "initial_epoch = 11\n",
        "learning_rate = 4e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    swin_t_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='EnsembleJoint_SwinT_unfrozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz8OekxyQgxo"
      },
      "source": [
        "##### Create the EfficientNetB3 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qNwBCwarQgxo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "49d9e884e9924b5b831477768caf81c5",
            "fd3123f37aff4961a02d1202511d730b",
            "33a4e18cba174a3c814c353c050775ef",
            "ad35149f1fe54b59bfcdbe647dd3d41c",
            "eed00be125584151adfb708126500b62",
            "adc12e868eeb4abeb521255c27c9d94d",
            "888a53f0d4664d83b4c796dc3dc7b969",
            "7a3d51e374c4411bb033e0f7e901cd3e",
            "fafbe7f4fd6048479a03cb2e7ff2330e",
            "eb0d4922d3ec47d6be8d234674ad3ed4",
            "c850ac4a79e64f23a466efc0adb4751b"
          ]
        },
        "outputId": "b031d681-9634-4398-a5d3-d6104c02090a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-cf984f9c.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-cf984f9c.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/47.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49d9e884e9924b5b831477768caf81c5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# Load the EfficientNetB3 model trained on ImageNet\n",
        "backbone_model = torchvision.models.efficientnet_b3(weights='IMAGENET1K_V1')\n",
        "backbone_model.classifier = nn.Identity()\n",
        "\n",
        "\n",
        "# Add Dropout layers after the activation function as per this paper http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf\n",
        "#backbone_model.features[0].add_module('3', nn.Dropout(p = 0.2))\n",
        "\n",
        "#backbone_model.features[1][0].block[0].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[1][1].block[0].add_module('3', nn.Dropout(p = 0.1))\n",
        "\n",
        "#backbone_model.features[2][0].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[2][1].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[2][2].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "\n",
        "backbone_model.features[3][0].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[3][1].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[3][2].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "\n",
        "backbone_model.features[4][0].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[4][1].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[4][2].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[4][3].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "\n",
        "backbone_model.features[5][0].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[5][1].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[5][2].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[5][3].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "\n",
        "backbone_model.features[6][0].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][1].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][2].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][3].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][4].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][5].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "\n",
        "backbone_model.features[7][0].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[7][1].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "\n",
        "#print(backbone_model)\n",
        "\n",
        "class EffnetB3JointModel(nn.Module):\n",
        "    def __init__(self, backbone) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        # 3 super classes\n",
        "        self.superclass = nn.Linear(in_features = 1536, out_features = 3)\n",
        "        # 89 sub classes\n",
        "        self.subclass = nn.Linear(in_features = 1536, out_features = 89)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.backbone(x)\n",
        "        super_class_out = self.superclass(out)\n",
        "        sub_class_out = self.subclass(out)\n",
        "        return super_class_out, sub_class_out\n",
        "\n",
        "# Create the baseline model\n",
        "effnetb3_joint_model = EffnetB3JointModel(backbone_model)\n",
        "effnetb3_joint_model = effnetb3_joint_model.to(device, non_blocking = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctPMWCbPQgxo"
      },
      "source": [
        "##### Train the EfficientNetB3 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSndx9phQgxo"
      },
      "source": [
        "###### Freeze all the layers except Classifier layers (phase 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "K26DKgdcQgxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3bcd76c-a9b7-435b-cc2a-723b1d5fa8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 40, 32, 32]           1,080\n",
            "       BatchNorm2d-2           [-1, 40, 32, 32]              80\n",
            "              SiLU-3           [-1, 40, 32, 32]               0\n",
            "            Conv2d-4           [-1, 40, 32, 32]             360\n",
            "       BatchNorm2d-5           [-1, 40, 32, 32]              80\n",
            "              SiLU-6           [-1, 40, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 40, 1, 1]               0\n",
            "            Conv2d-8             [-1, 10, 1, 1]             410\n",
            "              SiLU-9             [-1, 10, 1, 1]               0\n",
            "           Conv2d-10             [-1, 40, 1, 1]             440\n",
            "          Sigmoid-11             [-1, 40, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 40, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]             960\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "          Dropout-19           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-20             [-1, 24, 1, 1]               0\n",
            "           Conv2d-21              [-1, 6, 1, 1]             150\n",
            "             SiLU-22              [-1, 6, 1, 1]               0\n",
            "           Conv2d-23             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-24             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-25           [-1, 24, 32, 32]               0\n",
            "           Conv2d-26           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-27           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-28           [-1, 24, 32, 32]               0\n",
            "           MBConv-29           [-1, 24, 32, 32]               0\n",
            "           Conv2d-30          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-31          [-1, 144, 32, 32]             288\n",
            "             SiLU-32          [-1, 144, 32, 32]               0\n",
            "           Conv2d-33          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-34          [-1, 144, 16, 16]             288\n",
            "             SiLU-35          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-36            [-1, 144, 1, 1]               0\n",
            "           Conv2d-37              [-1, 6, 1, 1]             870\n",
            "             SiLU-38              [-1, 6, 1, 1]               0\n",
            "           Conv2d-39            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-40            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-41          [-1, 144, 16, 16]               0\n",
            "           Conv2d-42           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "           MBConv-44           [-1, 32, 16, 16]               0\n",
            "           Conv2d-45          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-46          [-1, 192, 16, 16]             384\n",
            "             SiLU-47          [-1, 192, 16, 16]               0\n",
            "           Conv2d-48          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-49          [-1, 192, 16, 16]             384\n",
            "             SiLU-50          [-1, 192, 16, 16]               0\n",
            "          Dropout-51          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-52            [-1, 192, 1, 1]               0\n",
            "           Conv2d-53              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-54              [-1, 8, 1, 1]               0\n",
            "           Conv2d-55            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-56            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-57          [-1, 192, 16, 16]               0\n",
            "           Conv2d-58           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-60           [-1, 32, 16, 16]               0\n",
            "           MBConv-61           [-1, 32, 16, 16]               0\n",
            "           Conv2d-62          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-63          [-1, 192, 16, 16]             384\n",
            "             SiLU-64          [-1, 192, 16, 16]               0\n",
            "           Conv2d-65          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-66          [-1, 192, 16, 16]             384\n",
            "             SiLU-67          [-1, 192, 16, 16]               0\n",
            "          Dropout-68          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-69            [-1, 192, 1, 1]               0\n",
            "           Conv2d-70              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-71              [-1, 8, 1, 1]               0\n",
            "           Conv2d-72            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-73            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-74          [-1, 192, 16, 16]               0\n",
            "           Conv2d-75           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-76           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-77           [-1, 32, 16, 16]               0\n",
            "           MBConv-78           [-1, 32, 16, 16]               0\n",
            "           Conv2d-79          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-80          [-1, 192, 16, 16]             384\n",
            "             SiLU-81          [-1, 192, 16, 16]               0\n",
            "           Conv2d-82            [-1, 192, 8, 8]           4,800\n",
            "      BatchNorm2d-83            [-1, 192, 8, 8]             384\n",
            "             SiLU-84            [-1, 192, 8, 8]               0\n",
            "          Dropout-85            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-86            [-1, 192, 1, 1]               0\n",
            "           Conv2d-87              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-88              [-1, 8, 1, 1]               0\n",
            "           Conv2d-89            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-90            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-91            [-1, 192, 8, 8]               0\n",
            "           Conv2d-92             [-1, 48, 8, 8]           9,216\n",
            "      BatchNorm2d-93             [-1, 48, 8, 8]              96\n",
            "           MBConv-94             [-1, 48, 8, 8]               0\n",
            "           Conv2d-95            [-1, 288, 8, 8]          13,824\n",
            "      BatchNorm2d-96            [-1, 288, 8, 8]             576\n",
            "             SiLU-97            [-1, 288, 8, 8]               0\n",
            "           Conv2d-98            [-1, 288, 8, 8]           7,200\n",
            "      BatchNorm2d-99            [-1, 288, 8, 8]             576\n",
            "            SiLU-100            [-1, 288, 8, 8]               0\n",
            "         Dropout-101            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-102            [-1, 288, 1, 1]               0\n",
            "          Conv2d-103             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-104             [-1, 12, 1, 1]               0\n",
            "          Conv2d-105            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-106            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-107            [-1, 288, 8, 8]               0\n",
            "          Conv2d-108             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-109             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-110             [-1, 48, 8, 8]               0\n",
            "          MBConv-111             [-1, 48, 8, 8]               0\n",
            "          Conv2d-112            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-113            [-1, 288, 8, 8]             576\n",
            "            SiLU-114            [-1, 288, 8, 8]               0\n",
            "          Conv2d-115            [-1, 288, 8, 8]           7,200\n",
            "     BatchNorm2d-116            [-1, 288, 8, 8]             576\n",
            "            SiLU-117            [-1, 288, 8, 8]               0\n",
            "         Dropout-118            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-119            [-1, 288, 1, 1]               0\n",
            "          Conv2d-120             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-121             [-1, 12, 1, 1]               0\n",
            "          Conv2d-122            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-123            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-124            [-1, 288, 8, 8]               0\n",
            "          Conv2d-125             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-126             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-127             [-1, 48, 8, 8]               0\n",
            "          MBConv-128             [-1, 48, 8, 8]               0\n",
            "          Conv2d-129            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-130            [-1, 288, 8, 8]             576\n",
            "            SiLU-131            [-1, 288, 8, 8]               0\n",
            "          Conv2d-132            [-1, 288, 4, 4]           2,592\n",
            "     BatchNorm2d-133            [-1, 288, 4, 4]             576\n",
            "            SiLU-134            [-1, 288, 4, 4]               0\n",
            "         Dropout-135            [-1, 288, 4, 4]               0\n",
            "AdaptiveAvgPool2d-136            [-1, 288, 1, 1]               0\n",
            "          Conv2d-137             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-138             [-1, 12, 1, 1]               0\n",
            "          Conv2d-139            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-140            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-141            [-1, 288, 4, 4]               0\n",
            "          Conv2d-142             [-1, 96, 4, 4]          27,648\n",
            "     BatchNorm2d-143             [-1, 96, 4, 4]             192\n",
            "          MBConv-144             [-1, 96, 4, 4]               0\n",
            "          Conv2d-145            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-146            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-147            [-1, 576, 4, 4]               0\n",
            "          Conv2d-148            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-149            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-150            [-1, 576, 4, 4]               0\n",
            "         Dropout-151            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-152            [-1, 576, 1, 1]               0\n",
            "          Conv2d-153             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-154             [-1, 24, 1, 1]               0\n",
            "          Conv2d-155            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-156            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-157            [-1, 576, 4, 4]               0\n",
            "          Conv2d-158             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-159             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-160             [-1, 96, 4, 4]               0\n",
            "          MBConv-161             [-1, 96, 4, 4]               0\n",
            "          Conv2d-162            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-163            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-164            [-1, 576, 4, 4]               0\n",
            "          Conv2d-165            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-166            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-167            [-1, 576, 4, 4]               0\n",
            "         Dropout-168            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-169            [-1, 576, 1, 1]               0\n",
            "          Conv2d-170             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-171             [-1, 24, 1, 1]               0\n",
            "          Conv2d-172            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-173            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-174            [-1, 576, 4, 4]               0\n",
            "          Conv2d-175             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-176             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-177             [-1, 96, 4, 4]               0\n",
            "          MBConv-178             [-1, 96, 4, 4]               0\n",
            "          Conv2d-179            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-180            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-181            [-1, 576, 4, 4]               0\n",
            "          Conv2d-182            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-183            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-184            [-1, 576, 4, 4]               0\n",
            "         Dropout-185            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-186            [-1, 576, 1, 1]               0\n",
            "          Conv2d-187             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-188             [-1, 24, 1, 1]               0\n",
            "          Conv2d-189            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-190            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-191            [-1, 576, 4, 4]               0\n",
            "          Conv2d-192             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-193             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-194             [-1, 96, 4, 4]               0\n",
            "          MBConv-195             [-1, 96, 4, 4]               0\n",
            "          Conv2d-196            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-197            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-198            [-1, 576, 4, 4]               0\n",
            "          Conv2d-199            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-200            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-201            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-202            [-1, 576, 1, 1]               0\n",
            "          Conv2d-203             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-204             [-1, 24, 1, 1]               0\n",
            "          Conv2d-205            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-206            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-207            [-1, 576, 4, 4]               0\n",
            "          Conv2d-208             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-209             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-210             [-1, 96, 4, 4]               0\n",
            "          MBConv-211             [-1, 96, 4, 4]               0\n",
            "          Conv2d-212            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-213            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-214            [-1, 576, 4, 4]               0\n",
            "          Conv2d-215            [-1, 576, 4, 4]          14,400\n",
            "     BatchNorm2d-216            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-217            [-1, 576, 4, 4]               0\n",
            "         Dropout-218            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-219            [-1, 576, 1, 1]               0\n",
            "          Conv2d-220             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-221             [-1, 24, 1, 1]               0\n",
            "          Conv2d-222            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-223            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-224            [-1, 576, 4, 4]               0\n",
            "          Conv2d-225            [-1, 136, 4, 4]          78,336\n",
            "     BatchNorm2d-226            [-1, 136, 4, 4]             272\n",
            "          MBConv-227            [-1, 136, 4, 4]               0\n",
            "          Conv2d-228            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-229            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-230            [-1, 816, 4, 4]               0\n",
            "          Conv2d-231            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-232            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-233            [-1, 816, 4, 4]               0\n",
            "         Dropout-234            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-235            [-1, 816, 1, 1]               0\n",
            "          Conv2d-236             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-237             [-1, 34, 1, 1]               0\n",
            "          Conv2d-238            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-239            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-240            [-1, 816, 4, 4]               0\n",
            "          Conv2d-241            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-242            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-243            [-1, 136, 4, 4]               0\n",
            "          MBConv-244            [-1, 136, 4, 4]               0\n",
            "          Conv2d-245            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-246            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-247            [-1, 816, 4, 4]               0\n",
            "          Conv2d-248            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-249            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-250            [-1, 816, 4, 4]               0\n",
            "         Dropout-251            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-252            [-1, 816, 1, 1]               0\n",
            "          Conv2d-253             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-254             [-1, 34, 1, 1]               0\n",
            "          Conv2d-255            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-256            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-257            [-1, 816, 4, 4]               0\n",
            "          Conv2d-258            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-259            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-260            [-1, 136, 4, 4]               0\n",
            "          MBConv-261            [-1, 136, 4, 4]               0\n",
            "          Conv2d-262            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-263            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-264            [-1, 816, 4, 4]               0\n",
            "          Conv2d-265            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-266            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-267            [-1, 816, 4, 4]               0\n",
            "         Dropout-268            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-269            [-1, 816, 1, 1]               0\n",
            "          Conv2d-270             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-271             [-1, 34, 1, 1]               0\n",
            "          Conv2d-272            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-273            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-274            [-1, 816, 4, 4]               0\n",
            "          Conv2d-275            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-276            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-277            [-1, 136, 4, 4]               0\n",
            "          MBConv-278            [-1, 136, 4, 4]               0\n",
            "          Conv2d-279            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-280            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-281            [-1, 816, 4, 4]               0\n",
            "          Conv2d-282            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-283            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-284            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-285            [-1, 816, 1, 1]               0\n",
            "          Conv2d-286             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-287             [-1, 34, 1, 1]               0\n",
            "          Conv2d-288            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-289            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-290            [-1, 816, 4, 4]               0\n",
            "          Conv2d-291            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-292            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-293            [-1, 136, 4, 4]               0\n",
            "          MBConv-294            [-1, 136, 4, 4]               0\n",
            "          Conv2d-295            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-296            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-297            [-1, 816, 4, 4]               0\n",
            "          Conv2d-298            [-1, 816, 2, 2]          20,400\n",
            "     BatchNorm2d-299            [-1, 816, 2, 2]           1,632\n",
            "            SiLU-300            [-1, 816, 2, 2]               0\n",
            "         Dropout-301            [-1, 816, 2, 2]               0\n",
            "AdaptiveAvgPool2d-302            [-1, 816, 1, 1]               0\n",
            "          Conv2d-303             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-304             [-1, 34, 1, 1]               0\n",
            "          Conv2d-305            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-306            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-307            [-1, 816, 2, 2]               0\n",
            "          Conv2d-308            [-1, 232, 2, 2]         189,312\n",
            "     BatchNorm2d-309            [-1, 232, 2, 2]             464\n",
            "          MBConv-310            [-1, 232, 2, 2]               0\n",
            "          Conv2d-311           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-312           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-313           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-314           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-315           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-316           [-1, 1392, 2, 2]               0\n",
            "         Dropout-317           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-318           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-319             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-320             [-1, 58, 1, 1]               0\n",
            "          Conv2d-321           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-322           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-323           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-324            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-325            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-326            [-1, 232, 2, 2]               0\n",
            "          MBConv-327            [-1, 232, 2, 2]               0\n",
            "          Conv2d-328           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-329           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-330           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-331           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-332           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-333           [-1, 1392, 2, 2]               0\n",
            "         Dropout-334           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-335           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-336             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-337             [-1, 58, 1, 1]               0\n",
            "          Conv2d-338           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-339           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-340           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-341            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-342            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-343            [-1, 232, 2, 2]               0\n",
            "          MBConv-344            [-1, 232, 2, 2]               0\n",
            "          Conv2d-345           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-346           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-347           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-348           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-349           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-350           [-1, 1392, 2, 2]               0\n",
            "         Dropout-351           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-352           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-353             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-354             [-1, 58, 1, 1]               0\n",
            "          Conv2d-355           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-356           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-357           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-358            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-359            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-360            [-1, 232, 2, 2]               0\n",
            "          MBConv-361            [-1, 232, 2, 2]               0\n",
            "          Conv2d-362           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-363           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-364           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-365           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-366           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-367           [-1, 1392, 2, 2]               0\n",
            "         Dropout-368           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-369           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-370             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-371             [-1, 58, 1, 1]               0\n",
            "          Conv2d-372           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-373           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-374           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-375            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-376            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-377            [-1, 232, 2, 2]               0\n",
            "          MBConv-378            [-1, 232, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-380           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-381           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-382           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-383           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-384           [-1, 1392, 2, 2]               0\n",
            "         Dropout-385           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-386           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-387             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-388             [-1, 58, 1, 1]               0\n",
            "          Conv2d-389           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-390           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-391           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-392            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-393            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-394            [-1, 232, 2, 2]               0\n",
            "          MBConv-395            [-1, 232, 2, 2]               0\n",
            "          Conv2d-396           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-397           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-398           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-399           [-1, 1392, 2, 2]          12,528\n",
            "     BatchNorm2d-400           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-401           [-1, 1392, 2, 2]               0\n",
            "         Dropout-402           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-403           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-404             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-405             [-1, 58, 1, 1]               0\n",
            "          Conv2d-406           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-407           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-408           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-409            [-1, 384, 2, 2]         534,528\n",
            "     BatchNorm2d-410            [-1, 384, 2, 2]             768\n",
            "          MBConv-411            [-1, 384, 2, 2]               0\n",
            "          Conv2d-412           [-1, 2304, 2, 2]         884,736\n",
            "     BatchNorm2d-413           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-414           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-415           [-1, 2304, 2, 2]          20,736\n",
            "     BatchNorm2d-416           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-417           [-1, 2304, 2, 2]               0\n",
            "         Dropout-418           [-1, 2304, 2, 2]               0\n",
            "AdaptiveAvgPool2d-419           [-1, 2304, 1, 1]               0\n",
            "          Conv2d-420             [-1, 96, 1, 1]         221,280\n",
            "            SiLU-421             [-1, 96, 1, 1]               0\n",
            "          Conv2d-422           [-1, 2304, 1, 1]         223,488\n",
            "         Sigmoid-423           [-1, 2304, 1, 1]               0\n",
            "SqueezeExcitation-424           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-425            [-1, 384, 2, 2]         884,736\n",
            "     BatchNorm2d-426            [-1, 384, 2, 2]             768\n",
            " StochasticDepth-427            [-1, 384, 2, 2]               0\n",
            "          MBConv-428            [-1, 384, 2, 2]               0\n",
            "          Conv2d-429           [-1, 1536, 2, 2]         589,824\n",
            "     BatchNorm2d-430           [-1, 1536, 2, 2]           3,072\n",
            "            SiLU-431           [-1, 1536, 2, 2]               0\n",
            "AdaptiveAvgPool2d-432           [-1, 1536, 1, 1]               0\n",
            "        Identity-433                 [-1, 1536]               0\n",
            "    EfficientNet-434                 [-1, 1536]               0\n",
            "          Linear-435                    [-1, 3]           4,611\n",
            "          Linear-436                   [-1, 89]         136,793\n",
            "================================================================\n",
            "Total params: 10,837,636\n",
            "Trainable params: 141,404\n",
            "Non-trainable params: 10,696,232\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 30.59\n",
            "Params size (MB): 41.34\n",
            "Estimated Total Size (MB): 71.98\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with all backbone frozen)\n",
        "for param in effnetb3_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in effnetb3_joint_model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(effnetb3_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb3_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Nhv_gdjyQgxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4052bb85-b76b-4e2e-9a2f-a1654e5851fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 train: 100%|██████████| 495/495 [00:22<00:00, 21.80batch/s, loss=14.4, sub_class_accuracy=0, super_class_accuracy=0.333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train Super Class loss: 5.32523569161992 Super Class acc: 0.4190879166126251\n",
            "Sub Class loss: 8.975263571968098 Sub Class acc: 0.015980293974280357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 val: 100%|██████████| 23/23 [00:00<00:00, 26.82batch/s, loss=13.8, sub_class_accuracy=0.0333, super_class_accuracy=0.533]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 val Super Class loss: 4.928558260933255 Super Class acc: 0.5381471514701843\n",
            "Sub Class loss: 8.889733829030549 Sub Class acc: 0.0272479560226202\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 train: 100%|██████████| 495/495 [00:23<00:00, 20.88batch/s, loss=14.1, sub_class_accuracy=0, super_class_accuracy=0.333]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train Super Class loss: 5.099624229417177 Super Class acc: 0.4852829575538635\n",
            "Sub Class loss: 8.850223464156233 Sub Class acc: 0.024696815758943558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 val: 100%|██████████| 23/23 [00:00<00:00, 26.85batch/s, loss=13.5, sub_class_accuracy=0.0333, super_class_accuracy=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 val Super Class loss: 4.787609339247608 Super Class acc: 0.555858314037323\n",
            "Sub Class loss: 8.788221535955527 Sub Class acc: 0.03405994549393654\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 train: 100%|██████████| 495/495 [00:22<00:00, 21.70batch/s, loss=14, sub_class_accuracy=0.0417, super_class_accuracy=0.417]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train Super Class loss: 5.025078068181925 Super Class acc: 0.5017685890197754\n",
            "Sub Class loss: 8.762831346262217 Sub Class acc: 0.03031834214925766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 val: 100%|██████████| 23/23 [00:00<00:00, 26.98batch/s, loss=13.3, sub_class_accuracy=0.0333, super_class_accuracy=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 val Super Class loss: 4.726483453197115 Super Class acc: 0.5517711043357849\n",
            "Sub Class loss: 8.696751807626002 Sub Class acc: 0.042234331369400024\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 train: 100%|██████████| 495/495 [00:22<00:00, 21.77batch/s, loss=13.1, sub_class_accuracy=0, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train Super Class loss: 5.022950864699586 Super Class acc: 0.5008211135864258\n",
            "Sub Class loss: 8.704554017593669 Sub Class acc: 0.035624053329229355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 val: 100%|██████████| 23/23 [00:00<00:00, 26.69batch/s, loss=13.2, sub_class_accuracy=0.0667, super_class_accuracy=0.533]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 val Super Class loss: 4.705050738695856 Super Class acc: 0.5613079071044922\n",
            "Sub Class loss: 8.62757164126196 Sub Class acc: 0.04904632270336151\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 train: 100%|██████████| 495/495 [00:22<00:00, 21.77batch/s, loss=12.9, sub_class_accuracy=0.0417, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train Super Class loss: 4.985700293795637 Super Class acc: 0.503221333026886\n",
            "Sub Class loss: 8.646377952367503 Sub Class acc: 0.0396033339202404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 val: 100%|██████████| 23/23 [00:00<00:00, 26.96batch/s, loss=12.9, sub_class_accuracy=0.0333, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 val Super Class loss: 4.625527058862535 Super Class acc: 0.580381453037262\n",
            "Sub Class loss: 8.568694379738956 Sub Class acc: 0.05994550138711929\n",
            "--------------------\n",
            "Best Super Class val acc: 0.580381453037262\n",
            "Best Sub Class val acc: 0.05994550138711929\n",
            "Average Time taken for an epoch: 24.06867733001709 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "initial_epoch = 0\n",
        "learning_rate = 1e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb3_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='EnsembleJoint_EffnetB3_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jbQ5IDRQgxo"
      },
      "source": [
        "###### Unfreeze some layers of the backbone network (phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PAyd_FpjQgxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d764d90-c689-41af-ef1d-754830ba33a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 40, 32, 32]           1,080\n",
            "       BatchNorm2d-2           [-1, 40, 32, 32]              80\n",
            "              SiLU-3           [-1, 40, 32, 32]               0\n",
            "            Conv2d-4           [-1, 40, 32, 32]             360\n",
            "       BatchNorm2d-5           [-1, 40, 32, 32]              80\n",
            "              SiLU-6           [-1, 40, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 40, 1, 1]               0\n",
            "            Conv2d-8             [-1, 10, 1, 1]             410\n",
            "              SiLU-9             [-1, 10, 1, 1]               0\n",
            "           Conv2d-10             [-1, 40, 1, 1]             440\n",
            "          Sigmoid-11             [-1, 40, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 40, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]             960\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "          Dropout-19           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-20             [-1, 24, 1, 1]               0\n",
            "           Conv2d-21              [-1, 6, 1, 1]             150\n",
            "             SiLU-22              [-1, 6, 1, 1]               0\n",
            "           Conv2d-23             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-24             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-25           [-1, 24, 32, 32]               0\n",
            "           Conv2d-26           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-27           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-28           [-1, 24, 32, 32]               0\n",
            "           MBConv-29           [-1, 24, 32, 32]               0\n",
            "           Conv2d-30          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-31          [-1, 144, 32, 32]             288\n",
            "             SiLU-32          [-1, 144, 32, 32]               0\n",
            "           Conv2d-33          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-34          [-1, 144, 16, 16]             288\n",
            "             SiLU-35          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-36            [-1, 144, 1, 1]               0\n",
            "           Conv2d-37              [-1, 6, 1, 1]             870\n",
            "             SiLU-38              [-1, 6, 1, 1]               0\n",
            "           Conv2d-39            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-40            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-41          [-1, 144, 16, 16]               0\n",
            "           Conv2d-42           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "           MBConv-44           [-1, 32, 16, 16]               0\n",
            "           Conv2d-45          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-46          [-1, 192, 16, 16]             384\n",
            "             SiLU-47          [-1, 192, 16, 16]               0\n",
            "           Conv2d-48          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-49          [-1, 192, 16, 16]             384\n",
            "             SiLU-50          [-1, 192, 16, 16]               0\n",
            "          Dropout-51          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-52            [-1, 192, 1, 1]               0\n",
            "           Conv2d-53              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-54              [-1, 8, 1, 1]               0\n",
            "           Conv2d-55            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-56            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-57          [-1, 192, 16, 16]               0\n",
            "           Conv2d-58           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-60           [-1, 32, 16, 16]               0\n",
            "           MBConv-61           [-1, 32, 16, 16]               0\n",
            "           Conv2d-62          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-63          [-1, 192, 16, 16]             384\n",
            "             SiLU-64          [-1, 192, 16, 16]               0\n",
            "           Conv2d-65          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-66          [-1, 192, 16, 16]             384\n",
            "             SiLU-67          [-1, 192, 16, 16]               0\n",
            "          Dropout-68          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-69            [-1, 192, 1, 1]               0\n",
            "           Conv2d-70              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-71              [-1, 8, 1, 1]               0\n",
            "           Conv2d-72            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-73            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-74          [-1, 192, 16, 16]               0\n",
            "           Conv2d-75           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-76           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-77           [-1, 32, 16, 16]               0\n",
            "           MBConv-78           [-1, 32, 16, 16]               0\n",
            "           Conv2d-79          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-80          [-1, 192, 16, 16]             384\n",
            "             SiLU-81          [-1, 192, 16, 16]               0\n",
            "           Conv2d-82            [-1, 192, 8, 8]           4,800\n",
            "      BatchNorm2d-83            [-1, 192, 8, 8]             384\n",
            "             SiLU-84            [-1, 192, 8, 8]               0\n",
            "          Dropout-85            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-86            [-1, 192, 1, 1]               0\n",
            "           Conv2d-87              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-88              [-1, 8, 1, 1]               0\n",
            "           Conv2d-89            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-90            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-91            [-1, 192, 8, 8]               0\n",
            "           Conv2d-92             [-1, 48, 8, 8]           9,216\n",
            "      BatchNorm2d-93             [-1, 48, 8, 8]              96\n",
            "           MBConv-94             [-1, 48, 8, 8]               0\n",
            "           Conv2d-95            [-1, 288, 8, 8]          13,824\n",
            "      BatchNorm2d-96            [-1, 288, 8, 8]             576\n",
            "             SiLU-97            [-1, 288, 8, 8]               0\n",
            "           Conv2d-98            [-1, 288, 8, 8]           7,200\n",
            "      BatchNorm2d-99            [-1, 288, 8, 8]             576\n",
            "            SiLU-100            [-1, 288, 8, 8]               0\n",
            "         Dropout-101            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-102            [-1, 288, 1, 1]               0\n",
            "          Conv2d-103             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-104             [-1, 12, 1, 1]               0\n",
            "          Conv2d-105            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-106            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-107            [-1, 288, 8, 8]               0\n",
            "          Conv2d-108             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-109             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-110             [-1, 48, 8, 8]               0\n",
            "          MBConv-111             [-1, 48, 8, 8]               0\n",
            "          Conv2d-112            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-113            [-1, 288, 8, 8]             576\n",
            "            SiLU-114            [-1, 288, 8, 8]               0\n",
            "          Conv2d-115            [-1, 288, 8, 8]           7,200\n",
            "     BatchNorm2d-116            [-1, 288, 8, 8]             576\n",
            "            SiLU-117            [-1, 288, 8, 8]               0\n",
            "         Dropout-118            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-119            [-1, 288, 1, 1]               0\n",
            "          Conv2d-120             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-121             [-1, 12, 1, 1]               0\n",
            "          Conv2d-122            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-123            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-124            [-1, 288, 8, 8]               0\n",
            "          Conv2d-125             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-126             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-127             [-1, 48, 8, 8]               0\n",
            "          MBConv-128             [-1, 48, 8, 8]               0\n",
            "          Conv2d-129            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-130            [-1, 288, 8, 8]             576\n",
            "            SiLU-131            [-1, 288, 8, 8]               0\n",
            "          Conv2d-132            [-1, 288, 4, 4]           2,592\n",
            "     BatchNorm2d-133            [-1, 288, 4, 4]             576\n",
            "            SiLU-134            [-1, 288, 4, 4]               0\n",
            "         Dropout-135            [-1, 288, 4, 4]               0\n",
            "AdaptiveAvgPool2d-136            [-1, 288, 1, 1]               0\n",
            "          Conv2d-137             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-138             [-1, 12, 1, 1]               0\n",
            "          Conv2d-139            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-140            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-141            [-1, 288, 4, 4]               0\n",
            "          Conv2d-142             [-1, 96, 4, 4]          27,648\n",
            "     BatchNorm2d-143             [-1, 96, 4, 4]             192\n",
            "          MBConv-144             [-1, 96, 4, 4]               0\n",
            "          Conv2d-145            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-146            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-147            [-1, 576, 4, 4]               0\n",
            "          Conv2d-148            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-149            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-150            [-1, 576, 4, 4]               0\n",
            "         Dropout-151            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-152            [-1, 576, 1, 1]               0\n",
            "          Conv2d-153             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-154             [-1, 24, 1, 1]               0\n",
            "          Conv2d-155            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-156            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-157            [-1, 576, 4, 4]               0\n",
            "          Conv2d-158             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-159             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-160             [-1, 96, 4, 4]               0\n",
            "          MBConv-161             [-1, 96, 4, 4]               0\n",
            "          Conv2d-162            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-163            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-164            [-1, 576, 4, 4]               0\n",
            "          Conv2d-165            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-166            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-167            [-1, 576, 4, 4]               0\n",
            "         Dropout-168            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-169            [-1, 576, 1, 1]               0\n",
            "          Conv2d-170             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-171             [-1, 24, 1, 1]               0\n",
            "          Conv2d-172            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-173            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-174            [-1, 576, 4, 4]               0\n",
            "          Conv2d-175             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-176             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-177             [-1, 96, 4, 4]               0\n",
            "          MBConv-178             [-1, 96, 4, 4]               0\n",
            "          Conv2d-179            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-180            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-181            [-1, 576, 4, 4]               0\n",
            "          Conv2d-182            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-183            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-184            [-1, 576, 4, 4]               0\n",
            "         Dropout-185            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-186            [-1, 576, 1, 1]               0\n",
            "          Conv2d-187             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-188             [-1, 24, 1, 1]               0\n",
            "          Conv2d-189            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-190            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-191            [-1, 576, 4, 4]               0\n",
            "          Conv2d-192             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-193             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-194             [-1, 96, 4, 4]               0\n",
            "          MBConv-195             [-1, 96, 4, 4]               0\n",
            "          Conv2d-196            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-197            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-198            [-1, 576, 4, 4]               0\n",
            "          Conv2d-199            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-200            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-201            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-202            [-1, 576, 1, 1]               0\n",
            "          Conv2d-203             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-204             [-1, 24, 1, 1]               0\n",
            "          Conv2d-205            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-206            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-207            [-1, 576, 4, 4]               0\n",
            "          Conv2d-208             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-209             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-210             [-1, 96, 4, 4]               0\n",
            "          MBConv-211             [-1, 96, 4, 4]               0\n",
            "          Conv2d-212            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-213            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-214            [-1, 576, 4, 4]               0\n",
            "          Conv2d-215            [-1, 576, 4, 4]          14,400\n",
            "     BatchNorm2d-216            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-217            [-1, 576, 4, 4]               0\n",
            "         Dropout-218            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-219            [-1, 576, 1, 1]               0\n",
            "          Conv2d-220             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-221             [-1, 24, 1, 1]               0\n",
            "          Conv2d-222            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-223            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-224            [-1, 576, 4, 4]               0\n",
            "          Conv2d-225            [-1, 136, 4, 4]          78,336\n",
            "     BatchNorm2d-226            [-1, 136, 4, 4]             272\n",
            "          MBConv-227            [-1, 136, 4, 4]               0\n",
            "          Conv2d-228            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-229            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-230            [-1, 816, 4, 4]               0\n",
            "          Conv2d-231            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-232            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-233            [-1, 816, 4, 4]               0\n",
            "         Dropout-234            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-235            [-1, 816, 1, 1]               0\n",
            "          Conv2d-236             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-237             [-1, 34, 1, 1]               0\n",
            "          Conv2d-238            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-239            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-240            [-1, 816, 4, 4]               0\n",
            "          Conv2d-241            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-242            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-243            [-1, 136, 4, 4]               0\n",
            "          MBConv-244            [-1, 136, 4, 4]               0\n",
            "          Conv2d-245            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-246            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-247            [-1, 816, 4, 4]               0\n",
            "          Conv2d-248            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-249            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-250            [-1, 816, 4, 4]               0\n",
            "         Dropout-251            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-252            [-1, 816, 1, 1]               0\n",
            "          Conv2d-253             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-254             [-1, 34, 1, 1]               0\n",
            "          Conv2d-255            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-256            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-257            [-1, 816, 4, 4]               0\n",
            "          Conv2d-258            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-259            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-260            [-1, 136, 4, 4]               0\n",
            "          MBConv-261            [-1, 136, 4, 4]               0\n",
            "          Conv2d-262            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-263            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-264            [-1, 816, 4, 4]               0\n",
            "          Conv2d-265            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-266            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-267            [-1, 816, 4, 4]               0\n",
            "         Dropout-268            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-269            [-1, 816, 1, 1]               0\n",
            "          Conv2d-270             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-271             [-1, 34, 1, 1]               0\n",
            "          Conv2d-272            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-273            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-274            [-1, 816, 4, 4]               0\n",
            "          Conv2d-275            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-276            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-277            [-1, 136, 4, 4]               0\n",
            "          MBConv-278            [-1, 136, 4, 4]               0\n",
            "          Conv2d-279            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-280            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-281            [-1, 816, 4, 4]               0\n",
            "          Conv2d-282            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-283            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-284            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-285            [-1, 816, 1, 1]               0\n",
            "          Conv2d-286             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-287             [-1, 34, 1, 1]               0\n",
            "          Conv2d-288            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-289            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-290            [-1, 816, 4, 4]               0\n",
            "          Conv2d-291            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-292            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-293            [-1, 136, 4, 4]               0\n",
            "          MBConv-294            [-1, 136, 4, 4]               0\n",
            "          Conv2d-295            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-296            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-297            [-1, 816, 4, 4]               0\n",
            "          Conv2d-298            [-1, 816, 2, 2]          20,400\n",
            "     BatchNorm2d-299            [-1, 816, 2, 2]           1,632\n",
            "            SiLU-300            [-1, 816, 2, 2]               0\n",
            "         Dropout-301            [-1, 816, 2, 2]               0\n",
            "AdaptiveAvgPool2d-302            [-1, 816, 1, 1]               0\n",
            "          Conv2d-303             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-304             [-1, 34, 1, 1]               0\n",
            "          Conv2d-305            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-306            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-307            [-1, 816, 2, 2]               0\n",
            "          Conv2d-308            [-1, 232, 2, 2]         189,312\n",
            "     BatchNorm2d-309            [-1, 232, 2, 2]             464\n",
            "          MBConv-310            [-1, 232, 2, 2]               0\n",
            "          Conv2d-311           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-312           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-313           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-314           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-315           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-316           [-1, 1392, 2, 2]               0\n",
            "         Dropout-317           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-318           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-319             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-320             [-1, 58, 1, 1]               0\n",
            "          Conv2d-321           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-322           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-323           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-324            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-325            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-326            [-1, 232, 2, 2]               0\n",
            "          MBConv-327            [-1, 232, 2, 2]               0\n",
            "          Conv2d-328           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-329           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-330           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-331           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-332           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-333           [-1, 1392, 2, 2]               0\n",
            "         Dropout-334           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-335           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-336             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-337             [-1, 58, 1, 1]               0\n",
            "          Conv2d-338           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-339           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-340           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-341            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-342            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-343            [-1, 232, 2, 2]               0\n",
            "          MBConv-344            [-1, 232, 2, 2]               0\n",
            "          Conv2d-345           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-346           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-347           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-348           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-349           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-350           [-1, 1392, 2, 2]               0\n",
            "         Dropout-351           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-352           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-353             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-354             [-1, 58, 1, 1]               0\n",
            "          Conv2d-355           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-356           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-357           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-358            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-359            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-360            [-1, 232, 2, 2]               0\n",
            "          MBConv-361            [-1, 232, 2, 2]               0\n",
            "          Conv2d-362           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-363           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-364           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-365           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-366           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-367           [-1, 1392, 2, 2]               0\n",
            "         Dropout-368           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-369           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-370             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-371             [-1, 58, 1, 1]               0\n",
            "          Conv2d-372           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-373           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-374           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-375            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-376            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-377            [-1, 232, 2, 2]               0\n",
            "          MBConv-378            [-1, 232, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-380           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-381           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-382           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-383           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-384           [-1, 1392, 2, 2]               0\n",
            "         Dropout-385           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-386           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-387             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-388             [-1, 58, 1, 1]               0\n",
            "          Conv2d-389           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-390           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-391           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-392            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-393            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-394            [-1, 232, 2, 2]               0\n",
            "          MBConv-395            [-1, 232, 2, 2]               0\n",
            "          Conv2d-396           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-397           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-398           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-399           [-1, 1392, 2, 2]          12,528\n",
            "     BatchNorm2d-400           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-401           [-1, 1392, 2, 2]               0\n",
            "         Dropout-402           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-403           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-404             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-405             [-1, 58, 1, 1]               0\n",
            "          Conv2d-406           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-407           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-408           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-409            [-1, 384, 2, 2]         534,528\n",
            "     BatchNorm2d-410            [-1, 384, 2, 2]             768\n",
            "          MBConv-411            [-1, 384, 2, 2]               0\n",
            "          Conv2d-412           [-1, 2304, 2, 2]         884,736\n",
            "     BatchNorm2d-413           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-414           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-415           [-1, 2304, 2, 2]          20,736\n",
            "     BatchNorm2d-416           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-417           [-1, 2304, 2, 2]               0\n",
            "         Dropout-418           [-1, 2304, 2, 2]               0\n",
            "AdaptiveAvgPool2d-419           [-1, 2304, 1, 1]               0\n",
            "          Conv2d-420             [-1, 96, 1, 1]         221,280\n",
            "            SiLU-421             [-1, 96, 1, 1]               0\n",
            "          Conv2d-422           [-1, 2304, 1, 1]         223,488\n",
            "         Sigmoid-423           [-1, 2304, 1, 1]               0\n",
            "SqueezeExcitation-424           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-425            [-1, 384, 2, 2]         884,736\n",
            "     BatchNorm2d-426            [-1, 384, 2, 2]             768\n",
            " StochasticDepth-427            [-1, 384, 2, 2]               0\n",
            "          MBConv-428            [-1, 384, 2, 2]               0\n",
            "          Conv2d-429           [-1, 1536, 2, 2]         589,824\n",
            "     BatchNorm2d-430           [-1, 1536, 2, 2]           3,072\n",
            "            SiLU-431           [-1, 1536, 2, 2]               0\n",
            "AdaptiveAvgPool2d-432           [-1, 1536, 1, 1]               0\n",
            "        Identity-433                 [-1, 1536]               0\n",
            "    EfficientNet-434                 [-1, 1536]               0\n",
            "          Linear-435                    [-1, 3]           4,611\n",
            "          Linear-436                   [-1, 89]         136,793\n",
            "================================================================\n",
            "Total params: 10,837,636\n",
            "Trainable params: 4,018,518\n",
            "Non-trainable params: 6,819,118\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 30.59\n",
            "Params size (MB): 41.34\n",
            "Estimated Total Size (MB): 71.98\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with some backbone frozen)\n",
        "for param in effnetb3_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in effnetb3_joint_model.backbone.features[:7].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(effnetb3_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb3_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "d7a9w168Qgxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c545f0-e4fc-4912-ffbc-45885a225106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 train: 100%|██████████| 495/495 [00:25<00:00, 19.26batch/s, loss=12.9, sub_class_accuracy=0.0417, super_class_accuracy=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train Super Class loss: 4.762822962457812 Super Class acc: 0.5478145480155945\n",
            "Sub Class loss: 8.386173919091748 Sub Class acc: 0.04781455174088478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 val: 100%|██████████| 23/23 [00:00<00:00, 27.41batch/s, loss=11.8, sub_class_accuracy=0, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 val Super Class loss: 4.1333256909567915 Super Class acc: 0.6430517435073853\n",
            "Sub Class loss: 8.00930689466097 Sub Class acc: 0.07220708578824997\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 train: 100%|██████████| 495/495 [00:25<00:00, 19.41batch/s, loss=12, sub_class_accuracy=0.0417, super_class_accuracy=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train Super Class loss: 4.552533632730703 Super Class acc: 0.5769959688186646\n",
            "Sub Class loss: 8.105293791242294 Sub Class acc: 0.06385800987482071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 val: 100%|██████████| 23/23 [00:00<00:00, 27.24batch/s, loss=11.4, sub_class_accuracy=0.0333, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 val Super Class loss: 3.854064148843126 Super Class acc: 0.6471389532089233\n",
            "Sub Class loss: 7.748621700245288 Sub Class acc: 0.09264305233955383\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 train: 100%|██████████| 495/495 [00:25<00:00, 19.61batch/s, loss=14.2, sub_class_accuracy=0.0417, super_class_accuracy=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train Super Class loss: 4.44180630023218 Super Class acc: 0.5874179005622864\n",
            "Sub Class loss: 7.9622077831058204 Sub Class acc: 0.07187973707914352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 val: 100%|██████████| 23/23 [00:00<00:00, 27.44batch/s, loss=11.1, sub_class_accuracy=0.1, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 val Super Class loss: 3.722414061711335 Super Class acc: 0.6662124991416931\n",
            "Sub Class loss: 7.64882706166613 Sub Class acc: 0.10354223102331161\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 train: 100%|██████████| 495/495 [00:25<00:00, 19.67batch/s, loss=12.3, sub_class_accuracy=0.125, super_class_accuracy=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 train Super Class loss: 4.378631076407951 Super Class acc: 0.5941131711006165\n",
            "Sub Class loss: 7.868055672040788 Sub Class acc: 0.07863820344209671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 val: 100%|██████████| 23/23 [00:00<00:00, 26.98batch/s, loss=10.8, sub_class_accuracy=0.0333, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 val Super Class loss: 3.6078077359810186 Super Class acc: 0.6866484880447388\n",
            "Sub Class loss: 7.445745009492463 Sub Class acc: 0.10626702755689621\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 train: 100%|██████████| 495/495 [00:25<00:00, 19.59batch/s, loss=12.7, sub_class_accuracy=0, super_class_accuracy=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 train Super Class loss: 4.33045416708966 Super Class acc: 0.598787248134613\n",
            "Sub Class loss: 7.797541122956972 Sub Class acc: 0.08312278985977173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 val: 100%|██████████| 23/23 [00:00<00:00, 24.57batch/s, loss=10.5, sub_class_accuracy=0.0667, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 val Super Class loss: 3.6417783808968047 Super Class acc: 0.6825612783432007\n",
            "Sub Class loss: 7.389232044323913 Sub Class acc: 0.12125340104103088\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 train: 100%|██████████| 495/495 [00:25<00:00, 19.49batch/s, loss=11.8, sub_class_accuracy=0.0833, super_class_accuracy=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 train Super Class loss: 4.32896096050408 Super Class acc: 0.6006821393966675\n",
            "Sub Class loss: 7.745676064985217 Sub Class acc: 0.08400707691907883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 val: 100%|██████████| 23/23 [00:00<00:00, 26.91batch/s, loss=10.7, sub_class_accuracy=0.0333, super_class_accuracy=0.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 val Super Class loss: 3.538495126797003 Super Class acc: 0.7070844769477844\n",
            "Sub Class loss: 7.422636306253376 Sub Class acc: 0.11852861195802689\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 train: 100%|██████████| 495/495 [00:25<00:00, 19.34batch/s, loss=13.6, sub_class_accuracy=0.0833, super_class_accuracy=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 train Super Class loss: 4.27964522297663 Super Class acc: 0.6071879863739014\n",
            "Sub Class loss: 7.700938112992358 Sub Class acc: 0.08596513420343399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 val: 100%|██████████| 23/23 [00:00<00:00, 25.88batch/s, loss=10.7, sub_class_accuracy=0.0667, super_class_accuracy=0.767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 val Super Class loss: 3.5377499404330344 Super Class acc: 0.6948229074478149\n",
            "Sub Class loss: 7.344353248377912 Sub Class acc: 0.12397819757461548\n",
            "--------------------\n",
            "Best Super Class val acc: 0.7070844769477844\n",
            "Best Sub Class val acc: 0.12397819757461548\n",
            "Average Time taken for an epoch: 26.51488951274327 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 7\n",
        "initial_epoch = 5\n",
        "learning_rate = 3e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb3_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='EnsembleJoint_EffnetB3_semi_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40xH9IoTQgxp"
      },
      "source": [
        "###### Unfreeze all the layers in the network (phase 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "87oDcPIyQgxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ee7fb6-6abb-4c78-fdae-ecb10495be8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 40, 32, 32]           1,080\n",
            "       BatchNorm2d-2           [-1, 40, 32, 32]              80\n",
            "              SiLU-3           [-1, 40, 32, 32]               0\n",
            "            Conv2d-4           [-1, 40, 32, 32]             360\n",
            "       BatchNorm2d-5           [-1, 40, 32, 32]              80\n",
            "              SiLU-6           [-1, 40, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 40, 1, 1]               0\n",
            "            Conv2d-8             [-1, 10, 1, 1]             410\n",
            "              SiLU-9             [-1, 10, 1, 1]               0\n",
            "           Conv2d-10             [-1, 40, 1, 1]             440\n",
            "          Sigmoid-11             [-1, 40, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 40, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]             960\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "          Dropout-19           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-20             [-1, 24, 1, 1]               0\n",
            "           Conv2d-21              [-1, 6, 1, 1]             150\n",
            "             SiLU-22              [-1, 6, 1, 1]               0\n",
            "           Conv2d-23             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-24             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-25           [-1, 24, 32, 32]               0\n",
            "           Conv2d-26           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-27           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-28           [-1, 24, 32, 32]               0\n",
            "           MBConv-29           [-1, 24, 32, 32]               0\n",
            "           Conv2d-30          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-31          [-1, 144, 32, 32]             288\n",
            "             SiLU-32          [-1, 144, 32, 32]               0\n",
            "           Conv2d-33          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-34          [-1, 144, 16, 16]             288\n",
            "             SiLU-35          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-36            [-1, 144, 1, 1]               0\n",
            "           Conv2d-37              [-1, 6, 1, 1]             870\n",
            "             SiLU-38              [-1, 6, 1, 1]               0\n",
            "           Conv2d-39            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-40            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-41          [-1, 144, 16, 16]               0\n",
            "           Conv2d-42           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "           MBConv-44           [-1, 32, 16, 16]               0\n",
            "           Conv2d-45          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-46          [-1, 192, 16, 16]             384\n",
            "             SiLU-47          [-1, 192, 16, 16]               0\n",
            "           Conv2d-48          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-49          [-1, 192, 16, 16]             384\n",
            "             SiLU-50          [-1, 192, 16, 16]               0\n",
            "          Dropout-51          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-52            [-1, 192, 1, 1]               0\n",
            "           Conv2d-53              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-54              [-1, 8, 1, 1]               0\n",
            "           Conv2d-55            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-56            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-57          [-1, 192, 16, 16]               0\n",
            "           Conv2d-58           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-60           [-1, 32, 16, 16]               0\n",
            "           MBConv-61           [-1, 32, 16, 16]               0\n",
            "           Conv2d-62          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-63          [-1, 192, 16, 16]             384\n",
            "             SiLU-64          [-1, 192, 16, 16]               0\n",
            "           Conv2d-65          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-66          [-1, 192, 16, 16]             384\n",
            "             SiLU-67          [-1, 192, 16, 16]               0\n",
            "          Dropout-68          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-69            [-1, 192, 1, 1]               0\n",
            "           Conv2d-70              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-71              [-1, 8, 1, 1]               0\n",
            "           Conv2d-72            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-73            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-74          [-1, 192, 16, 16]               0\n",
            "           Conv2d-75           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-76           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-77           [-1, 32, 16, 16]               0\n",
            "           MBConv-78           [-1, 32, 16, 16]               0\n",
            "           Conv2d-79          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-80          [-1, 192, 16, 16]             384\n",
            "             SiLU-81          [-1, 192, 16, 16]               0\n",
            "           Conv2d-82            [-1, 192, 8, 8]           4,800\n",
            "      BatchNorm2d-83            [-1, 192, 8, 8]             384\n",
            "             SiLU-84            [-1, 192, 8, 8]               0\n",
            "          Dropout-85            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-86            [-1, 192, 1, 1]               0\n",
            "           Conv2d-87              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-88              [-1, 8, 1, 1]               0\n",
            "           Conv2d-89            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-90            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-91            [-1, 192, 8, 8]               0\n",
            "           Conv2d-92             [-1, 48, 8, 8]           9,216\n",
            "      BatchNorm2d-93             [-1, 48, 8, 8]              96\n",
            "           MBConv-94             [-1, 48, 8, 8]               0\n",
            "           Conv2d-95            [-1, 288, 8, 8]          13,824\n",
            "      BatchNorm2d-96            [-1, 288, 8, 8]             576\n",
            "             SiLU-97            [-1, 288, 8, 8]               0\n",
            "           Conv2d-98            [-1, 288, 8, 8]           7,200\n",
            "      BatchNorm2d-99            [-1, 288, 8, 8]             576\n",
            "            SiLU-100            [-1, 288, 8, 8]               0\n",
            "         Dropout-101            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-102            [-1, 288, 1, 1]               0\n",
            "          Conv2d-103             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-104             [-1, 12, 1, 1]               0\n",
            "          Conv2d-105            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-106            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-107            [-1, 288, 8, 8]               0\n",
            "          Conv2d-108             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-109             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-110             [-1, 48, 8, 8]               0\n",
            "          MBConv-111             [-1, 48, 8, 8]               0\n",
            "          Conv2d-112            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-113            [-1, 288, 8, 8]             576\n",
            "            SiLU-114            [-1, 288, 8, 8]               0\n",
            "          Conv2d-115            [-1, 288, 8, 8]           7,200\n",
            "     BatchNorm2d-116            [-1, 288, 8, 8]             576\n",
            "            SiLU-117            [-1, 288, 8, 8]               0\n",
            "         Dropout-118            [-1, 288, 8, 8]               0\n",
            "AdaptiveAvgPool2d-119            [-1, 288, 1, 1]               0\n",
            "          Conv2d-120             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-121             [-1, 12, 1, 1]               0\n",
            "          Conv2d-122            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-123            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-124            [-1, 288, 8, 8]               0\n",
            "          Conv2d-125             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-126             [-1, 48, 8, 8]              96\n",
            " StochasticDepth-127             [-1, 48, 8, 8]               0\n",
            "          MBConv-128             [-1, 48, 8, 8]               0\n",
            "          Conv2d-129            [-1, 288, 8, 8]          13,824\n",
            "     BatchNorm2d-130            [-1, 288, 8, 8]             576\n",
            "            SiLU-131            [-1, 288, 8, 8]               0\n",
            "          Conv2d-132            [-1, 288, 4, 4]           2,592\n",
            "     BatchNorm2d-133            [-1, 288, 4, 4]             576\n",
            "            SiLU-134            [-1, 288, 4, 4]               0\n",
            "         Dropout-135            [-1, 288, 4, 4]               0\n",
            "AdaptiveAvgPool2d-136            [-1, 288, 1, 1]               0\n",
            "          Conv2d-137             [-1, 12, 1, 1]           3,468\n",
            "            SiLU-138             [-1, 12, 1, 1]               0\n",
            "          Conv2d-139            [-1, 288, 1, 1]           3,744\n",
            "         Sigmoid-140            [-1, 288, 1, 1]               0\n",
            "SqueezeExcitation-141            [-1, 288, 4, 4]               0\n",
            "          Conv2d-142             [-1, 96, 4, 4]          27,648\n",
            "     BatchNorm2d-143             [-1, 96, 4, 4]             192\n",
            "          MBConv-144             [-1, 96, 4, 4]               0\n",
            "          Conv2d-145            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-146            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-147            [-1, 576, 4, 4]               0\n",
            "          Conv2d-148            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-149            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-150            [-1, 576, 4, 4]               0\n",
            "         Dropout-151            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-152            [-1, 576, 1, 1]               0\n",
            "          Conv2d-153             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-154             [-1, 24, 1, 1]               0\n",
            "          Conv2d-155            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-156            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-157            [-1, 576, 4, 4]               0\n",
            "          Conv2d-158             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-159             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-160             [-1, 96, 4, 4]               0\n",
            "          MBConv-161             [-1, 96, 4, 4]               0\n",
            "          Conv2d-162            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-163            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-164            [-1, 576, 4, 4]               0\n",
            "          Conv2d-165            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-166            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-167            [-1, 576, 4, 4]               0\n",
            "         Dropout-168            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-169            [-1, 576, 1, 1]               0\n",
            "          Conv2d-170             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-171             [-1, 24, 1, 1]               0\n",
            "          Conv2d-172            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-173            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-174            [-1, 576, 4, 4]               0\n",
            "          Conv2d-175             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-176             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-177             [-1, 96, 4, 4]               0\n",
            "          MBConv-178             [-1, 96, 4, 4]               0\n",
            "          Conv2d-179            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-180            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-181            [-1, 576, 4, 4]               0\n",
            "          Conv2d-182            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-183            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-184            [-1, 576, 4, 4]               0\n",
            "         Dropout-185            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-186            [-1, 576, 1, 1]               0\n",
            "          Conv2d-187             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-188             [-1, 24, 1, 1]               0\n",
            "          Conv2d-189            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-190            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-191            [-1, 576, 4, 4]               0\n",
            "          Conv2d-192             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-193             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-194             [-1, 96, 4, 4]               0\n",
            "          MBConv-195             [-1, 96, 4, 4]               0\n",
            "          Conv2d-196            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-197            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-198            [-1, 576, 4, 4]               0\n",
            "          Conv2d-199            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-200            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-201            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-202            [-1, 576, 1, 1]               0\n",
            "          Conv2d-203             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-204             [-1, 24, 1, 1]               0\n",
            "          Conv2d-205            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-206            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-207            [-1, 576, 4, 4]               0\n",
            "          Conv2d-208             [-1, 96, 4, 4]          55,296\n",
            "     BatchNorm2d-209             [-1, 96, 4, 4]             192\n",
            " StochasticDepth-210             [-1, 96, 4, 4]               0\n",
            "          MBConv-211             [-1, 96, 4, 4]               0\n",
            "          Conv2d-212            [-1, 576, 4, 4]          55,296\n",
            "     BatchNorm2d-213            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-214            [-1, 576, 4, 4]               0\n",
            "          Conv2d-215            [-1, 576, 4, 4]          14,400\n",
            "     BatchNorm2d-216            [-1, 576, 4, 4]           1,152\n",
            "            SiLU-217            [-1, 576, 4, 4]               0\n",
            "         Dropout-218            [-1, 576, 4, 4]               0\n",
            "AdaptiveAvgPool2d-219            [-1, 576, 1, 1]               0\n",
            "          Conv2d-220             [-1, 24, 1, 1]          13,848\n",
            "            SiLU-221             [-1, 24, 1, 1]               0\n",
            "          Conv2d-222            [-1, 576, 1, 1]          14,400\n",
            "         Sigmoid-223            [-1, 576, 1, 1]               0\n",
            "SqueezeExcitation-224            [-1, 576, 4, 4]               0\n",
            "          Conv2d-225            [-1, 136, 4, 4]          78,336\n",
            "     BatchNorm2d-226            [-1, 136, 4, 4]             272\n",
            "          MBConv-227            [-1, 136, 4, 4]               0\n",
            "          Conv2d-228            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-229            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-230            [-1, 816, 4, 4]               0\n",
            "          Conv2d-231            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-232            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-233            [-1, 816, 4, 4]               0\n",
            "         Dropout-234            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-235            [-1, 816, 1, 1]               0\n",
            "          Conv2d-236             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-237             [-1, 34, 1, 1]               0\n",
            "          Conv2d-238            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-239            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-240            [-1, 816, 4, 4]               0\n",
            "          Conv2d-241            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-242            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-243            [-1, 136, 4, 4]               0\n",
            "          MBConv-244            [-1, 136, 4, 4]               0\n",
            "          Conv2d-245            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-246            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-247            [-1, 816, 4, 4]               0\n",
            "          Conv2d-248            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-249            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-250            [-1, 816, 4, 4]               0\n",
            "         Dropout-251            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-252            [-1, 816, 1, 1]               0\n",
            "          Conv2d-253             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-254             [-1, 34, 1, 1]               0\n",
            "          Conv2d-255            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-256            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-257            [-1, 816, 4, 4]               0\n",
            "          Conv2d-258            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-259            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-260            [-1, 136, 4, 4]               0\n",
            "          MBConv-261            [-1, 136, 4, 4]               0\n",
            "          Conv2d-262            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-263            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-264            [-1, 816, 4, 4]               0\n",
            "          Conv2d-265            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-266            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-267            [-1, 816, 4, 4]               0\n",
            "         Dropout-268            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-269            [-1, 816, 1, 1]               0\n",
            "          Conv2d-270             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-271             [-1, 34, 1, 1]               0\n",
            "          Conv2d-272            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-273            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-274            [-1, 816, 4, 4]               0\n",
            "          Conv2d-275            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-276            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-277            [-1, 136, 4, 4]               0\n",
            "          MBConv-278            [-1, 136, 4, 4]               0\n",
            "          Conv2d-279            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-280            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-281            [-1, 816, 4, 4]               0\n",
            "          Conv2d-282            [-1, 816, 4, 4]          20,400\n",
            "     BatchNorm2d-283            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-284            [-1, 816, 4, 4]               0\n",
            "AdaptiveAvgPool2d-285            [-1, 816, 1, 1]               0\n",
            "          Conv2d-286             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-287             [-1, 34, 1, 1]               0\n",
            "          Conv2d-288            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-289            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-290            [-1, 816, 4, 4]               0\n",
            "          Conv2d-291            [-1, 136, 4, 4]         110,976\n",
            "     BatchNorm2d-292            [-1, 136, 4, 4]             272\n",
            " StochasticDepth-293            [-1, 136, 4, 4]               0\n",
            "          MBConv-294            [-1, 136, 4, 4]               0\n",
            "          Conv2d-295            [-1, 816, 4, 4]         110,976\n",
            "     BatchNorm2d-296            [-1, 816, 4, 4]           1,632\n",
            "            SiLU-297            [-1, 816, 4, 4]               0\n",
            "          Conv2d-298            [-1, 816, 2, 2]          20,400\n",
            "     BatchNorm2d-299            [-1, 816, 2, 2]           1,632\n",
            "            SiLU-300            [-1, 816, 2, 2]               0\n",
            "         Dropout-301            [-1, 816, 2, 2]               0\n",
            "AdaptiveAvgPool2d-302            [-1, 816, 1, 1]               0\n",
            "          Conv2d-303             [-1, 34, 1, 1]          27,778\n",
            "            SiLU-304             [-1, 34, 1, 1]               0\n",
            "          Conv2d-305            [-1, 816, 1, 1]          28,560\n",
            "         Sigmoid-306            [-1, 816, 1, 1]               0\n",
            "SqueezeExcitation-307            [-1, 816, 2, 2]               0\n",
            "          Conv2d-308            [-1, 232, 2, 2]         189,312\n",
            "     BatchNorm2d-309            [-1, 232, 2, 2]             464\n",
            "          MBConv-310            [-1, 232, 2, 2]               0\n",
            "          Conv2d-311           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-312           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-313           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-314           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-315           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-316           [-1, 1392, 2, 2]               0\n",
            "         Dropout-317           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-318           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-319             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-320             [-1, 58, 1, 1]               0\n",
            "          Conv2d-321           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-322           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-323           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-324            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-325            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-326            [-1, 232, 2, 2]               0\n",
            "          MBConv-327            [-1, 232, 2, 2]               0\n",
            "          Conv2d-328           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-329           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-330           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-331           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-332           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-333           [-1, 1392, 2, 2]               0\n",
            "         Dropout-334           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-335           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-336             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-337             [-1, 58, 1, 1]               0\n",
            "          Conv2d-338           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-339           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-340           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-341            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-342            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-343            [-1, 232, 2, 2]               0\n",
            "          MBConv-344            [-1, 232, 2, 2]               0\n",
            "          Conv2d-345           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-346           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-347           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-348           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-349           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-350           [-1, 1392, 2, 2]               0\n",
            "         Dropout-351           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-352           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-353             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-354             [-1, 58, 1, 1]               0\n",
            "          Conv2d-355           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-356           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-357           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-358            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-359            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-360            [-1, 232, 2, 2]               0\n",
            "          MBConv-361            [-1, 232, 2, 2]               0\n",
            "          Conv2d-362           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-363           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-364           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-365           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-366           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-367           [-1, 1392, 2, 2]               0\n",
            "         Dropout-368           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-369           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-370             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-371             [-1, 58, 1, 1]               0\n",
            "          Conv2d-372           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-373           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-374           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-375            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-376            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-377            [-1, 232, 2, 2]               0\n",
            "          MBConv-378            [-1, 232, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-380           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-381           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-382           [-1, 1392, 2, 2]          34,800\n",
            "     BatchNorm2d-383           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-384           [-1, 1392, 2, 2]               0\n",
            "         Dropout-385           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-386           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-387             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-388             [-1, 58, 1, 1]               0\n",
            "          Conv2d-389           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-390           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-391           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-392            [-1, 232, 2, 2]         322,944\n",
            "     BatchNorm2d-393            [-1, 232, 2, 2]             464\n",
            " StochasticDepth-394            [-1, 232, 2, 2]               0\n",
            "          MBConv-395            [-1, 232, 2, 2]               0\n",
            "          Conv2d-396           [-1, 1392, 2, 2]         322,944\n",
            "     BatchNorm2d-397           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-398           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-399           [-1, 1392, 2, 2]          12,528\n",
            "     BatchNorm2d-400           [-1, 1392, 2, 2]           2,784\n",
            "            SiLU-401           [-1, 1392, 2, 2]               0\n",
            "         Dropout-402           [-1, 1392, 2, 2]               0\n",
            "AdaptiveAvgPool2d-403           [-1, 1392, 1, 1]               0\n",
            "          Conv2d-404             [-1, 58, 1, 1]          80,794\n",
            "            SiLU-405             [-1, 58, 1, 1]               0\n",
            "          Conv2d-406           [-1, 1392, 1, 1]          82,128\n",
            "         Sigmoid-407           [-1, 1392, 1, 1]               0\n",
            "SqueezeExcitation-408           [-1, 1392, 2, 2]               0\n",
            "          Conv2d-409            [-1, 384, 2, 2]         534,528\n",
            "     BatchNorm2d-410            [-1, 384, 2, 2]             768\n",
            "          MBConv-411            [-1, 384, 2, 2]               0\n",
            "          Conv2d-412           [-1, 2304, 2, 2]         884,736\n",
            "     BatchNorm2d-413           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-414           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-415           [-1, 2304, 2, 2]          20,736\n",
            "     BatchNorm2d-416           [-1, 2304, 2, 2]           4,608\n",
            "            SiLU-417           [-1, 2304, 2, 2]               0\n",
            "         Dropout-418           [-1, 2304, 2, 2]               0\n",
            "AdaptiveAvgPool2d-419           [-1, 2304, 1, 1]               0\n",
            "          Conv2d-420             [-1, 96, 1, 1]         221,280\n",
            "            SiLU-421             [-1, 96, 1, 1]               0\n",
            "          Conv2d-422           [-1, 2304, 1, 1]         223,488\n",
            "         Sigmoid-423           [-1, 2304, 1, 1]               0\n",
            "SqueezeExcitation-424           [-1, 2304, 2, 2]               0\n",
            "          Conv2d-425            [-1, 384, 2, 2]         884,736\n",
            "     BatchNorm2d-426            [-1, 384, 2, 2]             768\n",
            " StochasticDepth-427            [-1, 384, 2, 2]               0\n",
            "          MBConv-428            [-1, 384, 2, 2]               0\n",
            "          Conv2d-429           [-1, 1536, 2, 2]         589,824\n",
            "     BatchNorm2d-430           [-1, 1536, 2, 2]           3,072\n",
            "            SiLU-431           [-1, 1536, 2, 2]               0\n",
            "AdaptiveAvgPool2d-432           [-1, 1536, 1, 1]               0\n",
            "        Identity-433                 [-1, 1536]               0\n",
            "    EfficientNet-434                 [-1, 1536]               0\n",
            "          Linear-435                    [-1, 3]           4,611\n",
            "          Linear-436                   [-1, 89]         136,793\n",
            "================================================================\n",
            "Total params: 10,837,636\n",
            "Trainable params: 10,837,636\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 30.59\n",
            "Params size (MB): 41.34\n",
            "Estimated Total Size (MB): 71.98\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with everything unfrozen)\n",
        "for param in effnetb3_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "summary(effnetb3_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb3_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZY9jxA0SQgxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c11c9602-e4e6-4e9a-ea55-75046d7c4be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 train: 100%|██████████| 495/495 [00:56<00:00,  8.68batch/s, loss=9.91, sub_class_accuracy=0.0833, super_class_accuracy=0.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 train Super Class loss: 3.415859900471416 Super Class acc: 0.7086912393569946\n",
            "Sub Class loss: 6.944864099588341 Sub Class acc: 0.13390600681304932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 val: 100%|██████████| 23/23 [00:00<00:00, 25.80batch/s, loss=9.41, sub_class_accuracy=0.1, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 val Super Class loss: 2.2048799657042086 Super Class acc: 0.8147138953208923\n",
            "Sub Class loss: 6.513996304868027 Sub Class acc: 0.1716621220111847\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 train: 100%|██████████| 495/495 [00:54<00:00,  9.01batch/s, loss=8.14, sub_class_accuracy=0.208, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 train Super Class loss: 2.777986955754139 Super Class acc: 0.773307204246521\n",
            "Sub Class loss: 6.202882981408781 Sub Class acc: 0.18746842443943024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 val: 100%|██████████| 23/23 [00:00<00:00, 26.17batch/s, loss=9.38, sub_class_accuracy=0.1, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 val Super Class loss: 2.045393949552193 Super Class acc: 0.8460490107536316\n",
            "Sub Class loss: 6.093724288472687 Sub Class acc: 0.2220708429813385\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 train: 100%|██████████| 495/495 [00:55<00:00,  8.91batch/s, loss=7.94, sub_class_accuracy=0.25, super_class_accuracy=0.792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 train Super Class loss: 2.4705722635897076 Super Class acc: 0.8043203353881836\n",
            "Sub Class loss: 5.683252622046333 Sub Class acc: 0.23945173621177673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 val: 100%|██████████| 23/23 [00:00<00:00, 26.18batch/s, loss=8.11, sub_class_accuracy=0.133, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 val Super Class loss: 1.8064862976931746 Super Class acc: 0.8664849996566772\n",
            "Sub Class loss: 5.729607307943401 Sub Class acc: 0.25749319791793823\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 train: 100%|██████████| 495/495 [00:55<00:00,  8.99batch/s, loss=7.26, sub_class_accuracy=0.25, super_class_accuracy=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 train Super Class loss: 2.1855360948720204 Super Class acc: 0.8249747157096863\n",
            "Sub Class loss: 5.257515803197829 Sub Class acc: 0.2754547894001007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 val: 100%|██████████| 23/23 [00:00<00:00, 25.95batch/s, loss=8.52, sub_class_accuracy=0.2, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 val Super Class loss: 1.8003157840924953 Super Class acc: 0.8555858135223389\n",
            "Sub Class loss: 5.703363675837296 Sub Class acc: 0.2602179944515228\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 train: 100%|██████████| 495/495 [00:55<00:00,  8.96batch/s, loss=5.64, sub_class_accuracy=0.25, super_class_accuracy=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 train Super Class loss: 1.9286348852561905 Super Class acc: 0.8473345041275024\n",
            "Sub Class loss: 4.764675818891945 Sub Class acc: 0.3247852325439453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 val: 100%|██████████| 23/23 [00:00<00:00, 25.87batch/s, loss=9.36, sub_class_accuracy=0.2, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 val Super Class loss: 1.7942789972478104 Super Class acc: 0.8623977899551392\n",
            "Sub Class loss: 5.583476080881478 Sub Class acc: 0.24931879341602325\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 train: 100%|██████████| 495/495 [00:55<00:00,  8.93batch/s, loss=4.44, sub_class_accuracy=0.542, super_class_accuracy=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 train Super Class loss: 1.7029234145764693 Super Class acc: 0.868431031703949\n",
            "Sub Class loss: 4.351596290020704 Sub Class acc: 0.37196817994117737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 val: 100%|██████████| 23/23 [00:00<00:00, 25.66batch/s, loss=9.4, sub_class_accuracy=0.133, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 val Super Class loss: 1.9802109353061592 Super Class acc: 0.8623977899551392\n",
            "Sub Class loss: 5.762568746665518 Sub Class acc: 0.2779291570186615\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 train: 100%|██████████| 495/495 [00:55<00:00,  8.96batch/s, loss=4.15, sub_class_accuracy=0.5, super_class_accuracy=0.958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 train Super Class loss: 1.541720529685965 Super Class acc: 0.8813794851303101\n",
            "Sub Class loss: 4.013148753073192 Sub Class acc: 0.40828701853752136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 val: 100%|██████████| 23/23 [00:00<00:00, 25.57batch/s, loss=9.43, sub_class_accuracy=0.3, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 val Super Class loss: 1.941384438435453 Super Class acc: 0.8583106398582458\n",
            "Sub Class loss: 5.740701896293286 Sub Class acc: 0.25613078474998474\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 train: 100%|██████████| 495/495 [00:55<00:00,  8.96batch/s, loss=4.85, sub_class_accuracy=0.417, super_class_accuracy=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 train Super Class loss: 1.3068217141887888 Super Class acc: 0.9003916382789612\n",
            "Sub Class loss: 3.5832400531585678 Sub Class acc: 0.4592597186565399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 val: 100%|██████████| 23/23 [00:00<00:00, 25.62batch/s, loss=10.6, sub_class_accuracy=0.2, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 val Super Class loss: 2.0994752288189504 Super Class acc: 0.8555858135223389\n",
            "Sub Class loss: 6.020109654772185 Sub Class acc: 0.2643051743507385\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 train: 100%|██████████| 495/495 [00:55<00:00,  8.88batch/s, loss=4.11, sub_class_accuracy=0.5, super_class_accuracy=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 train Super Class loss: 1.1893292909893742 Super Class acc: 0.9103082418441772\n",
            "Sub Class loss: 3.2305944357453242 Sub Class acc: 0.5141485333442688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 val: 100%|██████████| 23/23 [00:00<00:00, 25.39batch/s, loss=10.8, sub_class_accuracy=0.167, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 val Super Class loss: 1.8553970011118648 Super Class acc: 0.8705722093582153\n",
            "Sub Class loss: 5.94217471920502 Sub Class acc: 0.2888283431529999\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 train: 100%|██████████| 495/495 [00:55<00:00,  8.96batch/s, loss=2.28, sub_class_accuracy=0.875, super_class_accuracy=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 train Super Class loss: 0.9921339990598437 Super Class acc: 0.9250252842903137\n",
            "Sub Class loss: 2.882160108760489 Sub Class acc: 0.5543203353881836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 val: 100%|██████████| 23/23 [00:00<00:00, 26.13batch/s, loss=12, sub_class_accuracy=0.267, super_class_accuracy=0.967]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 val Super Class loss: 2.0195262852741522 Super Class acc: 0.885558545589447\n",
            "Sub Class loss: 6.378315746296979 Sub Class acc: 0.26294276118278503\n",
            "--------------------\n",
            "Best Super Class val acc: 0.885558545589447\n",
            "Best Sub Class val acc: 0.2888283431529999\n",
            "Average Time taken for an epoch: 56.54344816207886 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "initial_epoch = 12\n",
        "learning_rate = 4e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb3_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='EnsembleJoint_EffnetB3_unfrozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BFroJYrQgxn"
      },
      "source": [
        "##### Create the EfficientNetB4 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZDJY9fWQQgxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26507db-9729-4f1e-aaa6-98964eb489f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EfficientNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2dNormActivation(\n",
            "      (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (2): Conv2dNormActivation(\n",
            "            (0): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
            "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (2): Conv2dNormActivation(\n",
            "            (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.00625, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.018750000000000003, mode=row)\n",
            "      )\n",
            "      (2): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
            "      )\n",
            "      (3): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.03125, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.043750000000000004, mode=row)\n",
            "      )\n",
            "      (2): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
            "      )\n",
            "      (3): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.05625, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(336, 336, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=336, bias=False)\n",
            "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.06875, mode=row)\n",
            "      )\n",
            "      (2): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
            "      )\n",
            "      (3): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.08125, mode=row)\n",
            "      )\n",
            "      (4): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
            "      )\n",
            "      (5): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.09375, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.10625000000000001, mode=row)\n",
            "      )\n",
            "      (2): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
            "      )\n",
            "      (3): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.11875000000000001, mode=row)\n",
            "      )\n",
            "      (4): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
            "      )\n",
            "      (5): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.13125, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.14375000000000002, mode=row)\n",
            "      )\n",
            "      (2): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
            "      )\n",
            "      (3): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.15, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.15625, mode=row)\n",
            "      )\n",
            "      (4): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
            "      )\n",
            "      (5): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.16875, mode=row)\n",
            "      )\n",
            "      (6): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
            "      )\n",
            "      (7): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.18125000000000002, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n",
            "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n",
            "            (1): BatchNorm2d(2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "            (3): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.19375, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (8): Conv2dNormActivation(\n",
            "      (0): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (classifier): Identity()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "# Load the EfficientNetB4 model trained on ImageNet\n",
        "backbone_model = torchvision.models.efficientnet_b4(weights='IMAGENET1K_V1')\n",
        "backbone_model.classifier = nn.Identity()\n",
        "\n",
        "# Add Dropout layers after the activation function as per this paper http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf\n",
        "#backbone_model.features[0].add_module('3', nn.Dropout(p = 0.2))\n",
        "\n",
        "#backbone_model.features[1][0].block[0].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[1][1].block[0].add_module('3', nn.Dropout(p = 0.1))\n",
        "\n",
        "#backbone_model.features[2][0].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[2][1].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[2][2].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[2][3].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "\n",
        "backbone_model.features[3][0].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[3][1].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[3][2].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "backbone_model.features[3][3].block[1].add_module('3', nn.Dropout(p = 0.1))\n",
        "\n",
        "backbone_model.features[4][0].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[4][1].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[4][2].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[4][3].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[4][4].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "\n",
        "backbone_model.features[5][0].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[5][1].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[5][2].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[5][3].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[5][4].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "\n",
        "backbone_model.features[6][0].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[6][1].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[6][2].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[6][3].block[1].add_module('3', nn.Dropout(p = 0.15))\n",
        "backbone_model.features[6][4].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][5].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][6].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[6][7].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "\n",
        "backbone_model.features[7][0].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "backbone_model.features[7][1].block[1].add_module('3', nn.Dropout(p = 0.2))\n",
        "\n",
        "print(backbone_model)\n",
        "\n",
        "class EffnetB4JointModel(nn.Module):\n",
        "    def __init__(self, backbone) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        # 3 super classes\n",
        "        self.superclass = nn.Linear(in_features = 1792, out_features = 3)\n",
        "        # 89 sub classes\n",
        "        self.subclass = nn.Linear(in_features = 1792, out_features = 89)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.backbone(x)\n",
        "        super_class_out = self.superclass(out)\n",
        "        sub_class_out = self.subclass(out)\n",
        "        return super_class_out, sub_class_out\n",
        "\n",
        "# Create the baseline model\n",
        "effnetb4_joint_model = EffnetB4JointModel(backbone_model)\n",
        "effnetb4_joint_model = effnetb4_joint_model.to(device, non_blocking = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phXNyveLQgxn"
      },
      "source": [
        "##### Train the EfficientNetB4 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpNUz5lfQgxn"
      },
      "source": [
        "###### Freeze all the layers except Classifier layers (phase 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "CIEWJvOPQgxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc41283-06fd-4753-d29d-3f725be320a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 32, 32]           1,296\n",
            "       BatchNorm2d-2           [-1, 48, 32, 32]              96\n",
            "              SiLU-3           [-1, 48, 32, 32]               0\n",
            "            Conv2d-4           [-1, 48, 32, 32]             432\n",
            "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
            "              SiLU-6           [-1, 48, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 48, 1, 1]               0\n",
            "            Conv2d-8             [-1, 12, 1, 1]             588\n",
            "              SiLU-9             [-1, 12, 1, 1]               0\n",
            "           Conv2d-10             [-1, 48, 1, 1]             624\n",
            "          Sigmoid-11             [-1, 48, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 48, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]           1,152\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "          Dropout-19           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-20             [-1, 24, 1, 1]               0\n",
            "           Conv2d-21              [-1, 6, 1, 1]             150\n",
            "             SiLU-22              [-1, 6, 1, 1]               0\n",
            "           Conv2d-23             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-24             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-25           [-1, 24, 32, 32]               0\n",
            "           Conv2d-26           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-27           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-28           [-1, 24, 32, 32]               0\n",
            "           MBConv-29           [-1, 24, 32, 32]               0\n",
            "           Conv2d-30          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-31          [-1, 144, 32, 32]             288\n",
            "             SiLU-32          [-1, 144, 32, 32]               0\n",
            "           Conv2d-33          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-34          [-1, 144, 16, 16]             288\n",
            "             SiLU-35          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-36            [-1, 144, 1, 1]               0\n",
            "           Conv2d-37              [-1, 6, 1, 1]             870\n",
            "             SiLU-38              [-1, 6, 1, 1]               0\n",
            "           Conv2d-39            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-40            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-41          [-1, 144, 16, 16]               0\n",
            "           Conv2d-42           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "           MBConv-44           [-1, 32, 16, 16]               0\n",
            "           Conv2d-45          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-46          [-1, 192, 16, 16]             384\n",
            "             SiLU-47          [-1, 192, 16, 16]               0\n",
            "           Conv2d-48          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-49          [-1, 192, 16, 16]             384\n",
            "             SiLU-50          [-1, 192, 16, 16]               0\n",
            "          Dropout-51          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-52            [-1, 192, 1, 1]               0\n",
            "           Conv2d-53              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-54              [-1, 8, 1, 1]               0\n",
            "           Conv2d-55            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-56            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-57          [-1, 192, 16, 16]               0\n",
            "           Conv2d-58           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-60           [-1, 32, 16, 16]               0\n",
            "           MBConv-61           [-1, 32, 16, 16]               0\n",
            "           Conv2d-62          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-63          [-1, 192, 16, 16]             384\n",
            "             SiLU-64          [-1, 192, 16, 16]               0\n",
            "           Conv2d-65          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-66          [-1, 192, 16, 16]             384\n",
            "             SiLU-67          [-1, 192, 16, 16]               0\n",
            "          Dropout-68          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-69            [-1, 192, 1, 1]               0\n",
            "           Conv2d-70              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-71              [-1, 8, 1, 1]               0\n",
            "           Conv2d-72            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-73            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-74          [-1, 192, 16, 16]               0\n",
            "           Conv2d-75           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-76           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-77           [-1, 32, 16, 16]               0\n",
            "           MBConv-78           [-1, 32, 16, 16]               0\n",
            "           Conv2d-79          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-80          [-1, 192, 16, 16]             384\n",
            "             SiLU-81          [-1, 192, 16, 16]               0\n",
            "           Conv2d-82          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-83          [-1, 192, 16, 16]             384\n",
            "             SiLU-84          [-1, 192, 16, 16]               0\n",
            "          Dropout-85          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-86            [-1, 192, 1, 1]               0\n",
            "           Conv2d-87              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-88              [-1, 8, 1, 1]               0\n",
            "           Conv2d-89            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-90            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-91          [-1, 192, 16, 16]               0\n",
            "           Conv2d-92           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-93           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-94           [-1, 32, 16, 16]               0\n",
            "           MBConv-95           [-1, 32, 16, 16]               0\n",
            "           Conv2d-96          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-97          [-1, 192, 16, 16]             384\n",
            "             SiLU-98          [-1, 192, 16, 16]               0\n",
            "           Conv2d-99            [-1, 192, 8, 8]           4,800\n",
            "     BatchNorm2d-100            [-1, 192, 8, 8]             384\n",
            "            SiLU-101            [-1, 192, 8, 8]               0\n",
            "         Dropout-102            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-103            [-1, 192, 1, 1]               0\n",
            "          Conv2d-104              [-1, 8, 1, 1]           1,544\n",
            "            SiLU-105              [-1, 8, 1, 1]               0\n",
            "          Conv2d-106            [-1, 192, 1, 1]           1,728\n",
            "         Sigmoid-107            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-108            [-1, 192, 8, 8]               0\n",
            "          Conv2d-109             [-1, 56, 8, 8]          10,752\n",
            "     BatchNorm2d-110             [-1, 56, 8, 8]             112\n",
            "          MBConv-111             [-1, 56, 8, 8]               0\n",
            "          Conv2d-112            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-113            [-1, 336, 8, 8]             672\n",
            "            SiLU-114            [-1, 336, 8, 8]               0\n",
            "          Conv2d-115            [-1, 336, 8, 8]           8,400\n",
            "     BatchNorm2d-116            [-1, 336, 8, 8]             672\n",
            "            SiLU-117            [-1, 336, 8, 8]               0\n",
            "         Dropout-118            [-1, 336, 8, 8]               0\n",
            "AdaptiveAvgPool2d-119            [-1, 336, 1, 1]               0\n",
            "          Conv2d-120             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-121             [-1, 14, 1, 1]               0\n",
            "          Conv2d-122            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-123            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-124            [-1, 336, 8, 8]               0\n",
            "          Conv2d-125             [-1, 56, 8, 8]          18,816\n",
            "     BatchNorm2d-126             [-1, 56, 8, 8]             112\n",
            " StochasticDepth-127             [-1, 56, 8, 8]               0\n",
            "          MBConv-128             [-1, 56, 8, 8]               0\n",
            "          Conv2d-129            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-130            [-1, 336, 8, 8]             672\n",
            "            SiLU-131            [-1, 336, 8, 8]               0\n",
            "          Conv2d-132            [-1, 336, 8, 8]           8,400\n",
            "     BatchNorm2d-133            [-1, 336, 8, 8]             672\n",
            "            SiLU-134            [-1, 336, 8, 8]               0\n",
            "         Dropout-135            [-1, 336, 8, 8]               0\n",
            "AdaptiveAvgPool2d-136            [-1, 336, 1, 1]               0\n",
            "          Conv2d-137             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-138             [-1, 14, 1, 1]               0\n",
            "          Conv2d-139            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-140            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-141            [-1, 336, 8, 8]               0\n",
            "          Conv2d-142             [-1, 56, 8, 8]          18,816\n",
            "     BatchNorm2d-143             [-1, 56, 8, 8]             112\n",
            " StochasticDepth-144             [-1, 56, 8, 8]               0\n",
            "          MBConv-145             [-1, 56, 8, 8]               0\n",
            "          Conv2d-146            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-147            [-1, 336, 8, 8]             672\n",
            "            SiLU-148            [-1, 336, 8, 8]               0\n",
            "          Conv2d-149            [-1, 336, 8, 8]           8,400\n",
            "     BatchNorm2d-150            [-1, 336, 8, 8]             672\n",
            "            SiLU-151            [-1, 336, 8, 8]               0\n",
            "         Dropout-152            [-1, 336, 8, 8]               0\n",
            "AdaptiveAvgPool2d-153            [-1, 336, 1, 1]               0\n",
            "          Conv2d-154             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-155             [-1, 14, 1, 1]               0\n",
            "          Conv2d-156            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-157            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-158            [-1, 336, 8, 8]               0\n",
            "          Conv2d-159             [-1, 56, 8, 8]          18,816\n",
            "     BatchNorm2d-160             [-1, 56, 8, 8]             112\n",
            " StochasticDepth-161             [-1, 56, 8, 8]               0\n",
            "          MBConv-162             [-1, 56, 8, 8]               0\n",
            "          Conv2d-163            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-164            [-1, 336, 8, 8]             672\n",
            "            SiLU-165            [-1, 336, 8, 8]               0\n",
            "          Conv2d-166            [-1, 336, 4, 4]           3,024\n",
            "     BatchNorm2d-167            [-1, 336, 4, 4]             672\n",
            "            SiLU-168            [-1, 336, 4, 4]               0\n",
            "         Dropout-169            [-1, 336, 4, 4]               0\n",
            "AdaptiveAvgPool2d-170            [-1, 336, 1, 1]               0\n",
            "          Conv2d-171             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-172             [-1, 14, 1, 1]               0\n",
            "          Conv2d-173            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-174            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-175            [-1, 336, 4, 4]               0\n",
            "          Conv2d-176            [-1, 112, 4, 4]          37,632\n",
            "     BatchNorm2d-177            [-1, 112, 4, 4]             224\n",
            "          MBConv-178            [-1, 112, 4, 4]               0\n",
            "          Conv2d-179            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-180            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-181            [-1, 672, 4, 4]               0\n",
            "          Conv2d-182            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-183            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-184            [-1, 672, 4, 4]               0\n",
            "         Dropout-185            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-186            [-1, 672, 1, 1]               0\n",
            "          Conv2d-187             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-188             [-1, 28, 1, 1]               0\n",
            "          Conv2d-189            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-190            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-191            [-1, 672, 4, 4]               0\n",
            "          Conv2d-192            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-193            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-194            [-1, 112, 4, 4]               0\n",
            "          MBConv-195            [-1, 112, 4, 4]               0\n",
            "          Conv2d-196            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-197            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-198            [-1, 672, 4, 4]               0\n",
            "          Conv2d-199            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-200            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-201            [-1, 672, 4, 4]               0\n",
            "         Dropout-202            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-203            [-1, 672, 1, 1]               0\n",
            "          Conv2d-204             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-205             [-1, 28, 1, 1]               0\n",
            "          Conv2d-206            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-207            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-208            [-1, 672, 4, 4]               0\n",
            "          Conv2d-209            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-210            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-211            [-1, 112, 4, 4]               0\n",
            "          MBConv-212            [-1, 112, 4, 4]               0\n",
            "          Conv2d-213            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-214            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-215            [-1, 672, 4, 4]               0\n",
            "          Conv2d-216            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-217            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-218            [-1, 672, 4, 4]               0\n",
            "         Dropout-219            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-220            [-1, 672, 1, 1]               0\n",
            "          Conv2d-221             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-222             [-1, 28, 1, 1]               0\n",
            "          Conv2d-223            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-224            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-225            [-1, 672, 4, 4]               0\n",
            "          Conv2d-226            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-227            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-228            [-1, 112, 4, 4]               0\n",
            "          MBConv-229            [-1, 112, 4, 4]               0\n",
            "          Conv2d-230            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-231            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-232            [-1, 672, 4, 4]               0\n",
            "          Conv2d-233            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-234            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-235            [-1, 672, 4, 4]               0\n",
            "         Dropout-236            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-237            [-1, 672, 1, 1]               0\n",
            "          Conv2d-238             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-239             [-1, 28, 1, 1]               0\n",
            "          Conv2d-240            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-241            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-242            [-1, 672, 4, 4]               0\n",
            "          Conv2d-243            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-244            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-245            [-1, 112, 4, 4]               0\n",
            "          MBConv-246            [-1, 112, 4, 4]               0\n",
            "          Conv2d-247            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-248            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-249            [-1, 672, 4, 4]               0\n",
            "          Conv2d-250            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-251            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-252            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-253            [-1, 672, 1, 1]               0\n",
            "          Conv2d-254             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-255             [-1, 28, 1, 1]               0\n",
            "          Conv2d-256            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-257            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-258            [-1, 672, 4, 4]               0\n",
            "          Conv2d-259            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-260            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-261            [-1, 112, 4, 4]               0\n",
            "          MBConv-262            [-1, 112, 4, 4]               0\n",
            "          Conv2d-263            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-264            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-265            [-1, 672, 4, 4]               0\n",
            "          Conv2d-266            [-1, 672, 4, 4]          16,800\n",
            "     BatchNorm2d-267            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-268            [-1, 672, 4, 4]               0\n",
            "         Dropout-269            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-270            [-1, 672, 1, 1]               0\n",
            "          Conv2d-271             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-272             [-1, 28, 1, 1]               0\n",
            "          Conv2d-273            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-274            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-275            [-1, 672, 4, 4]               0\n",
            "          Conv2d-276            [-1, 160, 4, 4]         107,520\n",
            "     BatchNorm2d-277            [-1, 160, 4, 4]             320\n",
            "          MBConv-278            [-1, 160, 4, 4]               0\n",
            "          Conv2d-279            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-280            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-281            [-1, 960, 4, 4]               0\n",
            "          Conv2d-282            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-283            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-284            [-1, 960, 4, 4]               0\n",
            "         Dropout-285            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-286            [-1, 960, 1, 1]               0\n",
            "          Conv2d-287             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-288             [-1, 40, 1, 1]               0\n",
            "          Conv2d-289            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-290            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-291            [-1, 960, 4, 4]               0\n",
            "          Conv2d-292            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-293            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-294            [-1, 160, 4, 4]               0\n",
            "          MBConv-295            [-1, 160, 4, 4]               0\n",
            "          Conv2d-296            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-297            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-298            [-1, 960, 4, 4]               0\n",
            "          Conv2d-299            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-300            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-301            [-1, 960, 4, 4]               0\n",
            "         Dropout-302            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-303            [-1, 960, 1, 1]               0\n",
            "          Conv2d-304             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-305             [-1, 40, 1, 1]               0\n",
            "          Conv2d-306            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-307            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-308            [-1, 960, 4, 4]               0\n",
            "          Conv2d-309            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-310            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-311            [-1, 160, 4, 4]               0\n",
            "          MBConv-312            [-1, 160, 4, 4]               0\n",
            "          Conv2d-313            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-314            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-315            [-1, 960, 4, 4]               0\n",
            "          Conv2d-316            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-317            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-318            [-1, 960, 4, 4]               0\n",
            "         Dropout-319            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-320            [-1, 960, 1, 1]               0\n",
            "          Conv2d-321             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-322             [-1, 40, 1, 1]               0\n",
            "          Conv2d-323            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-324            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-325            [-1, 960, 4, 4]               0\n",
            "          Conv2d-326            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-327            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-328            [-1, 160, 4, 4]               0\n",
            "          MBConv-329            [-1, 160, 4, 4]               0\n",
            "          Conv2d-330            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-331            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-332            [-1, 960, 4, 4]               0\n",
            "          Conv2d-333            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-334            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-335            [-1, 960, 4, 4]               0\n",
            "         Dropout-336            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-337            [-1, 960, 1, 1]               0\n",
            "          Conv2d-338             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-339             [-1, 40, 1, 1]               0\n",
            "          Conv2d-340            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-341            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-342            [-1, 960, 4, 4]               0\n",
            "          Conv2d-343            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-344            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-345            [-1, 160, 4, 4]               0\n",
            "          MBConv-346            [-1, 160, 4, 4]               0\n",
            "          Conv2d-347            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-348            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-349            [-1, 960, 4, 4]               0\n",
            "          Conv2d-350            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-351            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-352            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-353            [-1, 960, 1, 1]               0\n",
            "          Conv2d-354             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-355             [-1, 40, 1, 1]               0\n",
            "          Conv2d-356            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-357            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-358            [-1, 960, 4, 4]               0\n",
            "          Conv2d-359            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-360            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-361            [-1, 160, 4, 4]               0\n",
            "          MBConv-362            [-1, 160, 4, 4]               0\n",
            "          Conv2d-363            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-364            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-365            [-1, 960, 4, 4]               0\n",
            "          Conv2d-366            [-1, 960, 2, 2]          24,000\n",
            "     BatchNorm2d-367            [-1, 960, 2, 2]           1,920\n",
            "            SiLU-368            [-1, 960, 2, 2]               0\n",
            "         Dropout-369            [-1, 960, 2, 2]               0\n",
            "AdaptiveAvgPool2d-370            [-1, 960, 1, 1]               0\n",
            "          Conv2d-371             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-372             [-1, 40, 1, 1]               0\n",
            "          Conv2d-373            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-374            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-375            [-1, 960, 2, 2]               0\n",
            "          Conv2d-376            [-1, 272, 2, 2]         261,120\n",
            "     BatchNorm2d-377            [-1, 272, 2, 2]             544\n",
            "          MBConv-378            [-1, 272, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-380           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-381           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-382           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-383           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-384           [-1, 1632, 2, 2]               0\n",
            "         Dropout-385           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-386           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-387             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-388             [-1, 68, 1, 1]               0\n",
            "          Conv2d-389           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-390           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-391           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-392            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-393            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-394            [-1, 272, 2, 2]               0\n",
            "          MBConv-395            [-1, 272, 2, 2]               0\n",
            "          Conv2d-396           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-397           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-398           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-399           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-400           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-401           [-1, 1632, 2, 2]               0\n",
            "         Dropout-402           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-403           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-404             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-405             [-1, 68, 1, 1]               0\n",
            "          Conv2d-406           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-407           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-408           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-409            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-410            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-411            [-1, 272, 2, 2]               0\n",
            "          MBConv-412            [-1, 272, 2, 2]               0\n",
            "          Conv2d-413           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-414           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-415           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-416           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-417           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-418           [-1, 1632, 2, 2]               0\n",
            "         Dropout-419           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-420           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-421             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-422             [-1, 68, 1, 1]               0\n",
            "          Conv2d-423           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-424           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-425           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-426            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-427            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-428            [-1, 272, 2, 2]               0\n",
            "          MBConv-429            [-1, 272, 2, 2]               0\n",
            "          Conv2d-430           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-431           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-432           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-433           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-434           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-435           [-1, 1632, 2, 2]               0\n",
            "         Dropout-436           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-437           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-438             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-439             [-1, 68, 1, 1]               0\n",
            "          Conv2d-440           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-441           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-442           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-443            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-444            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-445            [-1, 272, 2, 2]               0\n",
            "          MBConv-446            [-1, 272, 2, 2]               0\n",
            "          Conv2d-447           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-448           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-449           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-450           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-451           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-452           [-1, 1632, 2, 2]               0\n",
            "         Dropout-453           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-454           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-455             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-456             [-1, 68, 1, 1]               0\n",
            "          Conv2d-457           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-458           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-459           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-460            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-461            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-462            [-1, 272, 2, 2]               0\n",
            "          MBConv-463            [-1, 272, 2, 2]               0\n",
            "          Conv2d-464           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-465           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-466           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-467           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-468           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-469           [-1, 1632, 2, 2]               0\n",
            "         Dropout-470           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-471           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-472             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-473             [-1, 68, 1, 1]               0\n",
            "          Conv2d-474           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-475           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-476           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-477            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-478            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-479            [-1, 272, 2, 2]               0\n",
            "          MBConv-480            [-1, 272, 2, 2]               0\n",
            "          Conv2d-481           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-482           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-483           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-484           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-485           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-486           [-1, 1632, 2, 2]               0\n",
            "         Dropout-487           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-488           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-489             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-490             [-1, 68, 1, 1]               0\n",
            "          Conv2d-491           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-492           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-493           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-494            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-495            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-496            [-1, 272, 2, 2]               0\n",
            "          MBConv-497            [-1, 272, 2, 2]               0\n",
            "          Conv2d-498           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-499           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-500           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-501           [-1, 1632, 2, 2]          14,688\n",
            "     BatchNorm2d-502           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-503           [-1, 1632, 2, 2]               0\n",
            "         Dropout-504           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-505           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-506             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-507             [-1, 68, 1, 1]               0\n",
            "          Conv2d-508           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-509           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-510           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-511            [-1, 448, 2, 2]         731,136\n",
            "     BatchNorm2d-512            [-1, 448, 2, 2]             896\n",
            "          MBConv-513            [-1, 448, 2, 2]               0\n",
            "          Conv2d-514           [-1, 2688, 2, 2]       1,204,224\n",
            "     BatchNorm2d-515           [-1, 2688, 2, 2]           5,376\n",
            "            SiLU-516           [-1, 2688, 2, 2]               0\n",
            "          Conv2d-517           [-1, 2688, 2, 2]          24,192\n",
            "     BatchNorm2d-518           [-1, 2688, 2, 2]           5,376\n",
            "            SiLU-519           [-1, 2688, 2, 2]               0\n",
            "         Dropout-520           [-1, 2688, 2, 2]               0\n",
            "AdaptiveAvgPool2d-521           [-1, 2688, 1, 1]               0\n",
            "          Conv2d-522            [-1, 112, 1, 1]         301,168\n",
            "            SiLU-523            [-1, 112, 1, 1]               0\n",
            "          Conv2d-524           [-1, 2688, 1, 1]         303,744\n",
            "         Sigmoid-525           [-1, 2688, 1, 1]               0\n",
            "SqueezeExcitation-526           [-1, 2688, 2, 2]               0\n",
            "          Conv2d-527            [-1, 448, 2, 2]       1,204,224\n",
            "     BatchNorm2d-528            [-1, 448, 2, 2]             896\n",
            " StochasticDepth-529            [-1, 448, 2, 2]               0\n",
            "          MBConv-530            [-1, 448, 2, 2]               0\n",
            "          Conv2d-531           [-1, 1792, 2, 2]         802,816\n",
            "     BatchNorm2d-532           [-1, 1792, 2, 2]           3,584\n",
            "            SiLU-533           [-1, 1792, 2, 2]               0\n",
            "AdaptiveAvgPool2d-534           [-1, 1792, 1, 1]               0\n",
            "        Identity-535                 [-1, 1792]               0\n",
            "    EfficientNet-536                 [-1, 1792]               0\n",
            "          Linear-537                    [-1, 3]           5,379\n",
            "          Linear-538                   [-1, 89]         159,577\n",
            "================================================================\n",
            "Total params: 17,713,572\n",
            "Trainable params: 164,956\n",
            "Non-trainable params: 17,548,616\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 40.70\n",
            "Params size (MB): 67.57\n",
            "Estimated Total Size (MB): 108.32\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with all backbone frozen)\n",
        "for param in effnetb4_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in effnetb4_joint_model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(effnetb4_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb4_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xUUrrvbeQgxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2990622c-bc9d-4a0a-b5a2-102735347bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 train: 100%|██████████| 495/495 [00:24<00:00, 19.83batch/s, loss=14.3, sub_class_accuracy=0, super_class_accuracy=0.458]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train Super Class loss: 5.2935344300046 Super Class acc: 0.444100558757782\n",
            "Sub Class loss: 8.982821467429957 Sub Class acc: 0.01654876209795475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 val: 100%|██████████| 23/23 [00:00<00:00, 24.97batch/s, loss=13.8, sub_class_accuracy=0.0333, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 val Super Class loss: 16.38833329446959 Super Class acc: 0.5136239528656006\n",
            "Sub Class loss: 14.706131150352208 Sub Class acc: 0.0272479560226202\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 train: 100%|██████████| 495/495 [00:25<00:00, 19.78batch/s, loss=13.3, sub_class_accuracy=0.0833, super_class_accuracy=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train Super Class loss: 5.067669097042373 Super Class acc: 0.5022738575935364\n",
            "Sub Class loss: 8.842765845211543 Sub Class acc: 0.026970691978931427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 val: 100%|██████████| 23/23 [00:00<00:00, 24.73batch/s, loss=13.5, sub_class_accuracy=0.0667, super_class_accuracy=0.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 val Super Class loss: 20.981995638774592 Super Class acc: 0.5544959306716919\n",
            "Sub Class loss: 24.788064852722336 Sub Class acc: 0.03405994549393654\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 train: 100%|██████████| 495/495 [00:25<00:00, 19.35batch/s, loss=15.6, sub_class_accuracy=0, super_class_accuracy=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train Super Class loss: 5.009469662488501 Super Class acc: 0.5112430453300476\n",
            "Sub Class loss: 8.74926200980427 Sub Class acc: 0.03492925688624382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 val: 100%|██████████| 23/23 [00:00<00:00, 24.13batch/s, loss=13.2, sub_class_accuracy=0.0333, super_class_accuracy=0.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 val Super Class loss: 37.148234925413 Super Class acc: 0.5504087209701538\n",
            "Sub Class loss: 29.490395130188652 Sub Class acc: 0.042234331369400024\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 train: 100%|██████████| 495/495 [00:25<00:00, 19.19batch/s, loss=13.7, sub_class_accuracy=0.0417, super_class_accuracy=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train Super Class loss: 4.971135230965539 Super Class acc: 0.5147801637649536\n",
            "Sub Class loss: 8.678641717803785 Sub Class acc: 0.03821374475955963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 val: 100%|██████████| 23/23 [00:00<00:00, 24.88batch/s, loss=13.1, sub_class_accuracy=0.1, super_class_accuracy=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 val Super Class loss: 4.763108705467359 Super Class acc: 0.5585830807685852\n",
            "Sub Class loss: 11.53302620931932 Sub Class acc: 0.05040871724486351\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 train: 100%|██████████| 495/495 [00:25<00:00, 19.66batch/s, loss=13.6, sub_class_accuracy=0.0417, super_class_accuracy=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train Super Class loss: 4.92995870360345 Super Class acc: 0.5278549790382385\n",
            "Sub Class loss: 8.638961219980356 Sub Class acc: 0.042066700756549835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 val: 100%|██████████| 23/23 [00:00<00:00, 24.34batch/s, loss=12.9, sub_class_accuracy=0, super_class_accuracy=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 val Super Class loss: 6.46801226145565 Super Class acc: 0.5667575001716614\n",
            "Sub Class loss: 11.3482525095303 Sub Class acc: 0.05040871724486351\n",
            "--------------------\n",
            "Best Super Class val acc: 0.5667575001716614\n",
            "Best Sub Class val acc: 0.05040871724486351\n",
            "Average Time taken for an epoch: 26.61972060203552 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "initial_epoch = 0\n",
        "learning_rate = 1e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb4_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='EnsembleJoint_EffnetB4_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIBUnCCiQgxn"
      },
      "source": [
        "###### Unfreeze some layers of the backbone network (phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vTNALcVLQgxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b72aca7c-dcf9-4874-bf11-aac8da0a3924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 32, 32]           1,296\n",
            "       BatchNorm2d-2           [-1, 48, 32, 32]              96\n",
            "              SiLU-3           [-1, 48, 32, 32]               0\n",
            "            Conv2d-4           [-1, 48, 32, 32]             432\n",
            "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
            "              SiLU-6           [-1, 48, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 48, 1, 1]               0\n",
            "            Conv2d-8             [-1, 12, 1, 1]             588\n",
            "              SiLU-9             [-1, 12, 1, 1]               0\n",
            "           Conv2d-10             [-1, 48, 1, 1]             624\n",
            "          Sigmoid-11             [-1, 48, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 48, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]           1,152\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "          Dropout-19           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-20             [-1, 24, 1, 1]               0\n",
            "           Conv2d-21              [-1, 6, 1, 1]             150\n",
            "             SiLU-22              [-1, 6, 1, 1]               0\n",
            "           Conv2d-23             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-24             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-25           [-1, 24, 32, 32]               0\n",
            "           Conv2d-26           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-27           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-28           [-1, 24, 32, 32]               0\n",
            "           MBConv-29           [-1, 24, 32, 32]               0\n",
            "           Conv2d-30          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-31          [-1, 144, 32, 32]             288\n",
            "             SiLU-32          [-1, 144, 32, 32]               0\n",
            "           Conv2d-33          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-34          [-1, 144, 16, 16]             288\n",
            "             SiLU-35          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-36            [-1, 144, 1, 1]               0\n",
            "           Conv2d-37              [-1, 6, 1, 1]             870\n",
            "             SiLU-38              [-1, 6, 1, 1]               0\n",
            "           Conv2d-39            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-40            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-41          [-1, 144, 16, 16]               0\n",
            "           Conv2d-42           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "           MBConv-44           [-1, 32, 16, 16]               0\n",
            "           Conv2d-45          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-46          [-1, 192, 16, 16]             384\n",
            "             SiLU-47          [-1, 192, 16, 16]               0\n",
            "           Conv2d-48          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-49          [-1, 192, 16, 16]             384\n",
            "             SiLU-50          [-1, 192, 16, 16]               0\n",
            "          Dropout-51          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-52            [-1, 192, 1, 1]               0\n",
            "           Conv2d-53              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-54              [-1, 8, 1, 1]               0\n",
            "           Conv2d-55            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-56            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-57          [-1, 192, 16, 16]               0\n",
            "           Conv2d-58           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-60           [-1, 32, 16, 16]               0\n",
            "           MBConv-61           [-1, 32, 16, 16]               0\n",
            "           Conv2d-62          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-63          [-1, 192, 16, 16]             384\n",
            "             SiLU-64          [-1, 192, 16, 16]               0\n",
            "           Conv2d-65          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-66          [-1, 192, 16, 16]             384\n",
            "             SiLU-67          [-1, 192, 16, 16]               0\n",
            "          Dropout-68          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-69            [-1, 192, 1, 1]               0\n",
            "           Conv2d-70              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-71              [-1, 8, 1, 1]               0\n",
            "           Conv2d-72            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-73            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-74          [-1, 192, 16, 16]               0\n",
            "           Conv2d-75           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-76           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-77           [-1, 32, 16, 16]               0\n",
            "           MBConv-78           [-1, 32, 16, 16]               0\n",
            "           Conv2d-79          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-80          [-1, 192, 16, 16]             384\n",
            "             SiLU-81          [-1, 192, 16, 16]               0\n",
            "           Conv2d-82          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-83          [-1, 192, 16, 16]             384\n",
            "             SiLU-84          [-1, 192, 16, 16]               0\n",
            "          Dropout-85          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-86            [-1, 192, 1, 1]               0\n",
            "           Conv2d-87              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-88              [-1, 8, 1, 1]               0\n",
            "           Conv2d-89            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-90            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-91          [-1, 192, 16, 16]               0\n",
            "           Conv2d-92           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-93           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-94           [-1, 32, 16, 16]               0\n",
            "           MBConv-95           [-1, 32, 16, 16]               0\n",
            "           Conv2d-96          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-97          [-1, 192, 16, 16]             384\n",
            "             SiLU-98          [-1, 192, 16, 16]               0\n",
            "           Conv2d-99            [-1, 192, 8, 8]           4,800\n",
            "     BatchNorm2d-100            [-1, 192, 8, 8]             384\n",
            "            SiLU-101            [-1, 192, 8, 8]               0\n",
            "         Dropout-102            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-103            [-1, 192, 1, 1]               0\n",
            "          Conv2d-104              [-1, 8, 1, 1]           1,544\n",
            "            SiLU-105              [-1, 8, 1, 1]               0\n",
            "          Conv2d-106            [-1, 192, 1, 1]           1,728\n",
            "         Sigmoid-107            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-108            [-1, 192, 8, 8]               0\n",
            "          Conv2d-109             [-1, 56, 8, 8]          10,752\n",
            "     BatchNorm2d-110             [-1, 56, 8, 8]             112\n",
            "          MBConv-111             [-1, 56, 8, 8]               0\n",
            "          Conv2d-112            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-113            [-1, 336, 8, 8]             672\n",
            "            SiLU-114            [-1, 336, 8, 8]               0\n",
            "          Conv2d-115            [-1, 336, 8, 8]           8,400\n",
            "     BatchNorm2d-116            [-1, 336, 8, 8]             672\n",
            "            SiLU-117            [-1, 336, 8, 8]               0\n",
            "         Dropout-118            [-1, 336, 8, 8]               0\n",
            "AdaptiveAvgPool2d-119            [-1, 336, 1, 1]               0\n",
            "          Conv2d-120             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-121             [-1, 14, 1, 1]               0\n",
            "          Conv2d-122            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-123            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-124            [-1, 336, 8, 8]               0\n",
            "          Conv2d-125             [-1, 56, 8, 8]          18,816\n",
            "     BatchNorm2d-126             [-1, 56, 8, 8]             112\n",
            " StochasticDepth-127             [-1, 56, 8, 8]               0\n",
            "          MBConv-128             [-1, 56, 8, 8]               0\n",
            "          Conv2d-129            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-130            [-1, 336, 8, 8]             672\n",
            "            SiLU-131            [-1, 336, 8, 8]               0\n",
            "          Conv2d-132            [-1, 336, 8, 8]           8,400\n",
            "     BatchNorm2d-133            [-1, 336, 8, 8]             672\n",
            "            SiLU-134            [-1, 336, 8, 8]               0\n",
            "         Dropout-135            [-1, 336, 8, 8]               0\n",
            "AdaptiveAvgPool2d-136            [-1, 336, 1, 1]               0\n",
            "          Conv2d-137             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-138             [-1, 14, 1, 1]               0\n",
            "          Conv2d-139            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-140            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-141            [-1, 336, 8, 8]               0\n",
            "          Conv2d-142             [-1, 56, 8, 8]          18,816\n",
            "     BatchNorm2d-143             [-1, 56, 8, 8]             112\n",
            " StochasticDepth-144             [-1, 56, 8, 8]               0\n",
            "          MBConv-145             [-1, 56, 8, 8]               0\n",
            "          Conv2d-146            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-147            [-1, 336, 8, 8]             672\n",
            "            SiLU-148            [-1, 336, 8, 8]               0\n",
            "          Conv2d-149            [-1, 336, 8, 8]           8,400\n",
            "     BatchNorm2d-150            [-1, 336, 8, 8]             672\n",
            "            SiLU-151            [-1, 336, 8, 8]               0\n",
            "         Dropout-152            [-1, 336, 8, 8]               0\n",
            "AdaptiveAvgPool2d-153            [-1, 336, 1, 1]               0\n",
            "          Conv2d-154             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-155             [-1, 14, 1, 1]               0\n",
            "          Conv2d-156            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-157            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-158            [-1, 336, 8, 8]               0\n",
            "          Conv2d-159             [-1, 56, 8, 8]          18,816\n",
            "     BatchNorm2d-160             [-1, 56, 8, 8]             112\n",
            " StochasticDepth-161             [-1, 56, 8, 8]               0\n",
            "          MBConv-162             [-1, 56, 8, 8]               0\n",
            "          Conv2d-163            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-164            [-1, 336, 8, 8]             672\n",
            "            SiLU-165            [-1, 336, 8, 8]               0\n",
            "          Conv2d-166            [-1, 336, 4, 4]           3,024\n",
            "     BatchNorm2d-167            [-1, 336, 4, 4]             672\n",
            "            SiLU-168            [-1, 336, 4, 4]               0\n",
            "         Dropout-169            [-1, 336, 4, 4]               0\n",
            "AdaptiveAvgPool2d-170            [-1, 336, 1, 1]               0\n",
            "          Conv2d-171             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-172             [-1, 14, 1, 1]               0\n",
            "          Conv2d-173            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-174            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-175            [-1, 336, 4, 4]               0\n",
            "          Conv2d-176            [-1, 112, 4, 4]          37,632\n",
            "     BatchNorm2d-177            [-1, 112, 4, 4]             224\n",
            "          MBConv-178            [-1, 112, 4, 4]               0\n",
            "          Conv2d-179            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-180            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-181            [-1, 672, 4, 4]               0\n",
            "          Conv2d-182            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-183            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-184            [-1, 672, 4, 4]               0\n",
            "         Dropout-185            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-186            [-1, 672, 1, 1]               0\n",
            "          Conv2d-187             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-188             [-1, 28, 1, 1]               0\n",
            "          Conv2d-189            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-190            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-191            [-1, 672, 4, 4]               0\n",
            "          Conv2d-192            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-193            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-194            [-1, 112, 4, 4]               0\n",
            "          MBConv-195            [-1, 112, 4, 4]               0\n",
            "          Conv2d-196            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-197            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-198            [-1, 672, 4, 4]               0\n",
            "          Conv2d-199            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-200            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-201            [-1, 672, 4, 4]               0\n",
            "         Dropout-202            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-203            [-1, 672, 1, 1]               0\n",
            "          Conv2d-204             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-205             [-1, 28, 1, 1]               0\n",
            "          Conv2d-206            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-207            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-208            [-1, 672, 4, 4]               0\n",
            "          Conv2d-209            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-210            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-211            [-1, 112, 4, 4]               0\n",
            "          MBConv-212            [-1, 112, 4, 4]               0\n",
            "          Conv2d-213            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-214            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-215            [-1, 672, 4, 4]               0\n",
            "          Conv2d-216            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-217            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-218            [-1, 672, 4, 4]               0\n",
            "         Dropout-219            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-220            [-1, 672, 1, 1]               0\n",
            "          Conv2d-221             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-222             [-1, 28, 1, 1]               0\n",
            "          Conv2d-223            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-224            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-225            [-1, 672, 4, 4]               0\n",
            "          Conv2d-226            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-227            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-228            [-1, 112, 4, 4]               0\n",
            "          MBConv-229            [-1, 112, 4, 4]               0\n",
            "          Conv2d-230            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-231            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-232            [-1, 672, 4, 4]               0\n",
            "          Conv2d-233            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-234            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-235            [-1, 672, 4, 4]               0\n",
            "         Dropout-236            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-237            [-1, 672, 1, 1]               0\n",
            "          Conv2d-238             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-239             [-1, 28, 1, 1]               0\n",
            "          Conv2d-240            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-241            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-242            [-1, 672, 4, 4]               0\n",
            "          Conv2d-243            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-244            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-245            [-1, 112, 4, 4]               0\n",
            "          MBConv-246            [-1, 112, 4, 4]               0\n",
            "          Conv2d-247            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-248            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-249            [-1, 672, 4, 4]               0\n",
            "          Conv2d-250            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-251            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-252            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-253            [-1, 672, 1, 1]               0\n",
            "          Conv2d-254             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-255             [-1, 28, 1, 1]               0\n",
            "          Conv2d-256            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-257            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-258            [-1, 672, 4, 4]               0\n",
            "          Conv2d-259            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-260            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-261            [-1, 112, 4, 4]               0\n",
            "          MBConv-262            [-1, 112, 4, 4]               0\n",
            "          Conv2d-263            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-264            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-265            [-1, 672, 4, 4]               0\n",
            "          Conv2d-266            [-1, 672, 4, 4]          16,800\n",
            "     BatchNorm2d-267            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-268            [-1, 672, 4, 4]               0\n",
            "         Dropout-269            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-270            [-1, 672, 1, 1]               0\n",
            "          Conv2d-271             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-272             [-1, 28, 1, 1]               0\n",
            "          Conv2d-273            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-274            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-275            [-1, 672, 4, 4]               0\n",
            "          Conv2d-276            [-1, 160, 4, 4]         107,520\n",
            "     BatchNorm2d-277            [-1, 160, 4, 4]             320\n",
            "          MBConv-278            [-1, 160, 4, 4]               0\n",
            "          Conv2d-279            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-280            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-281            [-1, 960, 4, 4]               0\n",
            "          Conv2d-282            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-283            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-284            [-1, 960, 4, 4]               0\n",
            "         Dropout-285            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-286            [-1, 960, 1, 1]               0\n",
            "          Conv2d-287             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-288             [-1, 40, 1, 1]               0\n",
            "          Conv2d-289            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-290            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-291            [-1, 960, 4, 4]               0\n",
            "          Conv2d-292            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-293            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-294            [-1, 160, 4, 4]               0\n",
            "          MBConv-295            [-1, 160, 4, 4]               0\n",
            "          Conv2d-296            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-297            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-298            [-1, 960, 4, 4]               0\n",
            "          Conv2d-299            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-300            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-301            [-1, 960, 4, 4]               0\n",
            "         Dropout-302            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-303            [-1, 960, 1, 1]               0\n",
            "          Conv2d-304             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-305             [-1, 40, 1, 1]               0\n",
            "          Conv2d-306            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-307            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-308            [-1, 960, 4, 4]               0\n",
            "          Conv2d-309            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-310            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-311            [-1, 160, 4, 4]               0\n",
            "          MBConv-312            [-1, 160, 4, 4]               0\n",
            "          Conv2d-313            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-314            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-315            [-1, 960, 4, 4]               0\n",
            "          Conv2d-316            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-317            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-318            [-1, 960, 4, 4]               0\n",
            "         Dropout-319            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-320            [-1, 960, 1, 1]               0\n",
            "          Conv2d-321             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-322             [-1, 40, 1, 1]               0\n",
            "          Conv2d-323            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-324            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-325            [-1, 960, 4, 4]               0\n",
            "          Conv2d-326            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-327            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-328            [-1, 160, 4, 4]               0\n",
            "          MBConv-329            [-1, 160, 4, 4]               0\n",
            "          Conv2d-330            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-331            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-332            [-1, 960, 4, 4]               0\n",
            "          Conv2d-333            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-334            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-335            [-1, 960, 4, 4]               0\n",
            "         Dropout-336            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-337            [-1, 960, 1, 1]               0\n",
            "          Conv2d-338             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-339             [-1, 40, 1, 1]               0\n",
            "          Conv2d-340            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-341            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-342            [-1, 960, 4, 4]               0\n",
            "          Conv2d-343            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-344            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-345            [-1, 160, 4, 4]               0\n",
            "          MBConv-346            [-1, 160, 4, 4]               0\n",
            "          Conv2d-347            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-348            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-349            [-1, 960, 4, 4]               0\n",
            "          Conv2d-350            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-351            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-352            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-353            [-1, 960, 1, 1]               0\n",
            "          Conv2d-354             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-355             [-1, 40, 1, 1]               0\n",
            "          Conv2d-356            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-357            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-358            [-1, 960, 4, 4]               0\n",
            "          Conv2d-359            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-360            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-361            [-1, 160, 4, 4]               0\n",
            "          MBConv-362            [-1, 160, 4, 4]               0\n",
            "          Conv2d-363            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-364            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-365            [-1, 960, 4, 4]               0\n",
            "          Conv2d-366            [-1, 960, 2, 2]          24,000\n",
            "     BatchNorm2d-367            [-1, 960, 2, 2]           1,920\n",
            "            SiLU-368            [-1, 960, 2, 2]               0\n",
            "         Dropout-369            [-1, 960, 2, 2]               0\n",
            "AdaptiveAvgPool2d-370            [-1, 960, 1, 1]               0\n",
            "          Conv2d-371             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-372             [-1, 40, 1, 1]               0\n",
            "          Conv2d-373            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-374            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-375            [-1, 960, 2, 2]               0\n",
            "          Conv2d-376            [-1, 272, 2, 2]         261,120\n",
            "     BatchNorm2d-377            [-1, 272, 2, 2]             544\n",
            "          MBConv-378            [-1, 272, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-380           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-381           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-382           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-383           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-384           [-1, 1632, 2, 2]               0\n",
            "         Dropout-385           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-386           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-387             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-388             [-1, 68, 1, 1]               0\n",
            "          Conv2d-389           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-390           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-391           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-392            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-393            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-394            [-1, 272, 2, 2]               0\n",
            "          MBConv-395            [-1, 272, 2, 2]               0\n",
            "          Conv2d-396           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-397           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-398           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-399           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-400           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-401           [-1, 1632, 2, 2]               0\n",
            "         Dropout-402           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-403           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-404             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-405             [-1, 68, 1, 1]               0\n",
            "          Conv2d-406           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-407           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-408           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-409            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-410            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-411            [-1, 272, 2, 2]               0\n",
            "          MBConv-412            [-1, 272, 2, 2]               0\n",
            "          Conv2d-413           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-414           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-415           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-416           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-417           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-418           [-1, 1632, 2, 2]               0\n",
            "         Dropout-419           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-420           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-421             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-422             [-1, 68, 1, 1]               0\n",
            "          Conv2d-423           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-424           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-425           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-426            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-427            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-428            [-1, 272, 2, 2]               0\n",
            "          MBConv-429            [-1, 272, 2, 2]               0\n",
            "          Conv2d-430           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-431           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-432           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-433           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-434           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-435           [-1, 1632, 2, 2]               0\n",
            "         Dropout-436           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-437           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-438             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-439             [-1, 68, 1, 1]               0\n",
            "          Conv2d-440           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-441           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-442           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-443            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-444            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-445            [-1, 272, 2, 2]               0\n",
            "          MBConv-446            [-1, 272, 2, 2]               0\n",
            "          Conv2d-447           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-448           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-449           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-450           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-451           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-452           [-1, 1632, 2, 2]               0\n",
            "         Dropout-453           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-454           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-455             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-456             [-1, 68, 1, 1]               0\n",
            "          Conv2d-457           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-458           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-459           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-460            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-461            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-462            [-1, 272, 2, 2]               0\n",
            "          MBConv-463            [-1, 272, 2, 2]               0\n",
            "          Conv2d-464           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-465           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-466           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-467           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-468           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-469           [-1, 1632, 2, 2]               0\n",
            "         Dropout-470           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-471           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-472             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-473             [-1, 68, 1, 1]               0\n",
            "          Conv2d-474           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-475           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-476           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-477            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-478            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-479            [-1, 272, 2, 2]               0\n",
            "          MBConv-480            [-1, 272, 2, 2]               0\n",
            "          Conv2d-481           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-482           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-483           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-484           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-485           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-486           [-1, 1632, 2, 2]               0\n",
            "         Dropout-487           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-488           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-489             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-490             [-1, 68, 1, 1]               0\n",
            "          Conv2d-491           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-492           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-493           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-494            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-495            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-496            [-1, 272, 2, 2]               0\n",
            "          MBConv-497            [-1, 272, 2, 2]               0\n",
            "          Conv2d-498           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-499           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-500           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-501           [-1, 1632, 2, 2]          14,688\n",
            "     BatchNorm2d-502           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-503           [-1, 1632, 2, 2]               0\n",
            "         Dropout-504           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-505           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-506             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-507             [-1, 68, 1, 1]               0\n",
            "          Conv2d-508           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-509           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-510           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-511            [-1, 448, 2, 2]         731,136\n",
            "     BatchNorm2d-512            [-1, 448, 2, 2]             896\n",
            "          MBConv-513            [-1, 448, 2, 2]               0\n",
            "          Conv2d-514           [-1, 2688, 2, 2]       1,204,224\n",
            "     BatchNorm2d-515           [-1, 2688, 2, 2]           5,376\n",
            "            SiLU-516           [-1, 2688, 2, 2]               0\n",
            "          Conv2d-517           [-1, 2688, 2, 2]          24,192\n",
            "     BatchNorm2d-518           [-1, 2688, 2, 2]           5,376\n",
            "            SiLU-519           [-1, 2688, 2, 2]               0\n",
            "         Dropout-520           [-1, 2688, 2, 2]               0\n",
            "AdaptiveAvgPool2d-521           [-1, 2688, 1, 1]               0\n",
            "          Conv2d-522            [-1, 112, 1, 1]         301,168\n",
            "            SiLU-523            [-1, 112, 1, 1]               0\n",
            "          Conv2d-524           [-1, 2688, 1, 1]         303,744\n",
            "         Sigmoid-525           [-1, 2688, 1, 1]               0\n",
            "SqueezeExcitation-526           [-1, 2688, 2, 2]               0\n",
            "          Conv2d-527            [-1, 448, 2, 2]       1,204,224\n",
            "     BatchNorm2d-528            [-1, 448, 2, 2]             896\n",
            " StochasticDepth-529            [-1, 448, 2, 2]               0\n",
            "          MBConv-530            [-1, 448, 2, 2]               0\n",
            "          Conv2d-531           [-1, 1792, 2, 2]         802,816\n",
            "     BatchNorm2d-532           [-1, 1792, 2, 2]           3,584\n",
            "            SiLU-533           [-1, 1792, 2, 2]               0\n",
            "AdaptiveAvgPool2d-534           [-1, 1792, 1, 1]               0\n",
            "        Identity-535                 [-1, 1792]               0\n",
            "    EfficientNet-536                 [-1, 1792]               0\n",
            "          Linear-537                    [-1, 3]           5,379\n",
            "          Linear-538                   [-1, 89]         159,577\n",
            "================================================================\n",
            "Total params: 17,713,572\n",
            "Trainable params: 5,441,360\n",
            "Non-trainable params: 12,272,212\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 40.70\n",
            "Params size (MB): 67.57\n",
            "Estimated Total Size (MB): 108.32\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training the model (with some backbone frozen)\n",
        "for param in effnetb4_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in effnetb4_joint_model.backbone.features[:7].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "summary(effnetb4_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb4_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "XlV2h2FaQgxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7358b494-6123-4d2f-df5d-ffa37bfe6a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 train: 100%|██████████| 495/495 [00:28<00:00, 17.16batch/s, loss=13.1, sub_class_accuracy=0, super_class_accuracy=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train Super Class loss: 4.824104266916037 Super Class acc: 0.5421298742294312\n",
            "Sub Class loss: 8.526166124136656 Sub Class acc: 0.04958312213420868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 val: 100%|██████████| 23/23 [00:00<00:00, 23.78batch/s, loss=12.4, sub_class_accuracy=0.0333, super_class_accuracy=0.533]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 val Super Class loss: 5.34927718239844 Super Class acc: 0.5844686627388\n",
            "Sub Class loss: 8.579966986861475 Sub Class acc: 0.06811989098787308\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 train: 100%|██████████| 495/495 [00:28<00:00, 17.14batch/s, loss=12.7, sub_class_accuracy=0.0417, super_class_accuracy=0.458]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train Super Class loss: 4.681178522778618 Super Class acc: 0.5752273797988892\n",
            "Sub Class loss: 8.318163981637671 Sub Class acc: 0.057604849338531494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 val: 100%|██████████| 23/23 [00:00<00:00, 24.24batch/s, loss=11.9, sub_class_accuracy=0.0333, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 val Super Class loss: 4.211144270299241 Super Class acc: 0.6076294183731079\n",
            "Sub Class loss: 8.25641547756559 Sub Class acc: 0.08174386620521545\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 train: 100%|██████████| 495/495 [00:28<00:00, 17.30batch/s, loss=12.4, sub_class_accuracy=0.0417, super_class_accuracy=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train Super Class loss: 4.518031685595683 Super Class acc: 0.5883021950721741\n",
            "Sub Class loss: 8.102124472469196 Sub Class acc: 0.07049014419317245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 val: 100%|██████████| 23/23 [00:00<00:00, 24.29batch/s, loss=11.5, sub_class_accuracy=0, super_class_accuracy=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 val Super Class loss: 4.042988569762467 Super Class acc: 0.6226158142089844\n",
            "Sub Class loss: 7.847545140445719 Sub Class acc: 0.08174386620521545\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 train: 100%|██████████| 495/495 [00:28<00:00, 17.31batch/s, loss=12.8, sub_class_accuracy=0.0833, super_class_accuracy=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 train Super Class loss: 4.438996626277835 Super Class acc: 0.5951869487762451\n",
            "Sub Class loss: 7.967247602010749 Sub Class acc: 0.0718165710568428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 val: 100%|██████████| 23/23 [00:00<00:00, 25.03batch/s, loss=11.4, sub_class_accuracy=0.0333, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 val Super Class loss: 4.071096028391607 Super Class acc: 0.6444141864776611\n",
            "Sub Class loss: 8.090353271941723 Sub Class acc: 0.09673024713993073\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 train: 100%|██████████| 495/495 [00:28<00:00, 17.33batch/s, loss=11.9, sub_class_accuracy=0, super_class_accuracy=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 train Super Class loss: 4.3561339397934 Super Class acc: 0.6033982038497925\n",
            "Sub Class loss: 7.871313947809652 Sub Class acc: 0.08148054778575897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 val: 100%|██████████| 23/23 [00:00<00:00, 23.86batch/s, loss=11, sub_class_accuracy=0, super_class_accuracy=0.767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 val Super Class loss: 4.407699730155903 Super Class acc: 0.6158037781715393\n",
            "Sub Class loss: 8.521426642623194 Sub Class acc: 0.09945503622293472\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 train: 100%|██████████| 495/495 [00:28<00:00, 17.25batch/s, loss=11.5, sub_class_accuracy=0.0833, super_class_accuracy=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 train Super Class loss: 4.327854459155624 Super Class acc: 0.6081985831260681\n",
            "Sub Class loss: 7.813905080561086 Sub Class acc: 0.0845123827457428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 val: 100%|██████████| 23/23 [00:00<00:00, 24.79batch/s, loss=10.9, sub_class_accuracy=0.0333, super_class_accuracy=0.733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 val Super Class loss: 4.134300502996679 Super Class acc: 0.6457765698432922\n",
            "Sub Class loss: 7.988372832617903 Sub Class acc: 0.09400545060634613\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 train: 100%|██████████| 495/495 [00:29<00:00, 17.07batch/s, loss=11.6, sub_class_accuracy=0.0833, super_class_accuracy=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 train Super Class loss: 4.303236519254296 Super Class acc: 0.6074406504631042\n",
            "Sub Class loss: 7.807567628240754 Sub Class acc: 0.08312278985977173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 val: 100%|██████████| 23/23 [00:00<00:00, 23.96batch/s, loss=10.6, sub_class_accuracy=0, super_class_accuracy=0.767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 val Super Class loss: 4.278790001485913 Super Class acc: 0.6539509296417236\n",
            "Sub Class loss: 8.789379319962753 Sub Class acc: 0.09400545060634613\n",
            "--------------------\n",
            "Best Super Class val acc: 0.6539509296417236\n",
            "Best Sub Class val acc: 0.09945503622293472\n",
            "Average Time taken for an epoch: 30.0252936567579 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 7\n",
        "initial_epoch = 5\n",
        "learning_rate = 4e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb4_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='EnsembleJoint_EffnetB4_semi_frozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IccVf-iaQgxo"
      },
      "source": [
        "###### Unfreeze all the layers in the network (phase 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "jimJ_onrQgxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a42961-8dad-4664-baa9-e257452768f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 32, 32]           1,296\n",
            "       BatchNorm2d-2           [-1, 48, 32, 32]              96\n",
            "              SiLU-3           [-1, 48, 32, 32]               0\n",
            "            Conv2d-4           [-1, 48, 32, 32]             432\n",
            "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
            "              SiLU-6           [-1, 48, 32, 32]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 48, 1, 1]               0\n",
            "            Conv2d-8             [-1, 12, 1, 1]             588\n",
            "              SiLU-9             [-1, 12, 1, 1]               0\n",
            "           Conv2d-10             [-1, 48, 1, 1]             624\n",
            "          Sigmoid-11             [-1, 48, 1, 1]               0\n",
            "SqueezeExcitation-12           [-1, 48, 32, 32]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]           1,152\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           MBConv-15           [-1, 24, 32, 32]               0\n",
            "           Conv2d-16           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
            "             SiLU-18           [-1, 24, 32, 32]               0\n",
            "          Dropout-19           [-1, 24, 32, 32]               0\n",
            "AdaptiveAvgPool2d-20             [-1, 24, 1, 1]               0\n",
            "           Conv2d-21              [-1, 6, 1, 1]             150\n",
            "             SiLU-22              [-1, 6, 1, 1]               0\n",
            "           Conv2d-23             [-1, 24, 1, 1]             168\n",
            "          Sigmoid-24             [-1, 24, 1, 1]               0\n",
            "SqueezeExcitation-25           [-1, 24, 32, 32]               0\n",
            "           Conv2d-26           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-27           [-1, 24, 32, 32]              48\n",
            "  StochasticDepth-28           [-1, 24, 32, 32]               0\n",
            "           MBConv-29           [-1, 24, 32, 32]               0\n",
            "           Conv2d-30          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-31          [-1, 144, 32, 32]             288\n",
            "             SiLU-32          [-1, 144, 32, 32]               0\n",
            "           Conv2d-33          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-34          [-1, 144, 16, 16]             288\n",
            "             SiLU-35          [-1, 144, 16, 16]               0\n",
            "AdaptiveAvgPool2d-36            [-1, 144, 1, 1]               0\n",
            "           Conv2d-37              [-1, 6, 1, 1]             870\n",
            "             SiLU-38              [-1, 6, 1, 1]               0\n",
            "           Conv2d-39            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-40            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-41          [-1, 144, 16, 16]               0\n",
            "           Conv2d-42           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "           MBConv-44           [-1, 32, 16, 16]               0\n",
            "           Conv2d-45          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-46          [-1, 192, 16, 16]             384\n",
            "             SiLU-47          [-1, 192, 16, 16]               0\n",
            "           Conv2d-48          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-49          [-1, 192, 16, 16]             384\n",
            "             SiLU-50          [-1, 192, 16, 16]               0\n",
            "          Dropout-51          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-52            [-1, 192, 1, 1]               0\n",
            "           Conv2d-53              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-54              [-1, 8, 1, 1]               0\n",
            "           Conv2d-55            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-56            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-57          [-1, 192, 16, 16]               0\n",
            "           Conv2d-58           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-60           [-1, 32, 16, 16]               0\n",
            "           MBConv-61           [-1, 32, 16, 16]               0\n",
            "           Conv2d-62          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-63          [-1, 192, 16, 16]             384\n",
            "             SiLU-64          [-1, 192, 16, 16]               0\n",
            "           Conv2d-65          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-66          [-1, 192, 16, 16]             384\n",
            "             SiLU-67          [-1, 192, 16, 16]               0\n",
            "          Dropout-68          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-69            [-1, 192, 1, 1]               0\n",
            "           Conv2d-70              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-71              [-1, 8, 1, 1]               0\n",
            "           Conv2d-72            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-73            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-74          [-1, 192, 16, 16]               0\n",
            "           Conv2d-75           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-76           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-77           [-1, 32, 16, 16]               0\n",
            "           MBConv-78           [-1, 32, 16, 16]               0\n",
            "           Conv2d-79          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-80          [-1, 192, 16, 16]             384\n",
            "             SiLU-81          [-1, 192, 16, 16]               0\n",
            "           Conv2d-82          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-83          [-1, 192, 16, 16]             384\n",
            "             SiLU-84          [-1, 192, 16, 16]               0\n",
            "          Dropout-85          [-1, 192, 16, 16]               0\n",
            "AdaptiveAvgPool2d-86            [-1, 192, 1, 1]               0\n",
            "           Conv2d-87              [-1, 8, 1, 1]           1,544\n",
            "             SiLU-88              [-1, 8, 1, 1]               0\n",
            "           Conv2d-89            [-1, 192, 1, 1]           1,728\n",
            "          Sigmoid-90            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-91          [-1, 192, 16, 16]               0\n",
            "           Conv2d-92           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-93           [-1, 32, 16, 16]              64\n",
            "  StochasticDepth-94           [-1, 32, 16, 16]               0\n",
            "           MBConv-95           [-1, 32, 16, 16]               0\n",
            "           Conv2d-96          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-97          [-1, 192, 16, 16]             384\n",
            "             SiLU-98          [-1, 192, 16, 16]               0\n",
            "           Conv2d-99            [-1, 192, 8, 8]           4,800\n",
            "     BatchNorm2d-100            [-1, 192, 8, 8]             384\n",
            "            SiLU-101            [-1, 192, 8, 8]               0\n",
            "         Dropout-102            [-1, 192, 8, 8]               0\n",
            "AdaptiveAvgPool2d-103            [-1, 192, 1, 1]               0\n",
            "          Conv2d-104              [-1, 8, 1, 1]           1,544\n",
            "            SiLU-105              [-1, 8, 1, 1]               0\n",
            "          Conv2d-106            [-1, 192, 1, 1]           1,728\n",
            "         Sigmoid-107            [-1, 192, 1, 1]               0\n",
            "SqueezeExcitation-108            [-1, 192, 8, 8]               0\n",
            "          Conv2d-109             [-1, 56, 8, 8]          10,752\n",
            "     BatchNorm2d-110             [-1, 56, 8, 8]             112\n",
            "          MBConv-111             [-1, 56, 8, 8]               0\n",
            "          Conv2d-112            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-113            [-1, 336, 8, 8]             672\n",
            "            SiLU-114            [-1, 336, 8, 8]               0\n",
            "          Conv2d-115            [-1, 336, 8, 8]           8,400\n",
            "     BatchNorm2d-116            [-1, 336, 8, 8]             672\n",
            "            SiLU-117            [-1, 336, 8, 8]               0\n",
            "         Dropout-118            [-1, 336, 8, 8]               0\n",
            "AdaptiveAvgPool2d-119            [-1, 336, 1, 1]               0\n",
            "          Conv2d-120             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-121             [-1, 14, 1, 1]               0\n",
            "          Conv2d-122            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-123            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-124            [-1, 336, 8, 8]               0\n",
            "          Conv2d-125             [-1, 56, 8, 8]          18,816\n",
            "     BatchNorm2d-126             [-1, 56, 8, 8]             112\n",
            " StochasticDepth-127             [-1, 56, 8, 8]               0\n",
            "          MBConv-128             [-1, 56, 8, 8]               0\n",
            "          Conv2d-129            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-130            [-1, 336, 8, 8]             672\n",
            "            SiLU-131            [-1, 336, 8, 8]               0\n",
            "          Conv2d-132            [-1, 336, 8, 8]           8,400\n",
            "     BatchNorm2d-133            [-1, 336, 8, 8]             672\n",
            "            SiLU-134            [-1, 336, 8, 8]               0\n",
            "         Dropout-135            [-1, 336, 8, 8]               0\n",
            "AdaptiveAvgPool2d-136            [-1, 336, 1, 1]               0\n",
            "          Conv2d-137             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-138             [-1, 14, 1, 1]               0\n",
            "          Conv2d-139            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-140            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-141            [-1, 336, 8, 8]               0\n",
            "          Conv2d-142             [-1, 56, 8, 8]          18,816\n",
            "     BatchNorm2d-143             [-1, 56, 8, 8]             112\n",
            " StochasticDepth-144             [-1, 56, 8, 8]               0\n",
            "          MBConv-145             [-1, 56, 8, 8]               0\n",
            "          Conv2d-146            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-147            [-1, 336, 8, 8]             672\n",
            "            SiLU-148            [-1, 336, 8, 8]               0\n",
            "          Conv2d-149            [-1, 336, 8, 8]           8,400\n",
            "     BatchNorm2d-150            [-1, 336, 8, 8]             672\n",
            "            SiLU-151            [-1, 336, 8, 8]               0\n",
            "         Dropout-152            [-1, 336, 8, 8]               0\n",
            "AdaptiveAvgPool2d-153            [-1, 336, 1, 1]               0\n",
            "          Conv2d-154             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-155             [-1, 14, 1, 1]               0\n",
            "          Conv2d-156            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-157            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-158            [-1, 336, 8, 8]               0\n",
            "          Conv2d-159             [-1, 56, 8, 8]          18,816\n",
            "     BatchNorm2d-160             [-1, 56, 8, 8]             112\n",
            " StochasticDepth-161             [-1, 56, 8, 8]               0\n",
            "          MBConv-162             [-1, 56, 8, 8]               0\n",
            "          Conv2d-163            [-1, 336, 8, 8]          18,816\n",
            "     BatchNorm2d-164            [-1, 336, 8, 8]             672\n",
            "            SiLU-165            [-1, 336, 8, 8]               0\n",
            "          Conv2d-166            [-1, 336, 4, 4]           3,024\n",
            "     BatchNorm2d-167            [-1, 336, 4, 4]             672\n",
            "            SiLU-168            [-1, 336, 4, 4]               0\n",
            "         Dropout-169            [-1, 336, 4, 4]               0\n",
            "AdaptiveAvgPool2d-170            [-1, 336, 1, 1]               0\n",
            "          Conv2d-171             [-1, 14, 1, 1]           4,718\n",
            "            SiLU-172             [-1, 14, 1, 1]               0\n",
            "          Conv2d-173            [-1, 336, 1, 1]           5,040\n",
            "         Sigmoid-174            [-1, 336, 1, 1]               0\n",
            "SqueezeExcitation-175            [-1, 336, 4, 4]               0\n",
            "          Conv2d-176            [-1, 112, 4, 4]          37,632\n",
            "     BatchNorm2d-177            [-1, 112, 4, 4]             224\n",
            "          MBConv-178            [-1, 112, 4, 4]               0\n",
            "          Conv2d-179            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-180            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-181            [-1, 672, 4, 4]               0\n",
            "          Conv2d-182            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-183            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-184            [-1, 672, 4, 4]               0\n",
            "         Dropout-185            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-186            [-1, 672, 1, 1]               0\n",
            "          Conv2d-187             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-188             [-1, 28, 1, 1]               0\n",
            "          Conv2d-189            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-190            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-191            [-1, 672, 4, 4]               0\n",
            "          Conv2d-192            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-193            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-194            [-1, 112, 4, 4]               0\n",
            "          MBConv-195            [-1, 112, 4, 4]               0\n",
            "          Conv2d-196            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-197            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-198            [-1, 672, 4, 4]               0\n",
            "          Conv2d-199            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-200            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-201            [-1, 672, 4, 4]               0\n",
            "         Dropout-202            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-203            [-1, 672, 1, 1]               0\n",
            "          Conv2d-204             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-205             [-1, 28, 1, 1]               0\n",
            "          Conv2d-206            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-207            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-208            [-1, 672, 4, 4]               0\n",
            "          Conv2d-209            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-210            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-211            [-1, 112, 4, 4]               0\n",
            "          MBConv-212            [-1, 112, 4, 4]               0\n",
            "          Conv2d-213            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-214            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-215            [-1, 672, 4, 4]               0\n",
            "          Conv2d-216            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-217            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-218            [-1, 672, 4, 4]               0\n",
            "         Dropout-219            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-220            [-1, 672, 1, 1]               0\n",
            "          Conv2d-221             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-222             [-1, 28, 1, 1]               0\n",
            "          Conv2d-223            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-224            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-225            [-1, 672, 4, 4]               0\n",
            "          Conv2d-226            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-227            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-228            [-1, 112, 4, 4]               0\n",
            "          MBConv-229            [-1, 112, 4, 4]               0\n",
            "          Conv2d-230            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-231            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-232            [-1, 672, 4, 4]               0\n",
            "          Conv2d-233            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-234            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-235            [-1, 672, 4, 4]               0\n",
            "         Dropout-236            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-237            [-1, 672, 1, 1]               0\n",
            "          Conv2d-238             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-239             [-1, 28, 1, 1]               0\n",
            "          Conv2d-240            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-241            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-242            [-1, 672, 4, 4]               0\n",
            "          Conv2d-243            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-244            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-245            [-1, 112, 4, 4]               0\n",
            "          MBConv-246            [-1, 112, 4, 4]               0\n",
            "          Conv2d-247            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-248            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-249            [-1, 672, 4, 4]               0\n",
            "          Conv2d-250            [-1, 672, 4, 4]           6,048\n",
            "     BatchNorm2d-251            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-252            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-253            [-1, 672, 1, 1]               0\n",
            "          Conv2d-254             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-255             [-1, 28, 1, 1]               0\n",
            "          Conv2d-256            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-257            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-258            [-1, 672, 4, 4]               0\n",
            "          Conv2d-259            [-1, 112, 4, 4]          75,264\n",
            "     BatchNorm2d-260            [-1, 112, 4, 4]             224\n",
            " StochasticDepth-261            [-1, 112, 4, 4]               0\n",
            "          MBConv-262            [-1, 112, 4, 4]               0\n",
            "          Conv2d-263            [-1, 672, 4, 4]          75,264\n",
            "     BatchNorm2d-264            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-265            [-1, 672, 4, 4]               0\n",
            "          Conv2d-266            [-1, 672, 4, 4]          16,800\n",
            "     BatchNorm2d-267            [-1, 672, 4, 4]           1,344\n",
            "            SiLU-268            [-1, 672, 4, 4]               0\n",
            "         Dropout-269            [-1, 672, 4, 4]               0\n",
            "AdaptiveAvgPool2d-270            [-1, 672, 1, 1]               0\n",
            "          Conv2d-271             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-272             [-1, 28, 1, 1]               0\n",
            "          Conv2d-273            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-274            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-275            [-1, 672, 4, 4]               0\n",
            "          Conv2d-276            [-1, 160, 4, 4]         107,520\n",
            "     BatchNorm2d-277            [-1, 160, 4, 4]             320\n",
            "          MBConv-278            [-1, 160, 4, 4]               0\n",
            "          Conv2d-279            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-280            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-281            [-1, 960, 4, 4]               0\n",
            "          Conv2d-282            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-283            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-284            [-1, 960, 4, 4]               0\n",
            "         Dropout-285            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-286            [-1, 960, 1, 1]               0\n",
            "          Conv2d-287             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-288             [-1, 40, 1, 1]               0\n",
            "          Conv2d-289            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-290            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-291            [-1, 960, 4, 4]               0\n",
            "          Conv2d-292            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-293            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-294            [-1, 160, 4, 4]               0\n",
            "          MBConv-295            [-1, 160, 4, 4]               0\n",
            "          Conv2d-296            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-297            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-298            [-1, 960, 4, 4]               0\n",
            "          Conv2d-299            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-300            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-301            [-1, 960, 4, 4]               0\n",
            "         Dropout-302            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-303            [-1, 960, 1, 1]               0\n",
            "          Conv2d-304             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-305             [-1, 40, 1, 1]               0\n",
            "          Conv2d-306            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-307            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-308            [-1, 960, 4, 4]               0\n",
            "          Conv2d-309            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-310            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-311            [-1, 160, 4, 4]               0\n",
            "          MBConv-312            [-1, 160, 4, 4]               0\n",
            "          Conv2d-313            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-314            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-315            [-1, 960, 4, 4]               0\n",
            "          Conv2d-316            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-317            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-318            [-1, 960, 4, 4]               0\n",
            "         Dropout-319            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-320            [-1, 960, 1, 1]               0\n",
            "          Conv2d-321             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-322             [-1, 40, 1, 1]               0\n",
            "          Conv2d-323            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-324            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-325            [-1, 960, 4, 4]               0\n",
            "          Conv2d-326            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-327            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-328            [-1, 160, 4, 4]               0\n",
            "          MBConv-329            [-1, 160, 4, 4]               0\n",
            "          Conv2d-330            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-331            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-332            [-1, 960, 4, 4]               0\n",
            "          Conv2d-333            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-334            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-335            [-1, 960, 4, 4]               0\n",
            "         Dropout-336            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-337            [-1, 960, 1, 1]               0\n",
            "          Conv2d-338             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-339             [-1, 40, 1, 1]               0\n",
            "          Conv2d-340            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-341            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-342            [-1, 960, 4, 4]               0\n",
            "          Conv2d-343            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-344            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-345            [-1, 160, 4, 4]               0\n",
            "          MBConv-346            [-1, 160, 4, 4]               0\n",
            "          Conv2d-347            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-348            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-349            [-1, 960, 4, 4]               0\n",
            "          Conv2d-350            [-1, 960, 4, 4]          24,000\n",
            "     BatchNorm2d-351            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-352            [-1, 960, 4, 4]               0\n",
            "AdaptiveAvgPool2d-353            [-1, 960, 1, 1]               0\n",
            "          Conv2d-354             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-355             [-1, 40, 1, 1]               0\n",
            "          Conv2d-356            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-357            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-358            [-1, 960, 4, 4]               0\n",
            "          Conv2d-359            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-360            [-1, 160, 4, 4]             320\n",
            " StochasticDepth-361            [-1, 160, 4, 4]               0\n",
            "          MBConv-362            [-1, 160, 4, 4]               0\n",
            "          Conv2d-363            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-364            [-1, 960, 4, 4]           1,920\n",
            "            SiLU-365            [-1, 960, 4, 4]               0\n",
            "          Conv2d-366            [-1, 960, 2, 2]          24,000\n",
            "     BatchNorm2d-367            [-1, 960, 2, 2]           1,920\n",
            "            SiLU-368            [-1, 960, 2, 2]               0\n",
            "         Dropout-369            [-1, 960, 2, 2]               0\n",
            "AdaptiveAvgPool2d-370            [-1, 960, 1, 1]               0\n",
            "          Conv2d-371             [-1, 40, 1, 1]          38,440\n",
            "            SiLU-372             [-1, 40, 1, 1]               0\n",
            "          Conv2d-373            [-1, 960, 1, 1]          39,360\n",
            "         Sigmoid-374            [-1, 960, 1, 1]               0\n",
            "SqueezeExcitation-375            [-1, 960, 2, 2]               0\n",
            "          Conv2d-376            [-1, 272, 2, 2]         261,120\n",
            "     BatchNorm2d-377            [-1, 272, 2, 2]             544\n",
            "          MBConv-378            [-1, 272, 2, 2]               0\n",
            "          Conv2d-379           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-380           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-381           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-382           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-383           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-384           [-1, 1632, 2, 2]               0\n",
            "         Dropout-385           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-386           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-387             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-388             [-1, 68, 1, 1]               0\n",
            "          Conv2d-389           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-390           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-391           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-392            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-393            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-394            [-1, 272, 2, 2]               0\n",
            "          MBConv-395            [-1, 272, 2, 2]               0\n",
            "          Conv2d-396           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-397           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-398           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-399           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-400           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-401           [-1, 1632, 2, 2]               0\n",
            "         Dropout-402           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-403           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-404             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-405             [-1, 68, 1, 1]               0\n",
            "          Conv2d-406           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-407           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-408           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-409            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-410            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-411            [-1, 272, 2, 2]               0\n",
            "          MBConv-412            [-1, 272, 2, 2]               0\n",
            "          Conv2d-413           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-414           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-415           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-416           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-417           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-418           [-1, 1632, 2, 2]               0\n",
            "         Dropout-419           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-420           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-421             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-422             [-1, 68, 1, 1]               0\n",
            "          Conv2d-423           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-424           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-425           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-426            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-427            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-428            [-1, 272, 2, 2]               0\n",
            "          MBConv-429            [-1, 272, 2, 2]               0\n",
            "          Conv2d-430           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-431           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-432           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-433           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-434           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-435           [-1, 1632, 2, 2]               0\n",
            "         Dropout-436           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-437           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-438             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-439             [-1, 68, 1, 1]               0\n",
            "          Conv2d-440           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-441           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-442           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-443            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-444            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-445            [-1, 272, 2, 2]               0\n",
            "          MBConv-446            [-1, 272, 2, 2]               0\n",
            "          Conv2d-447           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-448           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-449           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-450           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-451           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-452           [-1, 1632, 2, 2]               0\n",
            "         Dropout-453           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-454           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-455             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-456             [-1, 68, 1, 1]               0\n",
            "          Conv2d-457           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-458           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-459           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-460            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-461            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-462            [-1, 272, 2, 2]               0\n",
            "          MBConv-463            [-1, 272, 2, 2]               0\n",
            "          Conv2d-464           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-465           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-466           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-467           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-468           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-469           [-1, 1632, 2, 2]               0\n",
            "         Dropout-470           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-471           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-472             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-473             [-1, 68, 1, 1]               0\n",
            "          Conv2d-474           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-475           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-476           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-477            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-478            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-479            [-1, 272, 2, 2]               0\n",
            "          MBConv-480            [-1, 272, 2, 2]               0\n",
            "          Conv2d-481           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-482           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-483           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-484           [-1, 1632, 2, 2]          40,800\n",
            "     BatchNorm2d-485           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-486           [-1, 1632, 2, 2]               0\n",
            "         Dropout-487           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-488           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-489             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-490             [-1, 68, 1, 1]               0\n",
            "          Conv2d-491           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-492           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-493           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-494            [-1, 272, 2, 2]         443,904\n",
            "     BatchNorm2d-495            [-1, 272, 2, 2]             544\n",
            " StochasticDepth-496            [-1, 272, 2, 2]               0\n",
            "          MBConv-497            [-1, 272, 2, 2]               0\n",
            "          Conv2d-498           [-1, 1632, 2, 2]         443,904\n",
            "     BatchNorm2d-499           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-500           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-501           [-1, 1632, 2, 2]          14,688\n",
            "     BatchNorm2d-502           [-1, 1632, 2, 2]           3,264\n",
            "            SiLU-503           [-1, 1632, 2, 2]               0\n",
            "         Dropout-504           [-1, 1632, 2, 2]               0\n",
            "AdaptiveAvgPool2d-505           [-1, 1632, 1, 1]               0\n",
            "          Conv2d-506             [-1, 68, 1, 1]         111,044\n",
            "            SiLU-507             [-1, 68, 1, 1]               0\n",
            "          Conv2d-508           [-1, 1632, 1, 1]         112,608\n",
            "         Sigmoid-509           [-1, 1632, 1, 1]               0\n",
            "SqueezeExcitation-510           [-1, 1632, 2, 2]               0\n",
            "          Conv2d-511            [-1, 448, 2, 2]         731,136\n",
            "     BatchNorm2d-512            [-1, 448, 2, 2]             896\n",
            "          MBConv-513            [-1, 448, 2, 2]               0\n",
            "          Conv2d-514           [-1, 2688, 2, 2]       1,204,224\n",
            "     BatchNorm2d-515           [-1, 2688, 2, 2]           5,376\n",
            "            SiLU-516           [-1, 2688, 2, 2]               0\n",
            "          Conv2d-517           [-1, 2688, 2, 2]          24,192\n",
            "     BatchNorm2d-518           [-1, 2688, 2, 2]           5,376\n",
            "            SiLU-519           [-1, 2688, 2, 2]               0\n",
            "         Dropout-520           [-1, 2688, 2, 2]               0\n",
            "AdaptiveAvgPool2d-521           [-1, 2688, 1, 1]               0\n",
            "          Conv2d-522            [-1, 112, 1, 1]         301,168\n",
            "            SiLU-523            [-1, 112, 1, 1]               0\n",
            "          Conv2d-524           [-1, 2688, 1, 1]         303,744\n",
            "         Sigmoid-525           [-1, 2688, 1, 1]               0\n",
            "SqueezeExcitation-526           [-1, 2688, 2, 2]               0\n",
            "          Conv2d-527            [-1, 448, 2, 2]       1,204,224\n",
            "     BatchNorm2d-528            [-1, 448, 2, 2]             896\n",
            " StochasticDepth-529            [-1, 448, 2, 2]               0\n",
            "          MBConv-530            [-1, 448, 2, 2]               0\n",
            "          Conv2d-531           [-1, 1792, 2, 2]         802,816\n",
            "     BatchNorm2d-532           [-1, 1792, 2, 2]           3,584\n",
            "            SiLU-533           [-1, 1792, 2, 2]               0\n",
            "AdaptiveAvgPool2d-534           [-1, 1792, 1, 1]               0\n",
            "        Identity-535                 [-1, 1792]               0\n",
            "    EfficientNet-536                 [-1, 1792]               0\n",
            "          Linear-537                    [-1, 3]           5,379\n",
            "          Linear-538                   [-1, 89]         159,577\n",
            "================================================================\n",
            "Total params: 17,713,572\n",
            "Trainable params: 17,713,572\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 40.70\n",
            "Params size (MB): 67.57\n",
            "Estimated Total Size (MB): 108.32\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Load best saved semi frozen model\n",
        "effnetb4_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_EffnetB4_semi_frozen_SuperClass.pth')['model_state_dict'], strict = True)\n",
        "\n",
        "\n",
        "# Training the model (with everything unfrozen)\n",
        "for param in effnetb4_joint_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "summary(effnetb4_joint_model, (3, 64, 64))\n",
        "\n",
        "trainable_params = []\n",
        "\n",
        "for name, param in effnetb4_joint_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name)\n",
        "        trainable_params.append(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bhnW_fmxQgxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2ff994-7157-456f-a665-a0309b8f4a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 train: 100%|██████████| 495/495 [01:05<00:00,  7.52batch/s, loss=10.7, sub_class_accuracy=0, super_class_accuracy=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 train Super Class loss: 4.02099327058609 Super Class acc: 0.6438226103782654\n",
            "Sub Class loss: 7.618277358671461 Sub Class acc: 0.09645022451877594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 val: 100%|██████████| 23/23 [00:00<00:00, 23.58batch/s, loss=9.5, sub_class_accuracy=0.0333, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 val Super Class loss: 3.430951033447354 Super Class acc: 0.7166212201118469\n",
            "Sub Class loss: 7.502837412363827 Sub Class acc: 0.11852861195802689\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 train: 100%|██████████| 495/495 [01:05<00:00,  7.58batch/s, loss=11.3, sub_class_accuracy=0.0417, super_class_accuracy=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 train Super Class loss: 3.5604214757123698 Super Class acc: 0.6958059668540955\n",
            "Sub Class loss: 7.1811452222749885 Sub Class acc: 0.11975745111703873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 val: 100%|██████████| 23/23 [00:01<00:00, 22.94batch/s, loss=10.2, sub_class_accuracy=0.0667, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 val Super Class loss: 3.1060029700276637 Super Class acc: 0.7506811618804932\n",
            "Sub Class loss: 7.08219571464393 Sub Class acc: 0.13351498544216156\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 train: 100%|██████████| 495/495 [01:05<00:00,  7.54batch/s, loss=9.34, sub_class_accuracy=0.208, super_class_accuracy=0.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 train Super Class loss: 3.268792617495702 Super Class acc: 0.7258085012435913\n",
            "Sub Class loss: 6.795101993429715 Sub Class acc: 0.14312784373760223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 val: 100%|██████████| 23/23 [00:01<00:00, 22.77batch/s, loss=9.82, sub_class_accuracy=0.0667, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 val Super Class loss: 2.587554738615774 Super Class acc: 0.7956402897834778\n",
            "Sub Class loss: 6.731212648448892 Sub Class acc: 0.15940053761005402\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 train: 100%|██████████| 495/495 [01:05<00:00,  7.57batch/s, loss=9.07, sub_class_accuracy=0.25, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 train Super Class loss: 3.07387406798009 Super Class acc: 0.7481051087379456\n",
            "Sub Class loss: 6.508481665896069 Sub Class acc: 0.1707933247089386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 val: 100%|██████████| 23/23 [00:00<00:00, 23.64batch/s, loss=9.46, sub_class_accuracy=0.0667, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 val Super Class loss: 2.5924078381191484 Super Class acc: 0.7970027327537537\n",
            "Sub Class loss: 6.768824703362072 Sub Class acc: 0.1607629358768463\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 train: 100%|██████████| 495/495 [01:05<00:00,  7.54batch/s, loss=10.2, sub_class_accuracy=0.0833, super_class_accuracy=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 train Super Class loss: 2.887307865382325 Super Class acc: 0.7662960886955261\n",
            "Sub Class loss: 6.204998742817266 Sub Class acc: 0.1906265765428543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 val: 100%|██████████| 23/23 [00:00<00:00, 23.00batch/s, loss=8.17, sub_class_accuracy=0.133, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 val Super Class loss: 2.4312196883096355 Super Class acc: 0.8092643022537231\n",
            "Sub Class loss: 6.442206289203031 Sub Class acc: 0.19209809601306915\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 train: 100%|██████████| 495/495 [01:06<00:00,  7.46batch/s, loss=8.39, sub_class_accuracy=0.292, super_class_accuracy=0.792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 train Super Class loss: 2.713121446080133 Super Class acc: 0.7825290560722351\n",
            "Sub Class loss: 5.950378733370387 Sub Class acc: 0.21286003291606903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 val: 100%|██████████| 23/23 [00:00<00:00, 23.08batch/s, loss=8.25, sub_class_accuracy=0.133, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 val Super Class loss: 2.4231099371851625 Super Class acc: 0.7956402897834778\n",
            "Sub Class loss: 6.339704232904502 Sub Class acc: 0.19618529081344604\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 train: 100%|██████████| 495/495 [01:06<00:00,  7.46batch/s, loss=6.16, sub_class_accuracy=0.292, super_class_accuracy=0.958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 train Super Class loss: 2.548984842823876 Super Class acc: 0.7918140292167664\n",
            "Sub Class loss: 5.582345724949155 Sub Class acc: 0.24696816504001617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 val: 100%|██████████| 23/23 [00:01<00:00, 22.60batch/s, loss=8.12, sub_class_accuracy=0.2, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 val Super Class loss: 2.2772389516356206 Super Class acc: 0.8188011050224304\n",
            "Sub Class loss: 6.25699603655033 Sub Class acc: 0.21389645338058472\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 train: 100%|██████████| 495/495 [01:06<00:00,  7.46batch/s, loss=6.77, sub_class_accuracy=0.208, super_class_accuracy=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 train Super Class loss: 2.4159726130805756 Super Class acc: 0.8077311515808105\n",
            "Sub Class loss: 5.27549725798057 Sub Class acc: 0.2786760926246643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 val: 100%|██████████| 23/23 [00:01<00:00, 21.98batch/s, loss=8.74, sub_class_accuracy=0.167, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 val Super Class loss: 2.166351167236427 Super Class acc: 0.8501362204551697\n",
            "Sub Class loss: 6.118600643947923 Sub Class acc: 0.24250680208206177\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 train: 100%|██████████| 495/495 [01:05<00:00,  7.51batch/s, loss=6.91, sub_class_accuracy=0.417, super_class_accuracy=0.792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 train Super Class loss: 2.1995323004898486 Super Class acc: 0.8221955299377441\n",
            "Sub Class loss: 4.906484173306797 Sub Class acc: 0.3135421872138977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 val: 100%|██████████| 23/23 [00:00<00:00, 23.01batch/s, loss=8.41, sub_class_accuracy=0.167, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 val Super Class loss: 2.051352715216151 Super Class acc: 0.8419618606567383\n",
            "Sub Class loss: 6.094914192074976 Sub Class acc: 0.23705722391605377\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 train: 100%|██████████| 495/495 [01:06<00:00,  7.44batch/s, loss=6.71, sub_class_accuracy=0.375, super_class_accuracy=0.792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 train Super Class loss: 2.1002539675334537 Super Class acc: 0.8355861306190491\n",
            "Sub Class loss: 4.645106365007243 Sub Class acc: 0.34594491124153137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 val: 100%|██████████| 23/23 [00:00<00:00, 23.13batch/s, loss=7.88, sub_class_accuracy=0.2, super_class_accuracy=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 val Super Class loss: 1.9429915944464524 Super Class acc: 0.8433242440223694\n",
            "Sub Class loss: 6.218628073908003 Sub Class acc: 0.24795639514923096\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 train: 100%|██████████| 495/495 [01:05<00:00,  7.50batch/s, loss=5.09, sub_class_accuracy=0.5, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 train Super Class loss: 1.901039440126477 Super Class acc: 0.8498610258102417\n",
            "Sub Class loss: 4.210011838722132 Sub Class acc: 0.3933173418045044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 val: 100%|██████████| 23/23 [00:01<00:00, 22.94batch/s, loss=8.5, sub_class_accuracy=0.233, super_class_accuracy=0.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 val Super Class loss: 1.9861394069500125 Super Class acc: 0.863760232925415\n",
            "Sub Class loss: 6.263245204488978 Sub Class acc: 0.25340598821640015\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 train: 100%|██████████| 495/495 [01:05<00:00,  7.53batch/s, loss=5.31, sub_class_accuracy=0.458, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 train Super Class loss: 1.6978149519628079 Super Class acc: 0.8669782876968384\n",
            "Sub Class loss: 3.7997997316704546 Sub Class acc: 0.43803688883781433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 val: 100%|██████████| 23/23 [00:01<00:00, 22.88batch/s, loss=9.8, sub_class_accuracy=0.267, super_class_accuracy=0.867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 val Super Class loss: 2.2437100693055654 Super Class acc: 0.8433242440223694\n",
            "Sub Class loss: 6.562466339454339 Sub Class acc: 0.25476840138435364\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 train: 100%|██████████| 495/495 [01:05<00:00,  7.55batch/s, loss=4.89, sub_class_accuracy=0.458, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 train Super Class loss: 1.552081133166969 Super Class acc: 0.8789161443710327\n",
            "Sub Class loss: 3.4615510305170463 Sub Class acc: 0.4870515465736389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 val: 100%|██████████| 23/23 [00:01<00:00, 22.60batch/s, loss=8.94, sub_class_accuracy=0.3, super_class_accuracy=0.833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 val Super Class loss: 2.1756047290579823 Super Class acc: 0.8446866273880005\n",
            "Sub Class loss: 6.668116500657001 Sub Class acc: 0.2752043604850769\n",
            "--------------------\n",
            "Best Super Class val acc: 0.863760232925415\n",
            "Best Sub Class val acc: 0.2752043604850769\n",
            "Average Time taken for an epoch: 67.25677967071533 sec\n"
          ]
        }
      ],
      "source": [
        "epochs = 13\n",
        "initial_epoch = 12\n",
        "learning_rate = 8e-4\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "fit_classifier(\n",
        "    effnetb4_joint_model, \n",
        "    train_loader=train_loader, \n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer, \n",
        "    loss_func=loss_func, \n",
        "    epochs=epochs,\n",
        "    initial_epoch=initial_epoch, \n",
        "    device=device,\n",
        "    name='EnsembleJoint_EffnetB4_unfrozen'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cahRG6TAQgxp"
      },
      "source": [
        "#### Accuracy on Augmented Validation dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx0ZXbzuQgxp"
      },
      "source": [
        "##### Kaggle Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tZ_JlgxFQgxp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class KaggleValDataset(nn.Module):\n",
        "    def __init__(self, mode = 'train', phflip = 0, pcoarse = 0):\n",
        "        super(KaggleValDataset, self).__init__()\n",
        "        self.mode = mode\n",
        "        \n",
        "        self.phflip = phflip\n",
        "        self.pcoarse = pcoarse\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.dataset = train_data\n",
        "        else:\n",
        "            self.dataset = val_data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.dataset[idx][0]\n",
        "        img = cv2.imread(os.path.join('train_shuffle_64', img_name))   \n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    #convert image from BGR to RGB format\n",
        "\n",
        "        super_class = torch.tensor(self.dataset[idx][1], dtype = torch.float32)\n",
        "        sub_class = torch.tensor(self.dataset[idx][2], dtype = torch.float32)\n",
        "\n",
        "        apply_transform = self.transform_data()\n",
        "        image = apply_transform(image = img)['image']\n",
        "\n",
        "        return image, super_class, sub_class\n",
        "\n",
        "    def transform_data(self):\n",
        "        transform_func = A.Compose(\n",
        "        [   \n",
        "            A.HorizontalFlip(p = self.phflip),\n",
        "            A.CoarseDropout(max_holes=8, max_height=4, max_width=4, min_holes=8, min_height=4, min_width=4, p=self.pcoarse),\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1),\n",
        "            ToTensorV2(p=1),\n",
        "        ])\n",
        "    \n",
        "        return transform_func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOoilRHvQgxp"
      },
      "source": [
        "##### Kaggle Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "js2D-MhdQgxp"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "verify_val_dataset_1 = KaggleValDataset(mode='val', phflip = 0, pcoarse = 0)\n",
        "verify_val_dataset_2 = KaggleValDataset(mode='val', phflip = 1, pcoarse = 0)\n",
        "verify_val_dataset_3 = KaggleValDataset(mode='val', phflip = 0, pcoarse = 1)\n",
        "\n",
        "verify_val_loader_1 = DataLoader(dataset = verify_val_dataset_1, batch_size = 32, shuffle = False)\n",
        "verify_val_loader_2 = DataLoader(dataset = verify_val_dataset_2, batch_size = 32, shuffle = False)\n",
        "verify_val_loader_3 = DataLoader(dataset = verify_val_dataset_3, batch_size = 32, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9oTBqEaTgNt"
      },
      "source": [
        "##### Super Class predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "lTGJjXwmTij5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02d022e-a1f0-4094-cf0a-a7a507ac710a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence and Accuracies of model 1 on data 1:\n",
            "0.9585612639901047 0.8732970027247956\n",
            "0.8405570698681698 0.12670299727520437\n",
            "======================\n",
            "###################\n",
            "Confidence and Accuracies of model 2 on data 1:\n",
            "0.9255251978004017 0.8637602179836512\n",
            "0.7409778049588204 0.1362397820163488\n",
            "======================\n",
            "###################\n",
            "Confidence and Accuracies of model 3 on data 1:\n",
            "0.9461072634275143 0.885558583106267\n",
            "0.7834743069750922 0.11444141689373297\n",
            "======================\n",
            "###################\n",
            "Overall Confidence and Accuracies:\n",
            "2.7381769889041396 0.8978201634877384\n",
            "1.9964302508036296 0.10217983651226158\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load best saved Super Class models\n",
        "swin_t_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_SwinT_unfrozen_SuperClass.pth')['model_state_dict'], strict = True)\n",
        "effnetb3_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_EffnetB3_unfrozen_SuperClass.pth')['model_state_dict'], strict = True)\n",
        "effnetb4_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_EffnetB4_unfrozen_SuperClass.pth')['model_state_dict'], strict = True)\n",
        "\n",
        "\n",
        "softmax_layer = nn.Softmax(dim = 1)\n",
        "subclasses = pd.read_csv(\"./Released_Data/sub_classes_mapping.csv\").to_numpy()\n",
        "superclasses = pd.read_csv(\"./Released_Data/super_classes_mapping.csv\").to_numpy()\n",
        "\n",
        "sub_pred_labels = [['predictions']]\n",
        "super_pred_labels = [['predictions']]\n",
        "\n",
        "overall_right_conf = 0.\n",
        "overall_right_imgs = 0.\n",
        "\n",
        "overall_wrong_conf = 0.\n",
        "overall_wrong_imgs = 0.\n",
        "\n",
        "total_conf = torch.zeros((len(verify_val_loader_1), 32, 3))\n",
        "total_conf = total_conf.to(device, non_blocking=True)\n",
        "\n",
        "model_count = 0\n",
        "\n",
        "for verify_model in [swin_t_joint_model, effnetb4_joint_model, effnetb3_joint_model]:\n",
        "    model_count += 1\n",
        "    count = 0\n",
        "    for val_loader in [verify_val_loader_1]:\n",
        "        count += 1\n",
        "\n",
        "        avg_right_conf = 0.\n",
        "        right_imgs = 0\n",
        "        \n",
        "        avg_wrong_conf = 0.\n",
        "        wrong_imgs = 0\n",
        "\n",
        "        for batch_idx, (images, super_labels, sub_labels) in enumerate(val_loader):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                super_outs, sub_outs = verify_model(images)\n",
        "                super_outs = softmax_layer(super_outs)\n",
        "                \n",
        "                total_conf[batch_idx][:super_outs.shape[0]] = torch.add(total_conf[batch_idx][:super_outs.shape[0]], super_outs)\n",
        "\n",
        "                max_super_values = torch.max(super_outs, dim = 1)[0]\n",
        "                max_super_idxs = torch.max(super_outs, dim = 1)[1]\n",
        "\n",
        "                for idx in range(super_labels.shape[0]):\n",
        "                    if max_super_idxs[idx] == super_labels[idx]:\n",
        "                        avg_right_conf += max_super_values[idx].item()\n",
        "                        right_imgs += 1\n",
        "                    else:\n",
        "                        avg_wrong_conf += max_super_values[idx].item()\n",
        "                        wrong_imgs += 1\n",
        "                        #print(torch.topk(sub_outs[idx], k=3))\n",
        "                    \n",
        "                    if count == 1 and model_count == 3:\n",
        "                        overall_max_super_values = torch.max(total_conf[batch_idx], dim = 1)[0]\n",
        "                        overall_max_super_idxs = torch.max(total_conf[batch_idx], dim = 1)[1]\n",
        "                        \n",
        "                        if overall_max_super_idxs[idx] == super_labels[idx]:\n",
        "                            overall_right_conf += (overall_max_super_values[idx].item())/count\n",
        "                            overall_right_imgs += 1\n",
        "                        else:\n",
        "                            overall_wrong_conf += (overall_max_super_values[idx].item())/count\n",
        "                            overall_wrong_imgs += 1\n",
        "                            #print(torch.topk(sub_outs[idx], k=3))\n",
        "\n",
        "                \n",
        "        print(f\"Confidence and Accuracies of model {model_count} on data {count}:\")\n",
        "        print(avg_right_conf/right_imgs, right_imgs/(right_imgs + wrong_imgs))\n",
        "        print(avg_wrong_conf/wrong_imgs, wrong_imgs/(right_imgs + wrong_imgs))\n",
        "        print(\"======================\")\n",
        "    \n",
        "    print(\"###################\")\n",
        "\n",
        "print(\"Overall Confidence and Accuracies:\")\n",
        "print(overall_right_conf/overall_right_imgs, overall_right_imgs/(overall_right_imgs + overall_wrong_imgs))\n",
        "print(overall_wrong_conf/overall_wrong_imgs, overall_wrong_imgs/(overall_right_imgs + overall_wrong_imgs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7KMbItuQgxp"
      },
      "source": [
        "##### Sub Class predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PENrYlsSQgxp",
        "outputId": "ddd2874c-6869-438f-d026-c1dfccc8da14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence and Accuracies of model 1 on data 1:\n",
            "0.7169678135975903 0.2779291553133515\n",
            "0.5924883896871558 0.7220708446866485\n",
            "======================\n",
            "###################\n",
            "Confidence and Accuracies of model 2 on data 1:\n",
            "0.6497578183716198 0.2888283378746594\n",
            "0.4626795372629531 0.7111716621253406\n",
            "======================\n",
            "###################\n",
            "Confidence and Accuracies of model 3 on data 1:\n",
            "0.6448337555595554 0.27520435967302453\n",
            "0.48954653150324984 0.7247956403269755\n",
            "======================\n",
            "###################\n",
            "Overall Confidence and Accuracies:\n",
            "0.5251617307756457 0.3474114441416894\n",
            "0.3863998849771881 0.6525885558583107\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load best saved Sub Class models\n",
        "swin_t_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_SwinT_unfrozen_SubClass.pth')['model_state_dict'], strict = True)\n",
        "effnetb3_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_EffnetB3_unfrozen_SubClass.pth')['model_state_dict'], strict = True)\n",
        "effnetb4_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_EffnetB4_unfrozen_SubClass.pth')['model_state_dict'], strict = True)\n",
        "\n",
        "\n",
        "softmax_layer = nn.Softmax(dim = 1)\n",
        "subclasses = pd.read_csv(\"./Released_Data/sub_classes_mapping.csv\").to_numpy()\n",
        "superclasses = pd.read_csv(\"./Released_Data/super_classes_mapping.csv\").to_numpy()\n",
        "\n",
        "sub_pred_labels = [['predictions']]\n",
        "super_pred_labels = [['predictions']]\n",
        "\n",
        "overall_right_conf = 0.\n",
        "overall_right_imgs = 0.\n",
        "\n",
        "overall_wrong_conf = 0.\n",
        "overall_wrong_imgs = 0.\n",
        "\n",
        "total_conf = torch.zeros((len(verify_val_loader_1), 32, 89))\n",
        "total_conf = total_conf.to(device, non_blocking=True)\n",
        "\n",
        "model_count = 0\n",
        "\n",
        "for verify_model in [swin_t_joint_model, effnetb3_joint_model, effnetb4_joint_model]:\n",
        "    model_count += 1\n",
        "    count = 0\n",
        "    for val_loader in [verify_val_loader_1]:\n",
        "        count += 1\n",
        "\n",
        "        avg_right_conf = 0.\n",
        "        right_imgs = 0\n",
        "        \n",
        "        avg_wrong_conf = 0.\n",
        "        wrong_imgs = 0\n",
        "\n",
        "        for batch_idx, (images, super_labels, sub_labels) in enumerate(val_loader):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                super_outs, sub_outs = verify_model(images)\n",
        "                \n",
        "                sub_outs = softmax_layer(sub_outs)\n",
        "                \n",
        "                total_conf[batch_idx][:sub_outs.shape[0]] = torch.add(total_conf[batch_idx][:sub_outs.shape[0]], sub_outs)\n",
        "\n",
        "                max_sub_values = torch.max(sub_outs, dim = 1)[0]\n",
        "                max_sub_idxs = torch.max(sub_outs, dim = 1)[1]\n",
        "\n",
        "                for idx in range(sub_labels.shape[0]):\n",
        "                    if max_sub_idxs[idx] == sub_labels[idx]:\n",
        "                        avg_right_conf += max_sub_values[idx].item()\n",
        "                        right_imgs += 1\n",
        "                    else:\n",
        "                        avg_wrong_conf += max_sub_values[idx].item()\n",
        "                        wrong_imgs += 1\n",
        "                        #print(torch.topk(sub_outs[idx], k=3))\n",
        "                    \n",
        "                    if count == 1 and model_count == 3:\n",
        "                        overall_max_sub_values = torch.max(total_conf[batch_idx], dim = 1)[0]\n",
        "                        overall_max_sub_idxs = torch.max(total_conf[batch_idx], dim = 1)[1]\n",
        "                        \n",
        "                        if overall_max_sub_idxs[idx] == sub_labels[idx]:\n",
        "                            overall_right_conf += (overall_max_sub_values[idx].item())/(count * model_count)\n",
        "                            overall_right_imgs += 1\n",
        "                        else:\n",
        "                            overall_wrong_conf += (overall_max_sub_values[idx].item())/(count * model_count)\n",
        "                            overall_wrong_imgs += 1\n",
        "                            #print(torch.topk(sub_outs[idx], k=3))\n",
        "\n",
        "                \n",
        "        print(f\"Confidence and Accuracies of model {model_count} on data {count}:\")\n",
        "        print(avg_right_conf/right_imgs, right_imgs/(right_imgs + wrong_imgs))\n",
        "        print(avg_wrong_conf/wrong_imgs, wrong_imgs/(right_imgs + wrong_imgs))\n",
        "        print(\"======================\")\n",
        "    \n",
        "    print(\"###################\")\n",
        "\n",
        "print(\"Overall Confidence and Accuracies:\")\n",
        "print(overall_right_conf/overall_right_imgs, overall_right_imgs/(overall_right_imgs + overall_wrong_imgs))\n",
        "print(overall_wrong_conf/overall_wrong_imgs, overall_wrong_imgs/(overall_right_imgs + overall_wrong_imgs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUNhh06VodaA"
      },
      "source": [
        "#### Test Dataset Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnfxs-NZodaB"
      },
      "source": [
        "##### Kaggle Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "i__f0ijGodaB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class KaggleTestDataset(nn.Module):\n",
        "    def __init__(self, phflip = 0, pcoarse = 0):\n",
        "        super(KaggleTestDataset, self).__init__()\n",
        "        self.dataset = [('./test_shuffle/' + str(i) + '.jpg') for i in range(0, 9127)]\n",
        "\n",
        "        self.phflip = phflip\n",
        "        self.pcoarse = pcoarse\n",
        "        # self.prot = prot\n",
        "        # self.ppersp = ppersp\n",
        "         \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.dataset[idx]\n",
        "        img = cv2.imread(img_name)\n",
        "        #for now resize the image to 64 x 64 using CUBIC interpolation\n",
        "        img = cv2.resize(img, (64, 64), interpolation = cv2.INTER_CUBIC)   \n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    #convert image from BGR to RGB format\n",
        "\n",
        "        apply_transform = self.transform_data()\n",
        "        image = apply_transform(image = img)['image']\n",
        "\n",
        "        return image\n",
        "\n",
        "    def transform_data(self):\n",
        "        transform_func = A.Compose(\n",
        "        [   \n",
        "            A.HorizontalFlip(p = self.phflip),\n",
        "            A.CoarseDropout(max_holes=8, max_height=4, max_width=4, min_holes=8, min_height=4, min_width=4, p=self.pcoarse),\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1),\n",
        "            ToTensorV2(p=1),\n",
        "        ])\n",
        "    \n",
        "        return transform_func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGrWsccAodaB"
      },
      "source": [
        "##### Kaggle Test Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "RnS5JBGjodaB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "test_dataset_1 = KaggleTestDataset(phflip = 0, pcoarse = 0)\n",
        "test_dataset_2 = KaggleTestDataset(phflip = 1, pcoarse = 0)\n",
        "test_dataset_3 = KaggleTestDataset(phflip = 0, pcoarse = 1)\n",
        "    \n",
        "test_loader_1 = DataLoader(dataset = test_dataset_1, batch_size = 32, shuffle = False)\n",
        "test_loader_2 = DataLoader(dataset = test_dataset_2, batch_size = 32, shuffle = False)\n",
        "test_loader_3 = DataLoader(dataset = test_dataset_3, batch_size = 32, shuffle = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfT5SuXBodaB"
      },
      "source": [
        "##### Sub Class predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "sOVyIxZoodaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41d457a-cc28-4584-d512-afe97cec314f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['predictions'], ['Scotch terrier, Scottish terrier, Scottie'], ['American alligator, Alligator mississipiensis'], ['novel'], ['novel'], ['ptarmigan'], ['European fire salamander, Salamandra salamandra'], ['beagle'], ['hognose snake, puff adder, sand viper'], ['hognose snake, puff adder, sand viper']]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import csv\n",
        "\n",
        "# Load best saved Sub Class models\n",
        "swin_t_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_SwinT_unfrozen_SubClass.pth')['model_state_dict'], strict = True)\n",
        "effnetb3_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_EffnetB3_unfrozen_SubClass.pth')['model_state_dict'], strict = True)\n",
        "effnetb4_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_EffnetB4_unfrozen_SubClass.pth')['model_state_dict'], strict = True)\n",
        "\n",
        "softmax_layer = nn.Softmax(dim = 1)\n",
        "subclasses = pd.read_csv(\"./Released_Data/sub_classes_mapping.csv\").to_numpy()\n",
        "superclasses = pd.read_csv(\"./Released_Data/super_classes_mapping.csv\").to_numpy()\n",
        "\n",
        "sub_pred_labels = [['predictions']]\n",
        "super_pred_labels = [['predictions']]\n",
        "\n",
        "overall_right_conf = 0.\n",
        "overall_right_imgs = 0.\n",
        "\n",
        "overall_wrong_conf = 0.\n",
        "overall_wrong_imgs = 0.\n",
        "\n",
        "total_conf = torch.zeros((len(test_loader_1), 32, 89))\n",
        "total_conf = total_conf.to(device, non_blocking=True)\n",
        "\n",
        "model_count = 0\n",
        "\n",
        "for verify_model in [swin_t_joint_model, effnetb4_joint_model, effnetb3_joint_model]:\n",
        "    model_count += 1\n",
        "    count = 0\n",
        "    for test_loader in [test_loader_1]:\n",
        "        count += 1\n",
        "\n",
        "        avg_right_conf = 0.\n",
        "        right_imgs = 0\n",
        "        \n",
        "        avg_wrong_conf = 0.\n",
        "        wrong_imgs = 0\n",
        "\n",
        "        for batch_idx, images in enumerate(test_loader):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                super_outs, sub_outs = verify_model(images)\n",
        "                sub_outs = softmax_layer(sub_outs)\n",
        "\n",
        "                total_conf[batch_idx][:sub_outs.shape[0]] = torch.add(total_conf[batch_idx][:sub_outs.shape[0]], sub_outs)\n",
        "\n",
        "                if count == 1 and model_count == 3:\n",
        "                    total_conf[batch_idx][:sub_outs.shape[0]] = total_conf[batch_idx][:sub_outs.shape[0]]/(model_count * count)\n",
        "                    #print(torch.topk(total_conf[batch_idx][:10]/(model_count * count), k=3))\n",
        "                    \n",
        "                    overall_sub_preds = torch.argmax(total_conf[batch_idx][:sub_outs.shape[0]], dim = 1)\n",
        "                    #overall_sub_values = torch.max(total_conf[batch_idx][:sub_outs.shape[0]], dim = 1)[0]\n",
        "                    \n",
        "                    overall_sub_values = torch.topk(total_conf[batch_idx][:sub_outs.shape[0]], dim = 1, k = 2)[0]\n",
        "\n",
        "                    sub_values1 = overall_sub_values[:, 0]\n",
        "                    sub_values2 = overall_sub_values[:, 1]\n",
        "\n",
        "                    overall_sub_preds = torch.where((sub_values1 > 0.35), overall_sub_preds, 89)\n",
        "                    #overall_sub_preds = torch.where((sub_values1 > 0.35) | (torch.sub(sub_values1, sub_values2) > 0.10), overall_sub_preds, 89)\n",
        "\n",
        "                    for i in range(len(overall_sub_preds)):\n",
        "                        sub_pred_labels.append([subclasses[overall_sub_preds[i]][1]])\n",
        "\n",
        "\n",
        "print(sub_pred_labels[:10])\n",
        "\n",
        "with open('ensemble_subclass_preds.csv', 'w') as f:\n",
        "    # using csv.writer method from CSV package\n",
        "    write = csv.writer(f)\n",
        "    write.writerows(sub_pred_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Super Class predictions"
      ],
      "metadata": {
        "id": "HzaBCmoIr-bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import csv\n",
        "\n",
        "# Load best saved Sub Class models\n",
        "swin_t_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_SwinT_unfrozen_SuperClass.pth')['model_state_dict'], strict = True)\n",
        "effnetb3_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_EffnetB3_unfrozen_SuperClass.pth')['model_state_dict'], strict = True)\n",
        "effnetb4_joint_model.load_state_dict(torch.load('./models/EnsembleJoint_EffnetB4_unfrozen_SuperClass.pth')['model_state_dict'], strict = True)\n",
        "\n",
        "softmax_layer = nn.Softmax(dim = 1)\n",
        "subclasses = pd.read_csv(\"./Released_Data/sub_classes_mapping.csv\").to_numpy()\n",
        "superclasses = pd.read_csv(\"./Released_Data/super_classes_mapping.csv\").to_numpy()\n",
        "\n",
        "sub_pred_labels = [['predictions']]\n",
        "super_pred_labels = [['predictions']]\n",
        "\n",
        "overall_right_conf = 0.\n",
        "overall_right_imgs = 0.\n",
        "\n",
        "overall_wrong_conf = 0.\n",
        "overall_wrong_imgs = 0.\n",
        "\n",
        "total_conf = torch.zeros((len(test_loader_1), 32, 3))\n",
        "total_conf = total_conf.to(device, non_blocking=True)\n",
        "\n",
        "model_count = 0\n",
        "\n",
        "for verify_model in [swin_t_joint_model, effnetb4_joint_model, effnetb3_joint_model]:\n",
        "    model_count += 1\n",
        "    count = 0\n",
        "    for test_loader in [test_loader_1]:\n",
        "        count += 1\n",
        "\n",
        "        avg_right_conf = 0.\n",
        "        right_imgs = 0\n",
        "        \n",
        "        avg_wrong_conf = 0.\n",
        "        wrong_imgs = 0\n",
        "\n",
        "        for batch_idx, images in enumerate(test_loader):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                super_outs, sub_outs = verify_model(images)\n",
        "                super_outs = softmax_layer(super_outs)\n",
        "\n",
        "                total_conf[batch_idx][:super_outs.shape[0]] = torch.add(total_conf[batch_idx][:super_outs.shape[0]], super_outs)\n",
        "\n",
        "                if count == 1 and model_count == 3:\n",
        "                    total_conf[batch_idx][:super_outs.shape[0]] = total_conf[batch_idx][:super_outs.shape[0]]/(model_count * count)\n",
        "                    #print(torch.topk(total_conf[batch_idx][:10]/(model_count * count), k=3))\n",
        "                    \n",
        "                    overall_super_preds = torch.argmax(total_conf[batch_idx][:super_outs.shape[0]], dim = 1)\n",
        "\n",
        "                    for i in range(len(overall_super_preds)):\n",
        "                        super_pred_labels.append([superclasses[overall_super_preds[i]][1]])\n",
        "\n",
        "\n",
        "print(super_pred_labels[:10])\n",
        "\n",
        "with open('ensemble_superclass_preds.csv', 'w') as f:\n",
        "    # using csv.writer method from CSV package\n",
        "    write = csv.writer(f)\n",
        "    write.writerows(super_pred_labels)\n"
      ],
      "metadata": {
        "id": "Z0rgRldJsBIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4fec28-df9e-4a0e-c46d-0a9e3f4a15f0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['predictions'], ['dog'], ['reptile'], ['reptile'], ['bird'], ['bird'], ['reptile'], ['dog'], ['reptile'], ['reptile']]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QEa5nVtus5QK",
        "5pXRiu5Uons_",
        "LZvH3sFqQLdt",
        "dBK0TTcBbk5Q",
        "pfqYefGKdjCL",
        "1X-VJRUwWI81",
        "tVH4Elj1e3GL",
        "EmvpcuP6s0oF",
        "k6_XaVfgSbYm",
        "HrEdW8Li5-DY",
        "CI1Srqj-GkHs",
        "VZvrRhmddgyt",
        "lRVv9fvjeZz6",
        "C19BLYHTe-Ou",
        "LJEE0vzie-Ov",
        "dU-vX-oye-Ov",
        "-d5iaNWIe-Ov",
        "y3mo7w5VgW7J",
        "LKUvkzSVgW7J",
        "M2aFWCJKgW7K",
        "r2y4blwZgW7K",
        "hQuPdGAfgW7K",
        "gfEPjLV4gW7K",
        "kAucHCRNlR_F",
        "GJr43jtTlR_F",
        "A1sIjZN6lR_F",
        "YIZBvNR1lR_F",
        "NGZ4csVxlR_G",
        "FaZLlv9olR_G",
        "MzdSFPqWYwLW",
        "Bqix9GZ2Kto8",
        "a63Sqs0HKwNM",
        "dlgw7N4eK8Hl",
        "vENS2PxDO-vZ",
        "mDCStS5tO-vb",
        "eg9QjyfrO-vb",
        "Rzl8UoNdO-vb",
        "W5Ur1eLdO-vc",
        "fSkS1b4WO-vc",
        "OMFVoQ63eBlj",
        "1j7G1YPGZ9fh",
        "KwSwDhXscTkD",
        "69AU6pgKcTkD",
        "d0y5wmnmcTkD",
        "7LOrX8CFcTkE",
        "X-XWSNZOeC6q",
        "2e178FOdcTkD",
        "HIltngkfZ9fi",
        "hFwkSEVRZ9fi",
        "_J8GoWL1Z9fi",
        "5XBiyWJUZ9fj",
        "_nGMaaUtQgxl",
        "Y4on0849Qgxl",
        "Fc-1HwYeQgxm",
        "ybW80B0fQgxm",
        "bxefnWFyQgxm",
        "o4WfLUbpQgxm",
        "qz8OekxyQgxo",
        "ctPMWCbPQgxo",
        "6BFroJYrQgxn",
        "phXNyveLQgxn",
        "hpNUz5lfQgxn",
        "fIBUnCCiQgxn",
        "IccVf-iaQgxo",
        "cahRG6TAQgxp",
        "dUNhh06VodaA",
        "u64OpYHing9W",
        "WT8t1AXTpN5k",
        "Yyeus9repZE5",
        "RuYpl51jpce7",
        "3tK24jbJ-4EN",
        "M8zqXHV5-4EO",
        "sE-zmmb4-4ER",
        "3JY_M5Uy-4EU",
        "jR5_AnAi-4EV",
        "-jEAbOGg-4EW",
        "byyyBjfN-4Ea",
        "rU9xzS0xMjZe",
        "H7j7xvHvvsaD",
        "JZ6Txy5vv1zN",
        "5yehRAaqv1zW",
        "gHvLhREzv1zY",
        "MswdU56G5OoH",
        "trDRtbSU5OoI",
        "23r8-MV65OoL",
        "o61ABJds5OoO",
        "z982IoCd5OoO",
        "SLZcaVkj5OoQ",
        "BnJVTjFG5OoS",
        "QYhTRhoUJC3d",
        "51aMp54cJC3i",
        "UdYiOvJ9JC3l",
        "ZPLtcDTMJC3m",
        "h0fHrn61JC3o",
        "vH2d_IO5Dwb6",
        "raEpp3tNEc0I",
        "CzVTKcvZEc0L",
        "gU01WvMdEIEO",
        "jkb7zalhEIES",
        "Jxhm51bbEIES",
        "7AZww3yOEIEU",
        "HgOfGSvYEIEW",
        "xHdo1_OnV4vj",
        "4dLB5E1JV4vk",
        "zsU-4FwaV4vn",
        "T96wc3dsV4vq",
        "77Y-TYYUV4vu",
        "LnQ2uGllV4vw",
        "27JkSaPZV4vy",
        "SkiqhJ0ikLNy",
        "C-KeQovWkLNz",
        "f6n0zk7IkLN3",
        "7JW772yNkLN6",
        "wYXt9zcokLN8",
        "y-rmrk8wkLN9",
        "UEakObEdkLN_",
        "ikQ9npRbkLOA",
        "b2mncJ_Z6eKL",
        "STR0-t4z6eKN",
        "aLjpIJXn6eKR",
        "Uojuq9vt6eKU",
        "uzQzwUi66eKX",
        "m5fEJBE5Bk9j",
        "-bAj6_C7uXEr",
        "SpsZPeusuakM",
        "ui0LwF64rphQ",
        "4ET5OsiWbiod",
        "P3yECJz3dKuI",
        "zOFONrImpylo",
        "tw4FLuBiwTvZ",
        "3TSY9ZayJwLM",
        "b_1w3N4F7qbb",
        "ZPPC3SrHykiJ",
        "87yfZmRJcRsm",
        "97W_t0fUeqKO",
        "TaA5xRxUwKBX",
        "rvpSZt9Jx0Kw",
        "OgjSliMoWQbK"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "1336dc93fed444907148fdefc226feab10af1c3f9ec40f52f703fca06f588eaf"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1eac266755e14dfdbfb7e331da9a8894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_267b5da6d4104a4fb540eeb24202ade4",
              "IPY_MODEL_bcb42bd15db94d569c3c7d5dcd68417a",
              "IPY_MODEL_2f54049fba174b8f9ecf1bb37cba8e5c"
            ],
            "layout": "IPY_MODEL_05df3846f31140c6a78e3de18766b889"
          }
        },
        "267b5da6d4104a4fb540eeb24202ade4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48447bacc83b4994a3245725f0c2c751",
            "placeholder": "​",
            "style": "IPY_MODEL_f150e713a47a4af9a7a0762101c18874",
            "value": "100%"
          }
        },
        "bcb42bd15db94d569c3c7d5dcd68417a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb6b5a6576294c55adbe568ec772cb41",
            "max": 113445839,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54e278fb178441e18a7470b44d6fbc5f",
            "value": 113445839
          }
        },
        "2f54049fba174b8f9ecf1bb37cba8e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6461925d48ed4295907384fdb9acbf24",
            "placeholder": "​",
            "style": "IPY_MODEL_88afd5b763ce48dcac39908b8837bbbc",
            "value": " 108M/108M [00:00&lt;00:00, 302MB/s]"
          }
        },
        "05df3846f31140c6a78e3de18766b889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48447bacc83b4994a3245725f0c2c751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f150e713a47a4af9a7a0762101c18874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb6b5a6576294c55adbe568ec772cb41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e278fb178441e18a7470b44d6fbc5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6461925d48ed4295907384fdb9acbf24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88afd5b763ce48dcac39908b8837bbbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18d214b88c574650969a45d9d420c1c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19a809866b8e42e6924aaaa904e28b04",
              "IPY_MODEL_dd69ec46a99f4cd2a26abcb140aeb1f3",
              "IPY_MODEL_4cd66c9f83694608816a91914d062af6"
            ],
            "layout": "IPY_MODEL_7258ceb06a5d4f48ba52c97768f5cb88"
          }
        },
        "19a809866b8e42e6924aaaa904e28b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a831b8c34c65433983f64fceda28cc3a",
            "placeholder": "​",
            "style": "IPY_MODEL_6411991615c644499971f682f18cbea4",
            "value": "100%"
          }
        },
        "dd69ec46a99f4cd2a26abcb140aeb1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbee345af0024e6ba568e4d6c1ccbc17",
            "max": 49475909,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c6e4b75a4954aa4869191387c2302c9",
            "value": 49475909
          }
        },
        "4cd66c9f83694608816a91914d062af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3677a94a957248c68732c90042ac26d1",
            "placeholder": "​",
            "style": "IPY_MODEL_b7f2793ee25e404b87c1e5c868bb8b4a",
            "value": " 47.2M/47.2M [00:04&lt;00:00, 18.3MB/s]"
          }
        },
        "7258ceb06a5d4f48ba52c97768f5cb88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a831b8c34c65433983f64fceda28cc3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6411991615c644499971f682f18cbea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbee345af0024e6ba568e4d6c1ccbc17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c6e4b75a4954aa4869191387c2302c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3677a94a957248c68732c90042ac26d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f2793ee25e404b87c1e5c868bb8b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2147900d1d274ca5bbfe1c76e708cee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc3f83edb4974ce695469235c7a6d77f",
              "IPY_MODEL_9b28f18573d0459282f1fdde5f785171",
              "IPY_MODEL_f6b7154e1cea4ad8a7b8f4bffb1ad2f5"
            ],
            "layout": "IPY_MODEL_193c0d3c9e414927a5aae5536f36ce25"
          }
        },
        "fc3f83edb4974ce695469235c7a6d77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a619383f356144918ca7ea573cf75e84",
            "placeholder": "​",
            "style": "IPY_MODEL_a1bc1c549d72439f89e70c50c11e3410",
            "value": "100%"
          }
        },
        "9b28f18573d0459282f1fdde5f785171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bab3268671d422c87a37fd25f22208d",
            "max": 113445839,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f98a8f4b25c54297a897bc91d11a8880",
            "value": 113445839
          }
        },
        "f6b7154e1cea4ad8a7b8f4bffb1ad2f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04a5af5fe4144b998d3d325859f26e2e",
            "placeholder": "​",
            "style": "IPY_MODEL_79222eb119a449c0813711bdbf1017e1",
            "value": " 108M/108M [00:00&lt;00:00, 142MB/s]"
          }
        },
        "193c0d3c9e414927a5aae5536f36ce25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a619383f356144918ca7ea573cf75e84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1bc1c549d72439f89e70c50c11e3410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bab3268671d422c87a37fd25f22208d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f98a8f4b25c54297a897bc91d11a8880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04a5af5fe4144b998d3d325859f26e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79222eb119a449c0813711bdbf1017e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49d9e884e9924b5b831477768caf81c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd3123f37aff4961a02d1202511d730b",
              "IPY_MODEL_33a4e18cba174a3c814c353c050775ef",
              "IPY_MODEL_ad35149f1fe54b59bfcdbe647dd3d41c"
            ],
            "layout": "IPY_MODEL_eed00be125584151adfb708126500b62"
          }
        },
        "fd3123f37aff4961a02d1202511d730b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc12e868eeb4abeb521255c27c9d94d",
            "placeholder": "​",
            "style": "IPY_MODEL_888a53f0d4664d83b4c796dc3dc7b969",
            "value": "100%"
          }
        },
        "33a4e18cba174a3c814c353c050775ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a3d51e374c4411bb033e0f7e901cd3e",
            "max": 49475909,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fafbe7f4fd6048479a03cb2e7ff2330e",
            "value": 49475909
          }
        },
        "ad35149f1fe54b59bfcdbe647dd3d41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb0d4922d3ec47d6be8d234674ad3ed4",
            "placeholder": "​",
            "style": "IPY_MODEL_c850ac4a79e64f23a466efc0adb4751b",
            "value": " 47.2M/47.2M [00:00&lt;00:00, 176MB/s]"
          }
        },
        "eed00be125584151adfb708126500b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc12e868eeb4abeb521255c27c9d94d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "888a53f0d4664d83b4c796dc3dc7b969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a3d51e374c4411bb033e0f7e901cd3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fafbe7f4fd6048479a03cb2e7ff2330e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb0d4922d3ec47d6be8d234674ad3ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c850ac4a79e64f23a466efc0adb4751b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}